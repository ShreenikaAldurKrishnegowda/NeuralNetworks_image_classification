{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a24bdb99",
      "metadata": {
        "id": "a24bdb99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5c7c947f-4a55-4e67-d202-5410cd3159dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install skorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QwJGL9gdL8r5",
        "outputId": "6d5be4da-96d9-4322-df05-b63872bdac16"
      },
      "id": "QwJGL9gdL8r5",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting skorch\n",
            "  Downloading skorch-0.15.0-py3-none-any.whl (239 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/239.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/239.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.3/239.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from skorch) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (1.11.4)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from skorch) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (4.66.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->skorch) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->skorch) (3.4.0)\n",
            "Installing collected packages: skorch\n",
            "Successfully installed skorch-0.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Comparison Between CNN and SVM with their application of the Fashion MNIST Dataset\n",
        "\n",
        "#Import Statements\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import joblib\n",
        "from torch import nn\n",
        "from torch.optim import SGD\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import accuracy_score\n",
        "from skorch import NeuralNetClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ohzf20aiVkpW"
      },
      "id": "Ohzf20aiVkpW",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "be9f0be2-59c3-4c7e-8c31-86272edde011",
      "metadata": {
        "id": "be9f0be2-59c3-4c7e-8c31-86272edde011"
      },
      "outputs": [],
      "source": [
        "#Path for the datasets\n",
        "train_path ='/content/drive/MyDrive/neural_computing_coursework/fashion-mnist_train.csv'\n",
        "test_path = '/content/drive/MyDrive/neural_computing_coursework/fashion-mnist_test.csv'\n",
        "#loading of the datasets into dataframe\n",
        "train_data = pd.read_csv(train_path)\n",
        "test_data = pd.read_csv(test_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2beabb41",
      "metadata": {
        "id": "2beabb41",
        "outputId": "c4739dc3-d842-44b7-cf4a-6f1eac35554c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 785)\n",
            "(10000, 785)\n"
          ]
        }
      ],
      "source": [
        "#Shape of the loaded training dataset\n",
        "print(train_data.shape)\n",
        "\n",
        "#Shape of the loaded training dataset\n",
        "print(test_data.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f007c7a4",
      "metadata": {
        "id": "f007c7a4",
        "outputId": "2287aa2b-9827-4814-941b-405788d0443f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0      2       0       0       0       0       0       0       0       0   \n",
              "1      9       0       0       0       0       0       0       0       0   \n",
              "2      6       0       0       0       0       0       0       0       5   \n",
              "3      0       0       0       0       1       2       0       0       0   \n",
              "4      3       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              "0       0  ...         0         0         0         0         0         0   \n",
              "1       0  ...         0         0         0         0         0         0   \n",
              "2       0  ...         0         0         0        30        43         0   \n",
              "3       0  ...         3         0         0         0         0         1   \n",
              "4       0  ...         0         0         0         0         0         0   \n",
              "\n",
              "   pixel781  pixel782  pixel783  pixel784  \n",
              "0         0         0         0         0  \n",
              "1         0         0         0         0  \n",
              "2         0         0         0         0  \n",
              "3         0         0         0         0  \n",
              "4         0         0         0         0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bd635010-15f9-4ab5-a648-5309c61d3c14\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd635010-15f9-4ab5-a648-5309c61d3c14')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bd635010-15f9-4ab5-a648-5309c61d3c14 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bd635010-15f9-4ab5-a648-5309c61d3c14');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-573dd327-c630-4e45-a87f-cdf18094890f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-573dd327-c630-4e45-a87f-cdf18094890f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-573dd327-c630-4e45-a87f-cdf18094890f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "bd010740",
      "metadata": {
        "id": "bd010740",
        "outputId": "bd8eb97c-b889-4390-c85e-a73e9624c8c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0      0       0       0       0       0       0       0       0       9   \n",
              "1      1       0       0       0       0       0       0       0       0   \n",
              "2      2       0       0       0       0       0       0      14      53   \n",
              "3      2       0       0       0       0       0       0       0       0   \n",
              "4      3       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              "0       8  ...       103        87        56         0         0         0   \n",
              "1       0  ...        34         0         0         0         0         0   \n",
              "2      99  ...         0         0         0         0        63        53   \n",
              "3       0  ...       137       126       140         0       133       224   \n",
              "4       0  ...         0         0         0         0         0         0   \n",
              "\n",
              "   pixel781  pixel782  pixel783  pixel784  \n",
              "0         0         0         0         0  \n",
              "1         0         0         0         0  \n",
              "2        31         0         0         0  \n",
              "3       222        56         0         0  \n",
              "4         0         0         0         0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8f19c30d-b4cb-44e8-8d1e-6380d48020ad\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>103</td>\n",
              "      <td>87</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>53</td>\n",
              "      <td>99</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>53</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>137</td>\n",
              "      <td>126</td>\n",
              "      <td>140</td>\n",
              "      <td>0</td>\n",
              "      <td>133</td>\n",
              "      <td>224</td>\n",
              "      <td>222</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f19c30d-b4cb-44e8-8d1e-6380d48020ad')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8f19c30d-b4cb-44e8-8d1e-6380d48020ad button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8f19c30d-b4cb-44e8-8d1e-6380d48020ad');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-eb5c7376-405f-4f28-9a70-975d120ed649\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eb5c7376-405f-4f28-9a70-975d120ed649')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-eb5c7376-405f-4f28-9a70-975d120ed649 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_data"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "test_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "046810f1",
      "metadata": {
        "id": "046810f1",
        "outputId": "cdc852fe-3001-4e3b-a2bb-b3a2d9f7fb16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#The display_images function provides a visualization of 10 images from the training dataset\n",
        "#and creates horizontal sub-plots with each image with its respective label.\n",
        "#the function reshapes the image from its falttened form and displays it using grayscale colormap\n",
        "\n",
        "def display_images(data, num_images=10):\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(10, 2))\n",
        "    for i in range(num_images):\n",
        "        img = data.iloc[i, 1:].values.reshape(28, 28)\n",
        "        ax = axes[i]\n",
        "        ax.imshow(img, cmap='gray')\n",
        "        ax.axis('off')\n",
        "        ax.set_title(f'Label: {data.iloc[i, 0]}')\n",
        "    plt.show()\n",
        "\n",
        "display_images(train_data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "5d0bc690",
      "metadata": {
        "id": "5d0bc690",
        "outputId": "af79fc29-48af-4c97-d4ff-7c37c54c6720",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counts of labels in the Training Dataset:\n",
            "label\n",
            "0    6000\n",
            "1    6000\n",
            "2    6000\n",
            "3    6000\n",
            "4    6000\n",
            "5    6000\n",
            "6    6000\n",
            "7    6000\n",
            "8    6000\n",
            "9    6000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#This code computes the frequency of the occurence of the labels from training dataset\n",
        "#and sorts them by the index value\n",
        "label_counts = train_data['label'].value_counts().sort_index()\n",
        "print(\"Counts of labels in the Training Dataset:\")\n",
        "print(label_counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "9efbdd8d",
      "metadata": {
        "id": "9efbdd8d",
        "outputId": "513d54f5-1278-4fe7-cc91-9bdb15078605",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lables with theri classes:\n",
            "0: T-shirt/top\n",
            "1: Trouser\n",
            "2: Pullover\n",
            "3: Dress\n",
            "4: Coat\n",
            "5: Sandal\n",
            "6: Shirt\n",
            "7: Sneaker\n",
            "8: Bag\n",
            "9: Ankle boot\n"
          ]
        }
      ],
      "source": [
        "#This code creates a dictionary of labels and their corresponding class names and prints them.\n",
        "#this is essential for mapping of the between lables and classes.\n",
        "label_names = {\n",
        "    0: \"T-shirt/top\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle boot\"\n",
        "}\n",
        "print(\"Lables with theri classes:\")\n",
        "for label, name in label_names.items():\n",
        "    print(f\"{label}: {name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e288c627",
      "metadata": {
        "id": "e288c627"
      },
      "outputs": [],
      "source": [
        "#training and test data is split and converted into numpy array for machine learing\n",
        "X_train = train_data.drop('label', axis=1).values.astype(np.float32)\n",
        "y_train = train_data['label'].values.astype(np.int64)\n",
        "X_test = test_data.drop('label', axis=1).values.astype(np.float32)\n",
        "y_test = test_data['label'].values.astype(np.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8c586717",
      "metadata": {
        "id": "8c586717"
      },
      "outputs": [],
      "source": [
        "#Scaling the pixel value to [0,1] range to bring all inputs on similar scale\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "39240873",
      "metadata": {
        "id": "39240873",
        "outputId": "ada21ba0-7c2a-48c3-f493-0eb0aef30579",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Images:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flipped Images:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 5 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxsAAACZCAYAAABHTieHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAimklEQVR4nO3dfZCVZf3H8UsDiSdBRJ5ZYQERBEFIUFPEp6AhKEtMG8VMi8DhD7JGlJhpAvtppjSOSU6NBcSogUIzEoqQgAKBELvK4/IkT8vC7oI8I5X+/r6/3w/t5bIXe3b3/frv+s61h/uc+z7XOTfn/tzfCz7//PPPAwAAAABUsQurewMAAAAA1E6cbAAAAABIgpMNAAAAAElwsgEAAAAgCU42AAAAACTByQYAAACAJDjZAAAAAJAEJxsAAAAAkqgXO/GCCy5IuR2ooc5XT0iOPyjnsydp6mNQPb59fvXq+SX7s88+i6opkydPzox37drl5jRo0MDVzpw542qnTp1ytaZNm2bG06ZNi9oupX79+pnxv//970o/VlWqiWtgzLEWq0OHDq42ZcoUV7P7L4QQli5dmhnv3r3bzVm3bp2rderUydWuv/56VxsyZEhmvHDhQjdn6tSprlaVLrzQ/5+ueq0r+/rXxOMvV91+++2uVlhY6GqlpaWudvXVV7vahx9+WDUblsNijz9+2QAAAACQBCcbAAAAAJLgZAMAAABAEpxsAAAAAEgiOiAOAKhe//nPfyr9t3PmzHG1gQMHZsYNGzZ0cz766CNXKysrc7Urr7zS1Zo3b54Z9+7d280ZO3asqym5Egivac4lDH7LLbdkxrfeequbc/r0aVdTQe+uXbu6Wn5+fmY8dOhQN2fEiBGupo7lI0eOuJoN96rjdubMma7Wtm1bV7vvvvsy45KSEjdHqcowOOJMmjTJ1QYPHuxqt912W2bcq1cvN2f27Nmu9o9//MPVVq9e7Wo2IL548WI3R93MY9SoUa62f/9+V6tJ+GUDAAAAQBKcbAAAAABIgpMNAAAAAElwsgEAAAAgiQs+j0wq1YXukfji6F6K6lSbOojHUAFGFSZ84IEHXG3Hjh2uZgOzeXl5bs6aNWtcTYVxVQfn48ePZ8atW7d2c9Q+/Oc//+lqtvt4QUGBm1MdassaqG4EYAOuK1ascHMeffRRV/vXv/7lau3atXO1//73v5mxugmAuvHA3LlzXU0d33Y7hg8f7uao0HuLFi1c7eTJk5nx8uXL3Zxx48ZV+Hch6K7iKigco7Ycf5X11FNPudoPf/hDV9u4caOrvfTSS5lxly5d3JwHH3zQ1b70pS+52p133ulq9th97LHH3JymTZu6mnof9O/fPzM+evSom1Md6CAOAAAAoFpxsgEAAAAgCU42AAAAACRRZzIbN954o6t94xvfyIxV85a9e/e62kUXXeRqqrFR9+7dM2N1neayZcv8xlahevV838ZzaQxm1fXrRVG9ampmI7bR2jPPPJMZ2yZrIYRQv359V1PX8x46dMjV7PXC6prlEydORP2baq2JaUSlGgl++ctfdjV7nfTLL7/s5qjrt1OriWvgH//4R1ezn1chhPDBBx9kxuqzQ+V83n77bVdT2QubuykuLnZz1PXrI0eOdLUGDRq4mn08+5kfQgizZs1yta9+9auuZj/31fP585//7Gq//vWvXa0q1cTjryoVFRW5ms2KhaCPXdu8UR1r6u/Ua67WLDuvvLzczbG5pRB0A8yJEydmxjbDVl3IbAAAAACoVpxsAAAAAEiCkw0AAAAASXCyAQAAACCJGh8Q/7//+z9XmzBhgqvt3LnT1Ww4smXLlm6OCnfNnz/f1a699lpX+81vfpMZ7969281RoXEVkps6dWpm/Oqrr7o51aGuh9NQvWpqQFxp3769q82bNy8z3rZtm5ujGuWpplMqiG0DkaqxWL9+/VxNhc1tg8AQfLhSNTiL2a4Q/HNSgcy+ffu6Wmq5vgaqG5qsXr3a1VSjRttcceXKlW7O5Zdf7mpqP6vjwzb6U8HYAQMGuNqbb77paiqobpsQqveFuomBujFMt27dMmP1HL/2ta+52rPPPhv1b1ZWrh9/VUk1NV24cKGrHTx40NVUENuuY+pGPzZEHoJ+LUpKSlytcePGmXGrVq3cHPUdUK3pCxYsyIy/973vuTnVgYA4AAAAgGrFyQYAAACAJDjZAAAAAJAEJxsAAAAAkvAtX3OIDQN9+OGHbo4KEqqgjgrhlJaWZsYqFNazZ09X27Nnj6v95Cc/cbXNmze7mqXCkTaIFkIIzz//fGb8l7/8xc3p37+/qxUWFla4DXVNbPdmO0/Nueyyy1xNdaufO3fuF9nE/yk2qHc+w9M4d6NGjXI1u75dcsklbo4KSp85c8bVDh8+XOE8tU6q9U7NU+FKG05W3Xj37dvnaioobDuZq7Xz3nvvdbVXXnnF1eqS73znO1Hz1LFlP//UPr7nnnuiHr9Fixau9t5772XGam2zN3IJIYQHH3zQ1dRNYP7+979nxmPGjHFzVGj8008/dbWPP/44M96yZYubo8Ls6qYFVRkQr0uuv/56V1NrUfPmzV1NfR7a9U8da+rGBuo4VTcYqlcv+xVbbYN636l1Uh1bNQm/bAAAAABIgpMNAAAAAElwsgEAAAAgCU42AAAAACSRPCAeG8ZVbCD86NGjbk55ebmrqcCQCkw2aNAgM65fv76bo0I5w4YNc7UdO3ZUuB0qyKleCxUes90vjx8/7uaoIKQKuCsxYejaIva5xcxTXZ8fe+wxV1u8eLGrqeO5qrYrhLq1T2uDHj16uFrMzQDU2rZr1y5XUwHdDh06ZMYqLKs676rtUuubDdqq4G2TJk2iavZv1baqm2TU9YC4umFKUVGRq6l9ajsZ9+nTx815/fXXXU11Le/evbur2c/gNm3auDmqs7nafnUjg5EjR2bGtqNzCHpdVJ+bdp4KKzdq1MjVxo4d62q2GzTiqNdcrQOqg7iaZ7vOq7X0s88+czW1Jqqu33ae+o4ZuyZ26tTJ1WoSftkAAAAAkAQnGwAAAACS4GQDAAAAQBLJMxux14m/+OKLrmabUBUXF7s5zZo1c7Vjx465mrqG1M5TDV3UtX8qU6FyIrahy6lTp9wcVVNNXizVoMtefxhCCL/4xS+iajH7KbaZ3Pmitsdel6mel7oGU7F/q5r2/OxnP3O1Tz75xNVeeOEFV1NN3GJUNgcVu//UvNjXDJWnGkSePHkyM1ZNTNW1yHbtCUGvUTbbofZ9x44dXc02OAtBZ5BatWqVGas11j7HEHSDVZsJUcdku3btXK2ue/XVV11NZR7UPrX7XmUFV61a5Wrqs0hdr56fn58Zz58/38255ZZborbV5jNC8Mf8yy+/7ObccccdrrZ27VpX69y5c2asPg+2b9/uaup5o3JU7kdlxWyzyBB0vrJ3796ZsVp3YpvuqbXTfu9UmaGpU6e62k9/+lNXs987VVNT9X0yV/DLBgAAAIAkONkAAAAAkAQnGwAAAACS4GQDAAAAQBJVHhC3gSwV4lMhwTFjxrja1q1bM2MVTlOBSRUYUoEeu62nT592c1T4UgUtVTjIPp5tYBSCDnKqoKVtDqOeo2p+NG7cOFdTAXFLPcdcCwmrULTaz1ZsYM8eW6rRjmrEtmbNGldTIdsJEyZkxk899ZSbE7sf1Dz7+lRlM0NUvebNm7uabfikjl1Vs8HsEPT6ZteVmJtThKCPZ3UzDRv+VjfqUM875nmqxlpqu+o6dWMV1YCsbdu2rmY/c5csWeLmHDhwwNXUWnnixAlXe/rppzPjadOmuTmqKaEKcKvArA2qq2D5O++8U+HfheBvPqBuBKJu3KLW5iuuuMLVVGgfWer7mKqp/aA+q+1nqWrqF9uMWf2tbaSqbl40a9YsV3viiSdcza5/qvGkel/kCn7ZAAAAAJAEJxsAAAAAkuBkAwAAAEASnGwAAAAASKLKA+IxIeIZM2a4mgqB2YCuClirjow2VBlCXLdpFTiMDcuqx7eBNRVwV0FIFXiyz0k979jHV51WZ8+enRnXhIC4Cjna0NS7777r5qibCsRQ4cKCggJXU0F9dWw98sgjmfH69evdnDfffNPV1PGhHt/uQ4LfuU0FXO0ND1RYUQVV1fEQ82+qG1aomgqbq5szNGrUKDNWAfFmzZq5mnqP2huLqHVehc3rmr59+2bG6n2v9p86tux6qh5LdWZWN7tQ+9SG0v/whz+4OSrsq/bz9OnTXc1+ZqkbCGzatMnV1Of5jTfemBnbG9iEoDuIq7D8sGHDXI2AeMXUWqG+q3zwwQeupva9XdvUdxx1zMd+ltrParVm7dixw9XUe9HeYMGGz3Mdv2wAAAAASIKTDQAAAABJcLIBAAAAIAlONgAAAAAkcU4BcRUctCHByy+/3M0ZMGCAqx06dMjVbPBHhZ1th9oQdBdcFaq1j6cCbCrQeOrUqaiaDbSrcJPqKKlqdltVGFwFTFVQdMqUKa5mA+IxnbirmwpiT5o0KTNu06aNm6MCtarr98SJEzPj++67z81RofHXX3/d1dR7xYbXX3jhBTentLTU1VatWuVqig27qdCjCrrFzkPlqbBiTBd4tR6p/aXWShW0tSFD9VhqPVWhWnUDD1tTAUy17qoAsw0Fq8dSN86oa+xn0dy5c90cdXyoG24cPXo0Mx4zZoybU1hY6Grq8+niiy92tYEDB2bG6rvB8uXLXU3t59GjR7vaG2+8kRmrAPfvfvc7V1u0aJGr2SBv79693RzbZTwE/fqrMDu8Sy+9NDNW33HUZ9Pbb7/taqpru13vzuUmQYr9HmVvcnE2av2zNxpQNx7IZfyyAQAAACAJTjYAAAAAJMHJBgAAAIAkONkAAAAAkMQ5BcRjQsTPP/+8q6mwtmJDbDGhwRBC2Ldvn6upYJgNfKnQmQpHqjC47doagg+2qeetAnGdOnVyNRvUi+3gq8LmKqh32WWXZcYqmKzCo9VJvQZbtmzJjFW39G7durlaly5dXG3//v2Z8d69e90cG2ALIYRevXq52ubNm13NhsaXLFni5syZM8fVhgwZ4mobN250NYsweO5QN4tQ71+7f1RnWRUaV+FBFa60QV61BpaUlLiaeu+p57R79+7MWN0wRK2Lqmafuwoh23WsLrJr4OTJk6vssTds2OBqK1ascLW//vWvrmZv3hFCCNu2bcuM1Wff17/+dVdTNwcoKytztQceeCAzXrt2rZujPiO7d+/uajYQ3qFDBzdHfUag8q688srMWK1/qqa0bNnS1WI+69SxpqjP0jNnzlS4Dcq6detczX5XVDe/yWX8sgEAAAAgCU42AAAAACTByQYAAACAJKIzG7HXdtumJSNGjHBz7DWlIcRdr6y2QV3ba/MNZ3t8e719cXFx1Laq5jAqx7Fz584Kt0td85+fn+9q9to/dZ22EvO6hhDCj370o8z4ySefdHNy7Vp+ez1nCP6aSJXVUdezq8Zitvlfo0aN3Bx1PeegQYOi5q1fvz4zVtcAq4ZWquHUNddc42oHDhzIjNU1++q4Ve8p2+wodj1Qj6Vei1w7tlJTWbOYTJS6Jlxds6waV6rX3ebi1DaoHMSJEydcTe1De12xaian8h8qJ2LzHmoNVE1e6xr7novNaqmGZpZqYlpQUOBq9957r6uVl5e7ms2AvPbaa26Oyqip7e/Tp4+rffTRR5nxc8895+aoXJ/KUlrkM9LLy8vLjNX6EZupuP/++13NHpPq8WOp95ltPBybs1DvKXtMqsawuYxfNgAAAAAkwckGAAAAgCQ42QAAAACQBCcbAAAAAJKIDojHBjh/9atfZcYHDx50c1QY1zY4U/+mCkJ++umnrqYa8amg6oUXZs+1VBBSbWuDBg2iajawpgKN7dq1czUVvrRUmE/tI7X96jUbPXp0ZqwC4rlGBQdt4N6GsEMIYc+ePa6mmjjZ10kFxG1wP4QQDh065GqDBw92tRYtWmTGS5cudXNUeNaGHkMIYeHCha528803Z8YqNBzzvlNi14OY0Gld1L59e1dTx5c9BtXapkLR6nVXa6D9N1Xw1q6TZ6OCmjENXNWNC9RrYd8L6rFV8F7V1Huhtoh5z8U2aLXrgzrWhg0b5mpDhw51NXvDCrUdKvSqno9qwvruu++62vTp0zNjdXMXdXMNtcbGoElq1Ro4cGBmrL5DFRYWupoK+KuGorbZbuyNd2LXSbtmqWPh0UcfdTV1g4yY90ou45cNAAAAAElwsgEAAAAgCU42AAAAACTByQYAAACAJKID4rEeeeSRzHjTpk1ujgpTqyCsnafCO7Edb1Wnbvu3KjymtlV1XVahbhtgVgF3tf3q8W0wVHUGV8Fv1S3bdrUMIYTWrVtnxr169XJzVNi6OqnXznYMV3NWrlzpaio8ZkOIqmNs06ZNXU2FwFTgq2/fvpmxCsXOmzfP1RQVTluxYkVmPG7cODdn8eLFUY9vqXBubKdiFSS282L/rqaKDZLa52zfpyHors5qDdy2bZur2XVXdbE/fvy4q6m1WK1vq1atyoxVGFe9h1TN/pvq5gz79u1zta5du7ramjVrXK0uUeuFCmLb48/e1CIEfdyqY7J3796uZtdAFSK3Id4QdKdndTy0atUqMx41apSbY7tUh1D5G1sQBq9a/fv3z4zVflHHpPqsUzc3qEpq39s10XYsD0Efk++//76r2fdsz549v+gmVit+2QAAAACQBCcbAAAAAJLgZAMAAABAEpxsAAAAAEjinALiNgweQghlZWWZsepgLTdEdDK2YSAVnFahHBUUU4FWu20qgKoeS22rYh//6NGjbo56TiqUbsPDartU6E+FxtVrZmvjx493cx566CFXq06qc60NYufn57s5Kly4bNkyV2vZsmVm3LZtWzdHdSJWr68K1NrAuQrlq/38zjvvuJoKUdptmzZtmpujwvJTp051tYKCgsy4qjuD17VgpQpwq87zMWuNCh2q9a5Zs2auZm88odYQdeyqx1frpw0xxt5YIHZ9s1TwXoXq67rY95vdp7Gh/FmzZrnaDTfc4Gp2LW7cuLGbo47v73//+66mboBg32fqeatu4Wo7cP7ddNNNlfq74uJiV1PHkQ1wx96EJOY7VAh+zVI351Gf+7fddpur2e/bDRs2rHA7cwm/bAAAAABIgpMNAAAAAElwsgEAAAAgCU42AAAAACRxTgHxiRMnuprtNqsCeyo0HtMdXIULVQBadddWQUv7+CqYrbriqqCienwbNlJdxlWoKKaTq6IeKyZ4H0IIx44dy4xHjBhR4b93PqkuwM2bN3c1G55WXeE7duzoairovWjRosz42muvdXNU53EV+lfHqT3mDx8+7OZ069bN1datW+dqysGDBzPjBQsWuDlXXXWVq82cOdPVNm3alBn/6U9/cnNWr17taioQpwL69r2n3sOqk3VNpdYQ1b3bhsbVGqK6LtubG4SgO9TbNVC9D1SYXa3Xao2yncDV2q/WdbX/7b+p/q5NmzauFntDj7pEfS4r9rVbvny5m3PxxRe7murqPHfuXFez+8vesCCEENq3b+9qzzzzjKv169fP1WzX8q1bt7o5b731lqupYx65SX1vUzeFUPvefhap90VV3rxErZHq31SfBfbmS+p7Ri7jlw0AAAAASXCyAQAAACAJTjYAAAAAJBF9MatqaKauobbXpqvrs1VjIHttbwi+MYu6NlQ9lspZqOt71bZV1unTpyusqWvzYq6jDsHnLNScmMaFIejroe3rqK75/spXvuJq50tso8bS0tLMWO1jdV2wuq7bXquprldW14H27dvX1dQ1wHY/qCzNhg0bXC228ZCdp3ICtllfCPoa2C5dumTGTz75pJujtt/ujxD0PrHHs2pqpF7XmkrtC5WXUMe41adPH1dT7xfFrg9q36iciLpeWK279j2kGpuqtbNz586uZo8vtY6p66vVdtV16vhT71/bFPXb3/62m/O3v/3N1e6++25XU/vLNuLLy8tzcwYMGOBq8+fPdzWV4bP5M5X/UM1qbd5NPRbSs+uR+j5jczkh6EaT6pi3n5GxWabYHIedp/5u//79rnb11Ve7mv2sVrm52HW/OvDLBgAAAIAkONkAAAAAkAQnGwAAAACS4GQDAAAAQBLRAfF77rnH1VTjnp07d2bGKhCjmqNNmDDB1WxIeezYsW7O9u3bXU39m6qpmg1fqr+LramQo338hg0bRj2WCtLZ8J4KjsaESUOICxYVFRW5ObfeemvU46dgG9qEoMNQNliqmvuomxHENGVU4TR1kwTbDDAEve9tcFU19VNhcBWEVMHemJsKNGnSpMK/C8G/z9T7Tt3AQT1v9fj2mF+zZo2b06NHD1erqVRoWb3v7fH7xhtvuDkqOH/y5Mmox7c3S1BN8WKbKar3lQ29q/VO3Ywipllr7A0+CIh7sUFYu/7s2LHDzRkyZIirqWNB1WxoV90wRa2LQ4cOdTV1sw7btHT8+PFujroxg3ofVFbqRnG1WczNUGzj07P9nXrNY74Dxor5W7VdKriubsgU81i5jF82AAAAACTByQYAAACAJDjZAAAAAJAEJxsAAAAAkogOiL/22muudvvtt7vaNddck/0HRPB2165drvb000+7mu02W1JS4uao0KP6N2MCmSrgo0I4qqa6LtsAo3p8FTpWgSEbZIrp1nu27VKBOxvMUx2vVbD/fFEdi9VrZ8OmzZo1c3NUUFGFlm1NBetV91L1WBs3bnQ125m5cePGbo4Kg6vXQr0P7HGkjg8Vslehbnt8qL8rLy93NdV9Wh3fNqisbrhgw541mdpf6j0dEwJUYfDYIKINrx45csTNiT3e9u7d62r2/aduIqCOERUQt+upuiGGOsZV6LguiQ2DK/YGEurzRHXbVuuDWq/tmqo6x6sOy1u2bHE19T4YNGhQZrxq1So3p127dq6m1mucfzGha/W9MPZ7VWU7iMeK+QxWYjqB17SbDPDLBgAAAIAkONkAAAAAkAQnGwAAAACS4GQDAAAAQBLRAfHi4mJXGzZsmKuNHDkyMx49erSbo4LligohWirQozrLqpCj/dvYbuEqaKRCiDYorEI/sYEku/2qm/Ljjz/uaj179nS1H/zgB662evXqzHjmzJluzosvvuhqd911l9/YBNR+iAl1l5aWujkx3bxD8PtL3Xjg448/djV1fHzrW99yNXt8FxYWujkqsKvCbyocaeep95M6JtXrqv5NSz1vFdDPz893NdsxNS8vz82pyq6+1U0dSyoUb9eywYMHuznbtm1zNXWMq/eQPe5VgFsdI+qxWrRo4Wp23VLrnTpuVGd7eyzZG4icbVtjO43XVrGfa4rtHq/euytXrnQ1e8OHEHTo3+7DOXPmuDnqmFeh4Pvvv9/V7Lo4Y8YMN0etKyo0Xlk1LcibS2JeO/XZp9YBdYMX+/ix38di96mdp9Y69bm8bNmyqMevSfhlAwAAAEASnGwAAAAASIKTDQAAAABJRGc2Ys2ePft/jr+IBQsWZMY33XSTm6OuzVPXQ6sGUDHUNXaKuh415npAVVPXA9rrEtXzUddbP/TQQ672y1/+0tVUo8VcohrxqWsd7Tx1naZ6zdXraa/1Vg2nxo4d62qLFy+OevzrrrsuM7Z5pxBCuOGGG1ytffv2rqbY661jGyOq7IB9HdWxdumll7qaev/Y7QrB78tx48a5OfPmzXO1hx9+2NVqKpUtsPtHNXlUeSP1uqt9bf82trGgyuKoppS2YV9MI86z/Zv2Oalcimo6p7arrotpFhmCz1S89957bo7K96kGsCqHtWfPnsxY5Q5VJmTNmjWupvazPUaWLFni5mzfvt3VbHPiWLGf54gTk6tV1Ge1yh3bx4t9/Nhsh32fqXVZNTVdu3ZthY9d044rftkAAAAAkAQnGwAAAACS4GQDAAAAQBKcbAAAAABI4pwC4irsEhucsVQjMRuKVoFgFZJRAVelsk39VE0F7uy8mCZ0IeiQow26qdd58+bNrqZUNgweG5ZP4dixY66mgoP9+vXLjNUNBNTrq44t26hx9+7dbk5MkCsEvZ+XL1/+P8dno0LjqsGmbZ6pwsUq1K1CwocOHcqMi4qK3Bx1MwjbLDKEEAoKClxNvT61WWxA1x73sU2h1LyysjJXs8e4anCmgtjqhhhq3bXvNbVuqddCzbNhZdVItby83NWqskFbbRH7Od21a9fMeNWqVW7OoEGDXO3HP/6xq6nmk7Yp6tSpU90cdWMLte9Vw77Dhw9nxqop4fDhw11NrYsxalpot7ZSoWu1JtrPncp+fz3b38Z8rp3Lv1mT8MsGAAAAgCQ42QAAAACQBCcbAAAAAJLgZAMAAABAEucUEI8NOVqxQeP3338/M77zzjvdHBUEUoFGFcKxwcrY7VKPpf7W1mK6VIegQ802fKm24ZVXXvEbK6h/074WsSH46jRp0qTq3oRo6jWPoTour1ixIqo2ceLESv2buUC9V2pTiFyFXmM6dat1Rq13Stu2bSv8W3WcHjlyxNVUQFw9fmlpaYWPrwLu6jnZ5x67HtWrd04fc7VS7Gddjx49MuOf//znbs6mTZtcTR0fvXv3drWePXtmxipEvmXLFlfr1auXq6lja+HChZmxulmAfY4h+GB5LPW65trnZl2gboLTsmVLV0sd6I+5CZH6vlcb8csGAAAAgCQ42QAAAACQBCcbAAAAAJLgZAMAAABAElWenKtsV25l+vTpmfFdd93l5tjOxiGEcNFFF7maCgnabVWh1JjgdwhxIZ+YLuNnm2eDbUuXLq3w3zsbFTpGWrzmX0xtCoMrxcXFrhbTuX3Dhg1uTl5enqvZzuMhhNC0aVNXs0FstR6pfXH8+PGof9OuZSrEGxuWt12dVbDcdiwPQXe9Rhy7H1auXOnmPPfcc672+OOPu1r79u1dzQbJO3fu7OZcccUVrrZ7925XUzcV+O53v5sZ//73v3dz1PFnO6fHIiCeG9Q6o/aD3V+x3byrMliuvq/G3CClph1r/LIBAAAAIAlONgAAAAAkwckGAAAAgCQ42QAAAACQRJUHxGOCM5UN1wwfPrxSfwcAuaRFixauptZFG7p++OGH3ZydO3e6muq6rELpl1xySWasuoW3atXK1VRoV/2tDTGWlZW5OY0aNXK1gQMHutoTTzyRGd99991ujgrLq27WdV1skHTr1q2ZcePGjd0cdeMWdVOB8vJyV3vrrbcyYxWMve6661ytWbNmrrZnzx5Xmz17dmZcVFTk5uTn57uauuFLTAf71B2p65rKvp4q9K+OXXuTCXXcxt4kKOY9peaoYz4mqF7TjjV+2QAAAACQBCcbAAAAAJLgZAMAAABAElWe2QAA/G+2SWcIurnTHXfcUeFjjR071tWeffZZV1ONyuy1zapZmrp+uFu3bq4W0xS1TZs2bo7Kf4wfP97Vfvvb32bGU6ZMcXNOnDjharYZIOKv9/7kk08y41GjRrk5qmGpyuH07NnT1U6ePJkZq+NDZYbUvMmTJ7uazXa89NJLbo46ZtQxb49vMhu5q2PHjq6mmqbaPJc61lTzUJXtUI2jbUZNrZGqMbX6N2s6ftkAAAAAkAQnGwAAAACS4GQDAAAAQBKcbAAAAABI4oLPIxNNMU1GUPecr0Acxx+U8xnITH0MXnXVVa5mm/qpAHesb37zm65mG+Opxmu28V8IIfTv39/VDhw44Gq20drevXvdnBkzZrja5s2bXc1q0qSJq3Xq1MnV1q9fX+FjnYuauAaqx6rK56GCsOoGBbahnmrMp4K96phU+9kGbdXzPnjwoKvFSP0axqqJx191uPnmm12te/fumbG6mUTr1q1dTR3f6kYDJSUlmbEKkRcUFLjaokWLXC1XxR5//LIBAAAAIAlONgAAAAAkwckGAAAAgCQ42QAAAACQRHRAHAAAAAC+CH7ZAAAAAJAEJxsAAAAAkuBkAwAAAEASnGwAAAAASIKTDQAAAABJcLIBAAAAIAlONgAAAAAkwckGAAAAgCQ42QAAAACQxP8D4ou4/iCXXasAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Images:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flipped Images:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Images are flipped horrizontally from left to right to increase robustness of the trained models\n",
        "\n",
        "X_train_flipped = np.array([np.fliplr(img.reshape(28, 28)).flatten() for img in X_train])\n",
        "X_test_flipped = np.array([np.fliplr(img.reshape(28, 28)).flatten() for img in X_test])\n",
        "\n",
        "#This code displays the original and flipped images\n",
        "def display_images(images, number_of_images=5):\n",
        "    fig, axes = plt.subplots(1, number_of_images, figsize=(10, 2))\n",
        "    for i in range(number_of_images):\n",
        "        ax = axes[i]\n",
        "        ax.imshow(images[i].reshape(28, 28), cmap='gray')\n",
        "        ax.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "print(\"Original Images:\")\n",
        "display_images(X_train)\n",
        "\n",
        "print(\"Flipped Images:\")\n",
        "display_images(X_train_flipped)\n",
        "\n",
        "print(\"Original Images:\")\n",
        "display_images(X_test)\n",
        "\n",
        "print(\"Flipped Images:\")\n",
        "display_images(X_test_flipped)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "08289f5c",
      "metadata": {
        "id": "08289f5c"
      },
      "outputs": [],
      "source": [
        "#This code reshapes the flipped training and test datasets into 4D arrays for using in CNN\n",
        "#labels however are extracted from the original data\n",
        "#the features data from training and test dataset are further normalized\n",
        "X_train_flipped = train_data.iloc[:, 1:].values.reshape(-1, 1, 28, 28).astype('float32')\n",
        "y_train = train_data.iloc[:, 0].values\n",
        "X_test_flipped = test_data.iloc[:, 1:].values.reshape(-1, 1, 28, 28).astype('float32')\n",
        "y_test = test_data.iloc[:, 0].values\n",
        "\n",
        "X_train_flipped /= 255.0\n",
        "X_test_flipped /= 255.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "dc978bd5",
      "metadata": {
        "id": "dc978bd5"
      },
      "outputs": [],
      "source": [
        "#Implementation of CNN with 2 convolution layers with max pooling and 2 fully connected layers. Dropout is applied to the first fully connected\n",
        "#layer for regularlisation and preventing overfitting\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(64 * 4 * 4, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.pool(self.conv1(x)))\n",
        "        x = self.relu(self.pool(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 4 * 4)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "df7d1704",
      "metadata": {
        "id": "df7d1704"
      },
      "outputs": [],
      "source": [
        "#Neural Network classifier is implemented with max '10' iterations along with Stochastic Gradient Descent optimizer and CrossEntropy loss since we have a\n",
        "#multi-class classification task\n",
        "net = NeuralNetClassifier(\n",
        "    CNN,\n",
        "    max_epochs=10,\n",
        "    lr=0.01,\n",
        "    optimizer=SGD,\n",
        "    criterion=nn.CrossEntropyLoss,\n",
        "    batch_size=64,\n",
        "    device='cuda' if torch.cuda.is_available() else 'cpu'  # This determines the utilisation of either 'GPU' or 'CPU'.\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "e9e86d4e",
      "metadata": {
        "id": "e9e86d4e",
        "outputId": "b3da1450-884c-49db-9a29-f4f44ddc396c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.5462\u001b[0m       \u001b[32m0.6929\u001b[0m        \u001b[35m0.8646\u001b[0m  3.7401\n",
            "      2        \u001b[36m0.8193\u001b[0m       \u001b[32m0.7408\u001b[0m        \u001b[35m0.7024\u001b[0m  2.3564\n",
            "      3        \u001b[36m0.7157\u001b[0m       \u001b[32m0.7645\u001b[0m        \u001b[35m0.6313\u001b[0m  2.3271\n",
            "      4        \u001b[36m0.6590\u001b[0m       \u001b[32m0.7823\u001b[0m        \u001b[35m0.5803\u001b[0m  2.3041\n",
            "      5        \u001b[36m0.6119\u001b[0m       \u001b[32m0.8017\u001b[0m        \u001b[35m0.5414\u001b[0m  2.2735\n",
            "      6        \u001b[36m0.5777\u001b[0m       \u001b[32m0.8107\u001b[0m        \u001b[35m0.5162\u001b[0m  2.3280\n",
            "      7        \u001b[36m0.5488\u001b[0m       \u001b[32m0.8217\u001b[0m        \u001b[35m0.4921\u001b[0m  2.5399\n",
            "      8        \u001b[36m0.5262\u001b[0m       \u001b[32m0.8331\u001b[0m        \u001b[35m0.4611\u001b[0m  2.6877\n",
            "      9        \u001b[36m0.5043\u001b[0m       \u001b[32m0.8383\u001b[0m        \u001b[35m0.4454\u001b[0m  2.3060\n",
            "     10        \u001b[36m0.4881\u001b[0m       \u001b[32m0.8416\u001b[0m        \u001b[35m0.4332\u001b[0m  2.2757\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
              "  module_=CNN(\n",
              "    (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
              "    (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
              "    (fc1): Linear(in_features=1024, out_features=256, bias=True)\n",
              "    (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (relu): ReLU()\n",
              "  ),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "#The model is fit with training data and corresponding labels for training\n",
        "net.fit(X_train_flipped, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Save the trained CNN base model\n",
        "joblib.dump(net, 'trained_cnn_base_model.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "NXOIzl0MIuUU",
        "outputId": "f2b0023c-d7f3-440c-9921-7f6a905635be"
      },
      "id": "NXOIzl0MIuUU",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['trained_cnn_base_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "daba0a74",
      "metadata": {
        "id": "daba0a74",
        "outputId": "70fad124-ca37-4e21-e068-27e7609976c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy of the CNN model: 84.43%\n"
          ]
        }
      ],
      "source": [
        "# Performing predictions on the trained model\n",
        "y_pred_train = net.predict(X_train_flipped)\n",
        "#calculating the training accuracy\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "print(f\"Training Accuracy of the CNN model: {train_accuracy * 100:.2f}%\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "9ec5ae18-e651-46cd-a03c-7c02e1a9b1f8",
      "metadata": {
        "id": "9ec5ae18-e651-46cd-a03c-7c02e1a9b1f8"
      },
      "outputs": [],
      "source": [
        "#CNN with hyper paramater optimisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "c2cb66dd",
      "metadata": {
        "id": "c2cb66dd"
      },
      "outputs": [],
      "source": [
        "#CNN is implmented with number of filters in each of its layers and dropout rates making it more adaptable.\n",
        "#padding is also implemented to prevent the information loss at the border of images\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_filters_1=32, num_filters_2=64, dropout_rate=0.5):\n",
        "        super(CNN, self).__init__()\n",
        "        self.num_filters_1 = num_filters_1\n",
        "        self.num_filters_2 = num_filters_2\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, num_filters_1, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(num_filters_1, num_filters_2, kernel_size=5, padding=2)\n",
        "\n",
        "        #This line ensures that the input size of the fully connected layer matches with the size of the feautered maps.\n",
        "        self.fc1 = nn.Linear(num_filters_2 * 7 * 7, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.pool(self.conv1(x)))\n",
        "        x = self.relu(self.pool(self.conv2(x)))\n",
        "        x = x.view(-1, self.num_filters_2 * 7 * 7)  # Ensure the feature map size matches this calculation\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "6440ff88-f266-42a9-89f4-20ec2dd29ed5",
      "metadata": {
        "id": "6440ff88-f266-42a9-89f4-20ec2dd29ed5"
      },
      "outputs": [],
      "source": [
        "#Neural Network classifier is implemented with Stochastic Gradient Descent optimizer and CrossEntropy loss since we have a\n",
        "#multi-class classification task\n",
        "cnn_model_architecture = NeuralNetClassifier(\n",
        "    module=CNN,\n",
        "    module__num_filters_1=32,\n",
        "    module__num_filters_2=64,\n",
        "    module__dropout_rate=0.5,\n",
        "    max_epochs=10,\n",
        "    lr=0.01,\n",
        "    batch_size=64,\n",
        "    optimizer=torch.optim.SGD,\n",
        "    criterion=nn.CrossEntropyLoss,\n",
        "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "21e92867-537e-4a62-8513-42e1242e811b",
      "metadata": {
        "id": "21e92867-537e-4a62-8513-42e1242e811b"
      },
      "outputs": [],
      "source": [
        "#certain parameters are repeated to maintain consistency between the defined neural architecture and grid search.\n",
        "#Grid Search will override the values in the classifier with that from the grid_hyper_parameters\n",
        "#while still adhering to the constraints set by the Classifier.\n",
        "grid_hyper_parameters = {\n",
        "    'lr': [0.1,0.01],\n",
        "    'module__num_filters_1': [32, 64],\n",
        "    'module__num_filters_2': [64, 128],\n",
        "    'module__dropout_rate': [0.25, 0.5],\n",
        "    'max_epochs': [10,20]\n",
        "}\n",
        "trained_model = GridSearchCV(cnn_model_architecture, grid_hyper_parameters, refit=True, cv=2, scoring='accuracy', verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "022d3db9",
      "metadata": {
        "id": "022d3db9",
        "outputId": "672c5fba-6daf-45ce-bfdc-f6981d328fba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 21122
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.8841\u001b[0m       \u001b[32m0.7707\u001b[0m        \u001b[35m0.6059\u001b[0m  1.4248\n",
            "      2        \u001b[36m0.5090\u001b[0m       \u001b[32m0.8475\u001b[0m        \u001b[35m0.4217\u001b[0m  1.3291\n",
            "      3        \u001b[36m0.4235\u001b[0m       \u001b[32m0.8695\u001b[0m        \u001b[35m0.3668\u001b[0m  1.3822\n",
            "      4        \u001b[36m0.3751\u001b[0m       \u001b[32m0.8748\u001b[0m        \u001b[35m0.3444\u001b[0m  1.3904\n",
            "      5        \u001b[36m0.3449\u001b[0m       \u001b[32m0.8822\u001b[0m        \u001b[35m0.3307\u001b[0m  1.3188\n",
            "      6        \u001b[36m0.3139\u001b[0m       \u001b[32m0.8860\u001b[0m        \u001b[35m0.3162\u001b[0m  1.3241\n",
            "      7        \u001b[36m0.2942\u001b[0m       0.8853        \u001b[35m0.3054\u001b[0m  1.3195\n",
            "      8        \u001b[36m0.2735\u001b[0m       \u001b[32m0.8878\u001b[0m        \u001b[35m0.3016\u001b[0m  1.3155\n",
            "      9        \u001b[36m0.2577\u001b[0m       \u001b[32m0.8920\u001b[0m        \u001b[35m0.2851\u001b[0m  1.3473\n",
            "     10        \u001b[36m0.2439\u001b[0m       \u001b[32m0.8950\u001b[0m        \u001b[35m0.2800\u001b[0m  1.3220\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.25, module__num_filters_1=32, module__num_filters_2=64; total time=  14.4s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.8862\u001b[0m       \u001b[32m0.6372\u001b[0m        \u001b[35m1.7164\u001b[0m  1.3273\n",
            "      2        \u001b[36m0.5158\u001b[0m       \u001b[32m0.7113\u001b[0m        \u001b[35m0.9598\u001b[0m  1.3402\n",
            "      3        \u001b[36m0.4318\u001b[0m       \u001b[32m0.7553\u001b[0m        \u001b[35m0.7741\u001b[0m  1.3692\n",
            "      4        \u001b[36m0.3860\u001b[0m       \u001b[32m0.7833\u001b[0m        \u001b[35m0.6244\u001b[0m  1.3508\n",
            "      5        \u001b[36m0.3493\u001b[0m       0.7798        0.6612  1.3218\n",
            "      6        \u001b[36m0.3258\u001b[0m       \u001b[32m0.8078\u001b[0m        \u001b[35m0.5432\u001b[0m  1.3348\n",
            "      7        \u001b[36m0.3046\u001b[0m       \u001b[32m0.8165\u001b[0m        \u001b[35m0.5310\u001b[0m  1.4307\n",
            "      8        \u001b[36m0.2850\u001b[0m       \u001b[32m0.8253\u001b[0m        \u001b[35m0.4924\u001b[0m  1.3312\n",
            "      9        \u001b[36m0.2692\u001b[0m       \u001b[32m0.8263\u001b[0m        \u001b[35m0.4921\u001b[0m  1.3269\n",
            "     10        \u001b[36m0.2555\u001b[0m       \u001b[32m0.8392\u001b[0m        \u001b[35m0.4685\u001b[0m  1.3102\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.25, module__num_filters_1=32, module__num_filters_2=64; total time=  14.4s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.8495\u001b[0m       \u001b[32m0.8042\u001b[0m        \u001b[35m0.5349\u001b[0m  1.7383\n",
            "      2        \u001b[36m0.5041\u001b[0m       \u001b[32m0.8480\u001b[0m        \u001b[35m0.4214\u001b[0m  1.7184\n",
            "      3        \u001b[36m0.4199\u001b[0m       \u001b[32m0.8675\u001b[0m        \u001b[35m0.3684\u001b[0m  1.7338\n",
            "      4        \u001b[36m0.3732\u001b[0m       \u001b[32m0.8737\u001b[0m        \u001b[35m0.3483\u001b[0m  1.7647\n",
            "      5        \u001b[36m0.3400\u001b[0m       \u001b[32m0.8832\u001b[0m        \u001b[35m0.3258\u001b[0m  1.7577\n",
            "      6        \u001b[36m0.3155\u001b[0m       \u001b[32m0.8842\u001b[0m        \u001b[35m0.3199\u001b[0m  1.8704\n",
            "      7        \u001b[36m0.2928\u001b[0m       \u001b[32m0.8885\u001b[0m        \u001b[35m0.3011\u001b[0m  1.7778\n",
            "      8        \u001b[36m0.2745\u001b[0m       \u001b[32m0.8910\u001b[0m        \u001b[35m0.2905\u001b[0m  1.7485\n",
            "      9        \u001b[36m0.2587\u001b[0m       \u001b[32m0.8938\u001b[0m        \u001b[35m0.2875\u001b[0m  1.7423\n",
            "     10        \u001b[36m0.2427\u001b[0m       \u001b[32m0.8942\u001b[0m        \u001b[35m0.2870\u001b[0m  1.7593\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.25, module__num_filters_1=32, module__num_filters_2=128; total time=  18.7s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.8503\u001b[0m       \u001b[32m0.6542\u001b[0m        \u001b[35m1.2736\u001b[0m  1.7600\n",
            "      2        \u001b[36m0.5031\u001b[0m       \u001b[32m0.7293\u001b[0m        \u001b[35m0.9022\u001b[0m  1.7798\n",
            "      3        \u001b[36m0.4198\u001b[0m       \u001b[32m0.7748\u001b[0m        \u001b[35m0.6966\u001b[0m  1.8640\n",
            "      4        \u001b[36m0.3748\u001b[0m       \u001b[32m0.7887\u001b[0m        \u001b[35m0.6260\u001b[0m  1.7488\n",
            "      5        \u001b[36m0.3420\u001b[0m       \u001b[32m0.8015\u001b[0m        \u001b[35m0.5762\u001b[0m  1.7577\n",
            "      6        \u001b[36m0.3139\u001b[0m       \u001b[32m0.8172\u001b[0m        \u001b[35m0.5235\u001b[0m  1.7645\n",
            "      7        \u001b[36m0.2950\u001b[0m       \u001b[32m0.8190\u001b[0m        \u001b[35m0.5211\u001b[0m  1.7487\n",
            "      8        \u001b[36m0.2752\u001b[0m       \u001b[32m0.8350\u001b[0m        \u001b[35m0.4803\u001b[0m  1.7484\n",
            "      9        \u001b[36m0.2584\u001b[0m       0.8297        0.4953  1.7610\n",
            "     10        \u001b[36m0.2405\u001b[0m       \u001b[32m0.8463\u001b[0m        \u001b[35m0.4501\u001b[0m  1.7801\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.25, module__num_filters_1=32, module__num_filters_2=128; total time=  18.8s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.8398\u001b[0m       \u001b[32m0.8062\u001b[0m        \u001b[35m0.5479\u001b[0m  1.5880\n",
            "      2        \u001b[36m0.4979\u001b[0m       \u001b[32m0.8545\u001b[0m        \u001b[35m0.4149\u001b[0m  1.5836\n",
            "      3        \u001b[36m0.4184\u001b[0m       \u001b[32m0.8683\u001b[0m        \u001b[35m0.3787\u001b[0m  1.5770\n",
            "      4        \u001b[36m0.3699\u001b[0m       \u001b[32m0.8715\u001b[0m        \u001b[35m0.3504\u001b[0m  1.5819\n",
            "      5        \u001b[36m0.3399\u001b[0m       \u001b[32m0.8808\u001b[0m        \u001b[35m0.3247\u001b[0m  1.5779\n",
            "      6        \u001b[36m0.3130\u001b[0m       0.8788        \u001b[35m0.3244\u001b[0m  1.6363\n",
            "      7        \u001b[36m0.2903\u001b[0m       \u001b[32m0.8832\u001b[0m        \u001b[35m0.3091\u001b[0m  1.5973\n",
            "      8        \u001b[36m0.2717\u001b[0m       \u001b[32m0.8870\u001b[0m        \u001b[35m0.3028\u001b[0m  1.6074\n",
            "      9        \u001b[36m0.2545\u001b[0m       \u001b[32m0.8942\u001b[0m        \u001b[35m0.2866\u001b[0m  1.5729\n",
            "     10        \u001b[36m0.2389\u001b[0m       0.8937        0.2880  1.5705\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.25, module__num_filters_1=64, module__num_filters_2=64; total time=  17.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.8502\u001b[0m       \u001b[32m0.6592\u001b[0m        \u001b[35m1.3511\u001b[0m  1.5955\n",
            "      2        \u001b[36m0.4978\u001b[0m       \u001b[32m0.7225\u001b[0m        \u001b[35m0.9245\u001b[0m  1.5849\n",
            "      3        \u001b[36m0.4140\u001b[0m       \u001b[32m0.7652\u001b[0m        \u001b[35m0.7346\u001b[0m  1.5729\n",
            "      4        \u001b[36m0.3680\u001b[0m       \u001b[32m0.7965\u001b[0m        \u001b[35m0.5878\u001b[0m  1.5945\n",
            "      5        \u001b[36m0.3351\u001b[0m       \u001b[32m0.8108\u001b[0m        \u001b[35m0.5387\u001b[0m  1.6038\n",
            "      6        \u001b[36m0.3086\u001b[0m       \u001b[32m0.8210\u001b[0m        \u001b[35m0.5167\u001b[0m  1.5844\n",
            "      7        \u001b[36m0.2847\u001b[0m       \u001b[32m0.8260\u001b[0m        \u001b[35m0.4998\u001b[0m  1.6444\n",
            "      8        \u001b[36m0.2693\u001b[0m       \u001b[32m0.8348\u001b[0m        \u001b[35m0.4787\u001b[0m  1.5826\n",
            "      9        \u001b[36m0.2491\u001b[0m       \u001b[32m0.8398\u001b[0m        \u001b[35m0.4782\u001b[0m  1.5624\n",
            "     10        \u001b[36m0.2361\u001b[0m       0.8353        0.4907  1.6010\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.25, module__num_filters_1=64, module__num_filters_2=64; total time=  17.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.8519\u001b[0m       \u001b[32m0.8020\u001b[0m        \u001b[35m0.5365\u001b[0m  1.9537\n",
            "      2        \u001b[36m0.4966\u001b[0m       \u001b[32m0.8573\u001b[0m        \u001b[35m0.4085\u001b[0m  1.9387\n",
            "      3        \u001b[36m0.4130\u001b[0m       \u001b[32m0.8702\u001b[0m        \u001b[35m0.3661\u001b[0m  1.9262\n",
            "      4        \u001b[36m0.3662\u001b[0m       \u001b[32m0.8778\u001b[0m        \u001b[35m0.3349\u001b[0m  1.9317\n",
            "      5        \u001b[36m0.3326\u001b[0m       \u001b[32m0.8810\u001b[0m        \u001b[35m0.3205\u001b[0m  1.9255\n",
            "      6        \u001b[36m0.3033\u001b[0m       \u001b[32m0.8862\u001b[0m        \u001b[35m0.3045\u001b[0m  1.9420\n",
            "      7        \u001b[36m0.2834\u001b[0m       \u001b[32m0.8898\u001b[0m        \u001b[35m0.2956\u001b[0m  1.9438\n",
            "      8        \u001b[36m0.2643\u001b[0m       \u001b[32m0.8953\u001b[0m        \u001b[35m0.2821\u001b[0m  1.9354\n",
            "      9        \u001b[36m0.2471\u001b[0m       \u001b[32m0.8963\u001b[0m        \u001b[35m0.2810\u001b[0m  1.9374\n",
            "     10        \u001b[36m0.2327\u001b[0m       \u001b[32m0.8997\u001b[0m        \u001b[35m0.2700\u001b[0m  1.9355\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.25, module__num_filters_1=64, module__num_filters_2=128; total time=  20.6s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.8598\u001b[0m       \u001b[32m0.6358\u001b[0m        \u001b[35m1.7511\u001b[0m  1.9152\n",
            "      2        \u001b[36m0.5014\u001b[0m       \u001b[32m0.7312\u001b[0m        \u001b[35m0.8907\u001b[0m  1.9367\n",
            "      3        \u001b[36m0.4097\u001b[0m       \u001b[32m0.7628\u001b[0m        \u001b[35m0.7349\u001b[0m  1.9327\n",
            "      4        \u001b[36m0.3662\u001b[0m       \u001b[32m0.7912\u001b[0m        \u001b[35m0.6213\u001b[0m  1.9340\n",
            "      5        \u001b[36m0.3306\u001b[0m       \u001b[32m0.7932\u001b[0m        \u001b[35m0.6153\u001b[0m  1.9377\n",
            "      6        \u001b[36m0.3069\u001b[0m       \u001b[32m0.8287\u001b[0m        \u001b[35m0.4966\u001b[0m  1.9355\n",
            "      7        \u001b[36m0.2811\u001b[0m       \u001b[32m0.8302\u001b[0m        0.4976  1.9406\n",
            "      8        \u001b[36m0.2644\u001b[0m       \u001b[32m0.8408\u001b[0m        \u001b[35m0.4694\u001b[0m  1.9647\n",
            "      9        \u001b[36m0.2435\u001b[0m       \u001b[32m0.8458\u001b[0m        0.4721  1.9551\n",
            "     10        \u001b[36m0.2284\u001b[0m       \u001b[32m0.8500\u001b[0m        \u001b[35m0.4542\u001b[0m  1.9418\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.25, module__num_filters_1=64, module__num_filters_2=128; total time=  20.6s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.9163\u001b[0m       \u001b[32m0.8018\u001b[0m        \u001b[35m0.5329\u001b[0m  1.3320\n",
            "      2        \u001b[36m0.5449\u001b[0m       \u001b[32m0.8435\u001b[0m        \u001b[35m0.4278\u001b[0m  1.3245\n",
            "      3        \u001b[36m0.4587\u001b[0m       \u001b[32m0.8627\u001b[0m        \u001b[35m0.3787\u001b[0m  1.3103\n",
            "      4        \u001b[36m0.4090\u001b[0m       \u001b[32m0.8732\u001b[0m        \u001b[35m0.3479\u001b[0m  1.3303\n",
            "      5        \u001b[36m0.3696\u001b[0m       \u001b[32m0.8747\u001b[0m        \u001b[35m0.3300\u001b[0m  1.3335\n",
            "      6        \u001b[36m0.3438\u001b[0m       \u001b[32m0.8825\u001b[0m        \u001b[35m0.3146\u001b[0m  1.3307\n",
            "      7        \u001b[36m0.3208\u001b[0m       \u001b[32m0.8885\u001b[0m        \u001b[35m0.3062\u001b[0m  1.3281\n",
            "      8        \u001b[36m0.3014\u001b[0m       \u001b[32m0.8920\u001b[0m        \u001b[35m0.2905\u001b[0m  1.3287\n",
            "      9        \u001b[36m0.2864\u001b[0m       \u001b[32m0.8962\u001b[0m        \u001b[35m0.2889\u001b[0m  1.3364\n",
            "     10        \u001b[36m0.2729\u001b[0m       0.8923        0.2895  1.3452\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.5, module__num_filters_1=32, module__num_filters_2=64; total time=  14.2s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.9072\u001b[0m       \u001b[32m0.6610\u001b[0m        \u001b[35m1.5057\u001b[0m  1.3353\n",
            "      2        \u001b[36m0.5395\u001b[0m       \u001b[32m0.7123\u001b[0m        \u001b[35m0.9810\u001b[0m  1.3480\n",
            "      3        \u001b[36m0.4532\u001b[0m       \u001b[32m0.7640\u001b[0m        \u001b[35m0.7209\u001b[0m  1.3380\n",
            "      4        \u001b[36m0.4072\u001b[0m       \u001b[32m0.7895\u001b[0m        \u001b[35m0.6044\u001b[0m  1.3289\n",
            "      5        \u001b[36m0.3698\u001b[0m       \u001b[32m0.8022\u001b[0m        \u001b[35m0.5664\u001b[0m  1.3375\n",
            "      6        \u001b[36m0.3435\u001b[0m       \u001b[32m0.8178\u001b[0m        \u001b[35m0.5246\u001b[0m  1.3468\n",
            "      7        \u001b[36m0.3245\u001b[0m       \u001b[32m0.8263\u001b[0m        \u001b[35m0.4889\u001b[0m  1.3470\n",
            "      8        \u001b[36m0.3036\u001b[0m       \u001b[32m0.8313\u001b[0m        \u001b[35m0.4859\u001b[0m  1.3463\n",
            "      9        \u001b[36m0.2897\u001b[0m       \u001b[32m0.8385\u001b[0m        \u001b[35m0.4539\u001b[0m  1.3273\n",
            "     10        \u001b[36m0.2776\u001b[0m       \u001b[32m0.8560\u001b[0m        \u001b[35m0.4135\u001b[0m  1.3406\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.5, module__num_filters_1=32, module__num_filters_2=64; total time=  14.4s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.9042\u001b[0m       \u001b[32m0.8105\u001b[0m        \u001b[35m0.5218\u001b[0m  1.7706\n",
            "      2        \u001b[36m0.5322\u001b[0m       \u001b[32m0.8537\u001b[0m        \u001b[35m0.4222\u001b[0m  1.7625\n",
            "      3        \u001b[36m0.4485\u001b[0m       \u001b[32m0.8622\u001b[0m        \u001b[35m0.3828\u001b[0m  1.7625\n",
            "      4        \u001b[36m0.4021\u001b[0m       \u001b[32m0.8733\u001b[0m        \u001b[35m0.3428\u001b[0m  1.7691\n",
            "      5        \u001b[36m0.3650\u001b[0m       \u001b[32m0.8778\u001b[0m        \u001b[35m0.3272\u001b[0m  1.7902\n",
            "      6        \u001b[36m0.3400\u001b[0m       \u001b[32m0.8842\u001b[0m        \u001b[35m0.3145\u001b[0m  1.7746\n",
            "      7        \u001b[36m0.3155\u001b[0m       \u001b[32m0.8887\u001b[0m        \u001b[35m0.2995\u001b[0m  1.7634\n",
            "      8        \u001b[36m0.2972\u001b[0m       \u001b[32m0.8918\u001b[0m        \u001b[35m0.2930\u001b[0m  1.7682\n",
            "      9        \u001b[36m0.2806\u001b[0m       \u001b[32m0.8968\u001b[0m        \u001b[35m0.2791\u001b[0m  1.7704\n",
            "     10        \u001b[36m0.2641\u001b[0m       0.8943        \u001b[35m0.2790\u001b[0m  1.7732\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.5, module__num_filters_1=32, module__num_filters_2=128; total time=  18.8s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.8852\u001b[0m       \u001b[32m0.6487\u001b[0m        \u001b[35m1.6330\u001b[0m  1.7753\n",
            "      2        \u001b[36m0.5345\u001b[0m       \u001b[32m0.7127\u001b[0m        \u001b[35m1.0070\u001b[0m  1.7808\n",
            "      3        \u001b[36m0.4435\u001b[0m       \u001b[32m0.7635\u001b[0m        \u001b[35m0.7149\u001b[0m  1.7738\n",
            "      4        \u001b[36m0.3949\u001b[0m       \u001b[32m0.7955\u001b[0m        \u001b[35m0.5890\u001b[0m  1.7671\n",
            "      5        \u001b[36m0.3591\u001b[0m       \u001b[32m0.8157\u001b[0m        \u001b[35m0.5278\u001b[0m  1.7691\n",
            "      6        \u001b[36m0.3328\u001b[0m       \u001b[32m0.8165\u001b[0m        \u001b[35m0.5246\u001b[0m  1.7685\n",
            "      7        \u001b[36m0.3069\u001b[0m       0.8162        0.5450  1.7725\n",
            "      8        \u001b[36m0.2906\u001b[0m       \u001b[32m0.8443\u001b[0m        \u001b[35m0.4507\u001b[0m  1.7772\n",
            "      9        \u001b[36m0.2745\u001b[0m       \u001b[32m0.8527\u001b[0m        \u001b[35m0.4291\u001b[0m  1.7694\n",
            "     10        \u001b[36m0.2599\u001b[0m       \u001b[32m0.8532\u001b[0m        \u001b[35m0.4246\u001b[0m  1.7634\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.5, module__num_filters_1=32, module__num_filters_2=128; total time=  18.8s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.9101\u001b[0m       \u001b[32m0.7967\u001b[0m        \u001b[35m0.5469\u001b[0m  1.5526\n",
            "      2        \u001b[36m0.5344\u001b[0m       \u001b[32m0.8532\u001b[0m        \u001b[35m0.4128\u001b[0m  1.5647\n",
            "      3        \u001b[36m0.4397\u001b[0m       \u001b[32m0.8600\u001b[0m        \u001b[35m0.3812\u001b[0m  1.5750\n",
            "      4        \u001b[36m0.3934\u001b[0m       \u001b[32m0.8720\u001b[0m        \u001b[35m0.3499\u001b[0m  1.5772\n",
            "      5        \u001b[36m0.3634\u001b[0m       \u001b[32m0.8750\u001b[0m        \u001b[35m0.3375\u001b[0m  1.5726\n",
            "      6        \u001b[36m0.3362\u001b[0m       \u001b[32m0.8817\u001b[0m        \u001b[35m0.3216\u001b[0m  1.5791\n",
            "      7        \u001b[36m0.3151\u001b[0m       \u001b[32m0.8878\u001b[0m        \u001b[35m0.3046\u001b[0m  1.5737\n",
            "      8        \u001b[36m0.2968\u001b[0m       \u001b[32m0.8903\u001b[0m        \u001b[35m0.2949\u001b[0m  1.5826\n",
            "      9        \u001b[36m0.2819\u001b[0m       \u001b[32m0.8945\u001b[0m        \u001b[35m0.2841\u001b[0m  1.5692\n",
            "     10        \u001b[36m0.2673\u001b[0m       \u001b[32m0.8958\u001b[0m        \u001b[35m0.2777\u001b[0m  1.5705\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.5, module__num_filters_1=64, module__num_filters_2=64; total time=  16.8s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.8813\u001b[0m       \u001b[32m0.6620\u001b[0m        \u001b[35m1.2839\u001b[0m  1.5768\n",
            "      2        \u001b[36m0.5308\u001b[0m       \u001b[32m0.7348\u001b[0m        \u001b[35m0.8691\u001b[0m  1.5700\n",
            "      3        \u001b[36m0.4418\u001b[0m       \u001b[32m0.7722\u001b[0m        \u001b[35m0.6882\u001b[0m  1.6018\n",
            "      4        \u001b[36m0.3933\u001b[0m       \u001b[32m0.7848\u001b[0m        \u001b[35m0.6236\u001b[0m  1.5561\n",
            "      5        \u001b[36m0.3601\u001b[0m       \u001b[32m0.8022\u001b[0m        \u001b[35m0.5850\u001b[0m  1.5605\n",
            "      6        \u001b[36m0.3345\u001b[0m       \u001b[32m0.8200\u001b[0m        \u001b[35m0.5202\u001b[0m  1.5542\n",
            "      7        \u001b[36m0.3121\u001b[0m       \u001b[32m0.8310\u001b[0m        \u001b[35m0.4768\u001b[0m  1.5739\n",
            "      8        \u001b[36m0.2915\u001b[0m       \u001b[32m0.8430\u001b[0m        \u001b[35m0.4523\u001b[0m  1.5905\n",
            "      9        \u001b[36m0.2774\u001b[0m       \u001b[32m0.8458\u001b[0m        \u001b[35m0.4522\u001b[0m  1.5667\n",
            "     10        \u001b[36m0.2621\u001b[0m       \u001b[32m0.8623\u001b[0m        \u001b[35m0.4043\u001b[0m  1.5562\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.5, module__num_filters_1=64, module__num_filters_2=64; total time=  16.8s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.8910\u001b[0m       \u001b[32m0.7940\u001b[0m        \u001b[35m0.5486\u001b[0m  1.9295\n",
            "      2        \u001b[36m0.5376\u001b[0m       \u001b[32m0.8545\u001b[0m        \u001b[35m0.4248\u001b[0m  1.9392\n",
            "      3        \u001b[36m0.4491\u001b[0m       \u001b[32m0.8678\u001b[0m        \u001b[35m0.3673\u001b[0m  1.9358\n",
            "      4        \u001b[36m0.3979\u001b[0m       \u001b[32m0.8763\u001b[0m        \u001b[35m0.3376\u001b[0m  1.9539\n",
            "      5        \u001b[36m0.3593\u001b[0m       \u001b[32m0.8788\u001b[0m        \u001b[35m0.3250\u001b[0m  1.9478\n",
            "      6        \u001b[36m0.3327\u001b[0m       \u001b[32m0.8832\u001b[0m        \u001b[35m0.3082\u001b[0m  1.9407\n",
            "      7        \u001b[36m0.3127\u001b[0m       \u001b[32m0.8897\u001b[0m        \u001b[35m0.3008\u001b[0m  1.9213\n",
            "      8        \u001b[36m0.2917\u001b[0m       \u001b[32m0.8905\u001b[0m        \u001b[35m0.2924\u001b[0m  1.9345\n",
            "      9        \u001b[36m0.2711\u001b[0m       \u001b[32m0.9008\u001b[0m        \u001b[35m0.2728\u001b[0m  1.9434\n",
            "     10        \u001b[36m0.2564\u001b[0m       0.9002        \u001b[35m0.2692\u001b[0m  1.9392\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.5, module__num_filters_1=64, module__num_filters_2=128; total time=  20.6s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.9010\u001b[0m       \u001b[32m0.6643\u001b[0m        \u001b[35m1.2585\u001b[0m  1.9371\n",
            "      2        \u001b[36m0.5276\u001b[0m       \u001b[32m0.7505\u001b[0m        \u001b[35m0.8208\u001b[0m  1.9785\n",
            "      3        \u001b[36m0.4383\u001b[0m       \u001b[32m0.7803\u001b[0m        \u001b[35m0.6630\u001b[0m  1.9622\n",
            "      4        \u001b[36m0.3886\u001b[0m       \u001b[32m0.7913\u001b[0m        \u001b[35m0.6291\u001b[0m  1.9352\n",
            "      5        \u001b[36m0.3533\u001b[0m       \u001b[32m0.8055\u001b[0m        \u001b[35m0.5739\u001b[0m  1.9485\n",
            "      6        \u001b[36m0.3279\u001b[0m       \u001b[32m0.8215\u001b[0m        \u001b[35m0.5078\u001b[0m  1.9332\n",
            "      7        \u001b[36m0.3090\u001b[0m       \u001b[32m0.8325\u001b[0m        \u001b[35m0.4690\u001b[0m  1.9367\n",
            "      8        \u001b[36m0.2909\u001b[0m       \u001b[32m0.8445\u001b[0m        \u001b[35m0.4464\u001b[0m  1.9246\n",
            "      9        \u001b[36m0.2729\u001b[0m       0.8362        0.4799  1.9315\n",
            "     10        \u001b[36m0.2526\u001b[0m       \u001b[32m0.8547\u001b[0m        \u001b[35m0.4102\u001b[0m  1.9478\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.5, module__num_filters_1=64, module__num_filters_2=128; total time=  20.7s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.8972\u001b[0m       \u001b[32m0.7703\u001b[0m        \u001b[35m0.6066\u001b[0m  1.3559\n",
            "      2        \u001b[36m0.5275\u001b[0m       \u001b[32m0.8480\u001b[0m        \u001b[35m0.4280\u001b[0m  1.3494\n",
            "      3        \u001b[36m0.4387\u001b[0m       \u001b[32m0.8653\u001b[0m        \u001b[35m0.3781\u001b[0m  1.3290\n",
            "      4        \u001b[36m0.3869\u001b[0m       \u001b[32m0.8705\u001b[0m        \u001b[35m0.3515\u001b[0m  1.3465\n",
            "      5        \u001b[36m0.3519\u001b[0m       \u001b[32m0.8763\u001b[0m        \u001b[35m0.3409\u001b[0m  1.3396\n",
            "      6        \u001b[36m0.3244\u001b[0m       \u001b[32m0.8807\u001b[0m        \u001b[35m0.3198\u001b[0m  1.3306\n",
            "      7        \u001b[36m0.3022\u001b[0m       \u001b[32m0.8843\u001b[0m        \u001b[35m0.3105\u001b[0m  1.3379\n",
            "      8        \u001b[36m0.2854\u001b[0m       \u001b[32m0.8862\u001b[0m        \u001b[35m0.3020\u001b[0m  1.3393\n",
            "      9        \u001b[36m0.2646\u001b[0m       \u001b[32m0.8902\u001b[0m        \u001b[35m0.2950\u001b[0m  1.3337\n",
            "     10        \u001b[36m0.2506\u001b[0m       \u001b[32m0.8957\u001b[0m        \u001b[35m0.2916\u001b[0m  1.3294\n",
            "     11        \u001b[36m0.2352\u001b[0m       0.8943        \u001b[35m0.2914\u001b[0m  1.3208\n",
            "     12        \u001b[36m0.2237\u001b[0m       \u001b[32m0.8997\u001b[0m        \u001b[35m0.2785\u001b[0m  1.3136\n",
            "     13        \u001b[36m0.2101\u001b[0m       \u001b[32m0.9028\u001b[0m        \u001b[35m0.2730\u001b[0m  1.3333\n",
            "     14        \u001b[36m0.1966\u001b[0m       0.8990        0.2823  1.3451\n",
            "     15        \u001b[36m0.1845\u001b[0m       0.9008        0.2876  1.3391\n",
            "     16        \u001b[36m0.1715\u001b[0m       0.9017        0.2889  1.3368\n",
            "     17        \u001b[36m0.1620\u001b[0m       \u001b[32m0.9072\u001b[0m        0.2793  1.3244\n",
            "     18        \u001b[36m0.1516\u001b[0m       0.9068        0.2740  1.3327\n",
            "     19        \u001b[36m0.1426\u001b[0m       0.9038        0.2896  1.3546\n",
            "     20        \u001b[36m0.1324\u001b[0m       0.9062        0.2888  1.3384\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.25, module__num_filters_1=32, module__num_filters_2=64; total time=  27.8s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.8833\u001b[0m       \u001b[32m0.6540\u001b[0m        \u001b[35m1.5371\u001b[0m  1.3430\n",
            "      2        \u001b[36m0.5043\u001b[0m       \u001b[32m0.7182\u001b[0m        \u001b[35m0.9510\u001b[0m  1.3291\n",
            "      3        \u001b[36m0.4172\u001b[0m       \u001b[32m0.7702\u001b[0m        \u001b[35m0.6852\u001b[0m  1.3270\n",
            "      4        \u001b[36m0.3717\u001b[0m       \u001b[32m0.7858\u001b[0m        \u001b[35m0.6436\u001b[0m  1.3286\n",
            "      5        \u001b[36m0.3414\u001b[0m       \u001b[32m0.7952\u001b[0m        \u001b[35m0.6122\u001b[0m  1.3246\n",
            "      6        \u001b[36m0.3143\u001b[0m       \u001b[32m0.8067\u001b[0m        \u001b[35m0.5608\u001b[0m  1.3269\n",
            "      7        \u001b[36m0.2915\u001b[0m       \u001b[32m0.8245\u001b[0m        \u001b[35m0.4962\u001b[0m  1.3392\n",
            "      8        \u001b[36m0.2737\u001b[0m       \u001b[32m0.8310\u001b[0m        \u001b[35m0.4896\u001b[0m  1.3481\n",
            "      9        \u001b[36m0.2563\u001b[0m       \u001b[32m0.8345\u001b[0m        \u001b[35m0.4749\u001b[0m  1.3406\n",
            "     10        \u001b[36m0.2423\u001b[0m       \u001b[32m0.8405\u001b[0m        \u001b[35m0.4673\u001b[0m  1.3619\n",
            "     11        \u001b[36m0.2298\u001b[0m       \u001b[32m0.8492\u001b[0m        \u001b[35m0.4486\u001b[0m  1.3732\n",
            "     12        \u001b[36m0.2143\u001b[0m       \u001b[32m0.8538\u001b[0m        \u001b[35m0.4302\u001b[0m  1.3390\n",
            "     13        \u001b[36m0.2029\u001b[0m       \u001b[32m0.8642\u001b[0m        \u001b[35m0.4036\u001b[0m  1.3347\n",
            "     14        \u001b[36m0.1919\u001b[0m       0.8575        0.4389  1.3459\n",
            "     15        \u001b[36m0.1796\u001b[0m       0.8602        0.4267  1.3291\n",
            "     16        \u001b[36m0.1667\u001b[0m       0.8517        0.4598  1.3496\n",
            "     17        \u001b[36m0.1581\u001b[0m       0.8572        0.4337  1.3372\n",
            "     18        \u001b[36m0.1483\u001b[0m       \u001b[32m0.8687\u001b[0m        0.4114  1.3307\n",
            "     19        \u001b[36m0.1363\u001b[0m       \u001b[32m0.8732\u001b[0m        0.4123  1.3645\n",
            "     20        \u001b[36m0.1256\u001b[0m       \u001b[32m0.8783\u001b[0m        \u001b[35m0.3924\u001b[0m  1.3600\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.25, module__num_filters_1=32, module__num_filters_2=64; total time=  27.9s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.8361\u001b[0m       \u001b[32m0.7673\u001b[0m        \u001b[35m0.6037\u001b[0m  1.7586\n",
            "      2        \u001b[36m0.5008\u001b[0m       \u001b[32m0.8587\u001b[0m        \u001b[35m0.4108\u001b[0m  1.7712\n",
            "      3        \u001b[36m0.4208\u001b[0m       \u001b[32m0.8697\u001b[0m        \u001b[35m0.3645\u001b[0m  1.7706\n",
            "      4        \u001b[36m0.3726\u001b[0m       \u001b[32m0.8758\u001b[0m        \u001b[35m0.3455\u001b[0m  1.7708\n",
            "      5        \u001b[36m0.3376\u001b[0m       \u001b[32m0.8788\u001b[0m        \u001b[35m0.3267\u001b[0m  1.7631\n",
            "      6        \u001b[36m0.3109\u001b[0m       \u001b[32m0.8847\u001b[0m        \u001b[35m0.3135\u001b[0m  1.7822\n",
            "      7        \u001b[36m0.2859\u001b[0m       \u001b[32m0.8883\u001b[0m        \u001b[35m0.3034\u001b[0m  1.7657\n",
            "      8        \u001b[36m0.2707\u001b[0m       \u001b[32m0.8900\u001b[0m        \u001b[35m0.2891\u001b[0m  1.7637\n",
            "      9        \u001b[36m0.2543\u001b[0m       \u001b[32m0.8962\u001b[0m        \u001b[35m0.2839\u001b[0m  1.7647\n",
            "     10        \u001b[36m0.2356\u001b[0m       0.8940        \u001b[35m0.2837\u001b[0m  1.7738\n",
            "     11        \u001b[36m0.2234\u001b[0m       \u001b[32m0.8965\u001b[0m        \u001b[35m0.2780\u001b[0m  1.7658\n",
            "     12        \u001b[36m0.2055\u001b[0m       \u001b[32m0.8988\u001b[0m        0.2799  1.7781\n",
            "     13        \u001b[36m0.1946\u001b[0m       \u001b[32m0.9018\u001b[0m        0.2782  1.7548\n",
            "     14        \u001b[36m0.1817\u001b[0m       \u001b[32m0.9042\u001b[0m        \u001b[35m0.2733\u001b[0m  1.7677\n",
            "     15        \u001b[36m0.1684\u001b[0m       0.8958        0.2972  1.7845\n",
            "     16        \u001b[36m0.1573\u001b[0m       0.9042        0.2844  1.7796\n",
            "     17        \u001b[36m0.1456\u001b[0m       0.8973        0.3003  1.7649\n",
            "     18        \u001b[36m0.1336\u001b[0m       0.9008        0.3056  1.7730\n",
            "     19        \u001b[36m0.1233\u001b[0m       0.9002        0.3056  1.7805\n",
            "     20        \u001b[36m0.1125\u001b[0m       \u001b[32m0.9072\u001b[0m        0.2968  1.7589\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.25, module__num_filters_1=32, module__num_filters_2=128; total time=  36.6s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.8490\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m1.5383\u001b[0m  1.7666\n",
            "      2        \u001b[36m0.5001\u001b[0m       \u001b[32m0.7167\u001b[0m        \u001b[35m1.0127\u001b[0m  1.7709\n",
            "      3        \u001b[36m0.4183\u001b[0m       \u001b[32m0.7607\u001b[0m        \u001b[35m0.7691\u001b[0m  1.7738\n",
            "      4        \u001b[36m0.3712\u001b[0m       \u001b[32m0.7853\u001b[0m        \u001b[35m0.6224\u001b[0m  1.7747\n",
            "      5        \u001b[36m0.3391\u001b[0m       \u001b[32m0.8037\u001b[0m        \u001b[35m0.5710\u001b[0m  1.7607\n",
            "      6        \u001b[36m0.3110\u001b[0m       \u001b[32m0.8287\u001b[0m        \u001b[35m0.4958\u001b[0m  1.7715\n",
            "      7        \u001b[36m0.2906\u001b[0m       0.8210        0.5228  1.7579\n",
            "      8        \u001b[36m0.2713\u001b[0m       \u001b[32m0.8400\u001b[0m        \u001b[35m0.4671\u001b[0m  1.7637\n",
            "      9        \u001b[36m0.2526\u001b[0m       0.8305        0.5041  1.7668\n",
            "     10        \u001b[36m0.2371\u001b[0m       \u001b[32m0.8432\u001b[0m        0.4689  1.7767\n",
            "     11        \u001b[36m0.2205\u001b[0m       \u001b[32m0.8447\u001b[0m        0.4730  1.7702\n",
            "     12        \u001b[36m0.2065\u001b[0m       \u001b[32m0.8537\u001b[0m        \u001b[35m0.4439\u001b[0m  1.7673\n",
            "     13        \u001b[36m0.1918\u001b[0m       0.8525        0.4589  1.7593\n",
            "     14        \u001b[36m0.1805\u001b[0m       \u001b[32m0.8637\u001b[0m        \u001b[35m0.4207\u001b[0m  1.7656\n",
            "     15        \u001b[36m0.1696\u001b[0m       \u001b[32m0.8678\u001b[0m        \u001b[35m0.4144\u001b[0m  1.7768\n",
            "     16        \u001b[36m0.1553\u001b[0m       0.8570        0.4485  1.7891\n",
            "     17        \u001b[36m0.1430\u001b[0m       \u001b[32m0.8713\u001b[0m        \u001b[35m0.4052\u001b[0m  1.7793\n",
            "     18        \u001b[36m0.1313\u001b[0m       \u001b[32m0.8730\u001b[0m        0.4117  1.7675\n",
            "     19        \u001b[36m0.1277\u001b[0m       \u001b[32m0.8780\u001b[0m        \u001b[35m0.4002\u001b[0m  1.7654\n",
            "     20        \u001b[36m0.1127\u001b[0m       0.8668        0.4543  1.7523\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.25, module__num_filters_1=32, module__num_filters_2=128; total time=  36.6s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.8713\u001b[0m       \u001b[32m0.7963\u001b[0m        \u001b[35m0.5361\u001b[0m  1.5655\n",
            "      2        \u001b[36m0.5146\u001b[0m       \u001b[32m0.8473\u001b[0m        \u001b[35m0.4247\u001b[0m  1.5803\n",
            "      3        \u001b[36m0.4285\u001b[0m       \u001b[32m0.8695\u001b[0m        \u001b[35m0.3767\u001b[0m  1.5736\n",
            "      4        \u001b[36m0.3786\u001b[0m       \u001b[32m0.8728\u001b[0m        \u001b[35m0.3505\u001b[0m  1.5667\n",
            "      5        \u001b[36m0.3441\u001b[0m       \u001b[32m0.8808\u001b[0m        \u001b[35m0.3312\u001b[0m  1.5848\n",
            "      6        \u001b[36m0.3131\u001b[0m       \u001b[32m0.8837\u001b[0m        \u001b[35m0.3173\u001b[0m  1.5697\n",
            "      7        \u001b[36m0.2948\u001b[0m       \u001b[32m0.8878\u001b[0m        \u001b[35m0.3079\u001b[0m  1.5740\n",
            "      8        \u001b[36m0.2770\u001b[0m       \u001b[32m0.8913\u001b[0m        \u001b[35m0.2975\u001b[0m  1.5776\n",
            "      9        \u001b[36m0.2562\u001b[0m       \u001b[32m0.8935\u001b[0m        \u001b[35m0.2887\u001b[0m  1.5808\n",
            "     10        \u001b[36m0.2432\u001b[0m       \u001b[32m0.8957\u001b[0m        \u001b[35m0.2816\u001b[0m  1.5901\n",
            "     11        \u001b[36m0.2295\u001b[0m       \u001b[32m0.8987\u001b[0m        \u001b[35m0.2777\u001b[0m  1.5775\n",
            "     12        \u001b[36m0.2146\u001b[0m       \u001b[32m0.8998\u001b[0m        \u001b[35m0.2752\u001b[0m  1.5858\n",
            "     13        \u001b[36m0.2018\u001b[0m       \u001b[32m0.9015\u001b[0m        \u001b[35m0.2750\u001b[0m  1.5968\n",
            "     14        \u001b[36m0.1903\u001b[0m       \u001b[32m0.9033\u001b[0m        \u001b[35m0.2743\u001b[0m  1.5789\n",
            "     15        \u001b[36m0.1811\u001b[0m       \u001b[32m0.9043\u001b[0m        \u001b[35m0.2688\u001b[0m  1.5729\n",
            "     16        \u001b[36m0.1675\u001b[0m       0.9003        0.2811  1.5829\n",
            "     17        \u001b[36m0.1567\u001b[0m       0.9038        0.2787  1.5919\n",
            "     18        \u001b[36m0.1471\u001b[0m       0.9022        0.2911  1.5810\n",
            "     19        \u001b[36m0.1374\u001b[0m       \u001b[32m0.9088\u001b[0m        0.2765  1.5725\n",
            "     20        \u001b[36m0.1256\u001b[0m       0.9040        0.3017  1.5767\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.25, module__num_filters_1=64, module__num_filters_2=64; total time=  32.8s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.8345\u001b[0m       \u001b[32m0.6798\u001b[0m        \u001b[35m1.1669\u001b[0m  1.5774\n",
            "      2        \u001b[36m0.4915\u001b[0m       \u001b[32m0.7175\u001b[0m        \u001b[35m0.9327\u001b[0m  1.5548\n",
            "      3        \u001b[36m0.4099\u001b[0m       \u001b[32m0.7710\u001b[0m        \u001b[35m0.6910\u001b[0m  1.5966\n",
            "      4        \u001b[36m0.3642\u001b[0m       \u001b[32m0.7878\u001b[0m        \u001b[35m0.6319\u001b[0m  1.5907\n",
            "      5        \u001b[36m0.3315\u001b[0m       \u001b[32m0.8107\u001b[0m        \u001b[35m0.5377\u001b[0m  1.5574\n",
            "      6        \u001b[36m0.3066\u001b[0m       \u001b[32m0.8228\u001b[0m        \u001b[35m0.5197\u001b[0m  1.5708\n",
            "      7        \u001b[36m0.2837\u001b[0m       \u001b[32m0.8353\u001b[0m        \u001b[35m0.4864\u001b[0m  1.5959\n",
            "      8        \u001b[36m0.2656\u001b[0m       \u001b[32m0.8455\u001b[0m        \u001b[35m0.4654\u001b[0m  1.5911\n",
            "      9        \u001b[36m0.2496\u001b[0m       0.8452        0.4705  1.5723\n",
            "     10        \u001b[36m0.2384\u001b[0m       \u001b[32m0.8475\u001b[0m        \u001b[35m0.4652\u001b[0m  1.5860\n",
            "     11        \u001b[36m0.2235\u001b[0m       \u001b[32m0.8503\u001b[0m        0.4703  1.5962\n",
            "     12        \u001b[36m0.2069\u001b[0m       \u001b[32m0.8575\u001b[0m        \u001b[35m0.4558\u001b[0m  1.6023\n",
            "     13        \u001b[36m0.1964\u001b[0m       0.8537        0.4643  1.5915\n",
            "     14        \u001b[36m0.1843\u001b[0m       \u001b[32m0.8582\u001b[0m        \u001b[35m0.4494\u001b[0m  1.5903\n",
            "     15        \u001b[36m0.1721\u001b[0m       \u001b[32m0.8640\u001b[0m        \u001b[35m0.4424\u001b[0m  1.5726\n",
            "     16        \u001b[36m0.1636\u001b[0m       \u001b[32m0.8693\u001b[0m        \u001b[35m0.4269\u001b[0m  1.5559\n",
            "     17        \u001b[36m0.1535\u001b[0m       0.8678        \u001b[35m0.4142\u001b[0m  1.5982\n",
            "     18        \u001b[36m0.1427\u001b[0m       0.8583        0.4581  1.5787\n",
            "     19        \u001b[36m0.1324\u001b[0m       \u001b[32m0.8695\u001b[0m        0.4223  1.5840\n",
            "     20        \u001b[36m0.1241\u001b[0m       0.8663        0.4404  1.5686\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.25, module__num_filters_1=64, module__num_filters_2=64; total time=  32.8s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.8406\u001b[0m       \u001b[32m0.8008\u001b[0m        \u001b[35m0.5402\u001b[0m  1.9437\n",
            "      2        \u001b[36m0.4957\u001b[0m       \u001b[32m0.8598\u001b[0m        \u001b[35m0.4071\u001b[0m  1.9481\n",
            "      3        \u001b[36m0.4162\u001b[0m       \u001b[32m0.8652\u001b[0m        \u001b[35m0.3672\u001b[0m  1.9355\n",
            "      4        \u001b[36m0.3680\u001b[0m       \u001b[32m0.8763\u001b[0m        \u001b[35m0.3432\u001b[0m  1.9342\n",
            "      5        \u001b[36m0.3319\u001b[0m       \u001b[32m0.8787\u001b[0m        \u001b[35m0.3239\u001b[0m  1.9459\n",
            "      6        \u001b[36m0.3066\u001b[0m       \u001b[32m0.8840\u001b[0m        \u001b[35m0.3059\u001b[0m  1.9263\n",
            "      7        \u001b[36m0.2841\u001b[0m       \u001b[32m0.8883\u001b[0m        \u001b[35m0.2966\u001b[0m  1.9368\n",
            "      8        \u001b[36m0.2636\u001b[0m       \u001b[32m0.8943\u001b[0m        \u001b[35m0.2832\u001b[0m  1.9812\n",
            "      9        \u001b[36m0.2500\u001b[0m       \u001b[32m0.8985\u001b[0m        \u001b[35m0.2809\u001b[0m  1.9612\n",
            "     10        \u001b[36m0.2315\u001b[0m       0.8950        0.2856  1.9513\n",
            "     11        \u001b[36m0.2155\u001b[0m       0.8958        0.2911  1.9385\n",
            "     12        \u001b[36m0.2013\u001b[0m       \u001b[32m0.9015\u001b[0m        \u001b[35m0.2733\u001b[0m  1.9331\n",
            "     13        \u001b[36m0.1867\u001b[0m       0.9008        0.2748  1.9354\n",
            "     14        \u001b[36m0.1729\u001b[0m       \u001b[32m0.9088\u001b[0m        \u001b[35m0.2713\u001b[0m  1.9520\n",
            "     15        \u001b[36m0.1606\u001b[0m       0.9075        0.2732  1.9358\n",
            "     16        \u001b[36m0.1492\u001b[0m       0.9005        0.2800  1.9308\n",
            "     17        \u001b[36m0.1379\u001b[0m       0.9053        0.2798  1.9431\n",
            "     18        \u001b[36m0.1217\u001b[0m       \u001b[32m0.9103\u001b[0m        \u001b[35m0.2697\u001b[0m  1.9340\n",
            "     19        \u001b[36m0.1157\u001b[0m       0.9073        0.2831  1.9244\n",
            "     20        \u001b[36m0.1039\u001b[0m       0.9063        0.3026  1.9463\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.25, module__num_filters_1=64, module__num_filters_2=128; total time=  40.1s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.8273\u001b[0m       \u001b[32m0.6547\u001b[0m        \u001b[35m1.6207\u001b[0m  1.9247\n",
            "      2        \u001b[36m0.4926\u001b[0m       \u001b[32m0.7002\u001b[0m        \u001b[35m1.0197\u001b[0m  1.9275\n",
            "      3        \u001b[36m0.4093\u001b[0m       \u001b[32m0.7825\u001b[0m        \u001b[35m0.6463\u001b[0m  1.9441\n",
            "      4        \u001b[36m0.3640\u001b[0m       0.7802        0.6480  1.9335\n",
            "      5        \u001b[36m0.3287\u001b[0m       \u001b[32m0.8003\u001b[0m        \u001b[35m0.5731\u001b[0m  1.9574\n",
            "      6        \u001b[36m0.3045\u001b[0m       \u001b[32m0.8162\u001b[0m        \u001b[35m0.5233\u001b[0m  1.9410\n",
            "      7        \u001b[36m0.2830\u001b[0m       \u001b[32m0.8277\u001b[0m        \u001b[35m0.4996\u001b[0m  1.9326\n",
            "      8        \u001b[36m0.2641\u001b[0m       \u001b[32m0.8392\u001b[0m        \u001b[35m0.4755\u001b[0m  1.9337\n",
            "      9        \u001b[36m0.2448\u001b[0m       \u001b[32m0.8465\u001b[0m        \u001b[35m0.4588\u001b[0m  1.9352\n",
            "     10        \u001b[36m0.2310\u001b[0m       \u001b[32m0.8568\u001b[0m        \u001b[35m0.4153\u001b[0m  1.9324\n",
            "     11        \u001b[36m0.2174\u001b[0m       \u001b[32m0.8570\u001b[0m        0.4286  1.9504\n",
            "     12        \u001b[36m0.2004\u001b[0m       \u001b[32m0.8632\u001b[0m        0.4188  1.9437\n",
            "     13        \u001b[36m0.1894\u001b[0m       0.8592        0.4394  1.9362\n",
            "     14        \u001b[36m0.1772\u001b[0m       0.8598        0.4369  1.9424\n",
            "     15        \u001b[36m0.1635\u001b[0m       \u001b[32m0.8655\u001b[0m        \u001b[35m0.4131\u001b[0m  1.9506\n",
            "     16        \u001b[36m0.1539\u001b[0m       0.8648        0.4372  1.9463\n",
            "     17        \u001b[36m0.1437\u001b[0m       0.8607        0.4615  1.9534\n",
            "     18        \u001b[36m0.1294\u001b[0m       \u001b[32m0.8685\u001b[0m        0.4314  1.9398\n",
            "     19        \u001b[36m0.1219\u001b[0m       \u001b[32m0.8815\u001b[0m        \u001b[35m0.3927\u001b[0m  1.9353\n",
            "     20        \u001b[36m0.1101\u001b[0m       0.8750        0.4213  1.9344\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.25, module__num_filters_1=64, module__num_filters_2=128; total time=  40.1s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.9259\u001b[0m       \u001b[32m0.7837\u001b[0m        \u001b[35m0.5772\u001b[0m  1.3324\n",
            "      2        \u001b[36m0.5565\u001b[0m       \u001b[32m0.8452\u001b[0m        \u001b[35m0.4378\u001b[0m  1.3525\n",
            "      3        \u001b[36m0.4660\u001b[0m       \u001b[32m0.8600\u001b[0m        \u001b[35m0.3931\u001b[0m  1.3377\n",
            "      4        \u001b[36m0.4196\u001b[0m       \u001b[32m0.8673\u001b[0m        \u001b[35m0.3635\u001b[0m  1.3503\n",
            "      5        \u001b[36m0.3881\u001b[0m       \u001b[32m0.8733\u001b[0m        \u001b[35m0.3424\u001b[0m  1.3373\n",
            "      6        \u001b[36m0.3580\u001b[0m       \u001b[32m0.8768\u001b[0m        \u001b[35m0.3277\u001b[0m  1.3346\n",
            "      7        \u001b[36m0.3356\u001b[0m       \u001b[32m0.8813\u001b[0m        \u001b[35m0.3192\u001b[0m  1.3189\n",
            "      8        \u001b[36m0.3132\u001b[0m       \u001b[32m0.8828\u001b[0m        \u001b[35m0.3034\u001b[0m  1.3436\n",
            "      9        \u001b[36m0.2967\u001b[0m       \u001b[32m0.8878\u001b[0m        \u001b[35m0.2964\u001b[0m  1.3457\n",
            "     10        \u001b[36m0.2829\u001b[0m       \u001b[32m0.8892\u001b[0m        \u001b[35m0.2916\u001b[0m  1.3397\n",
            "     11        \u001b[36m0.2705\u001b[0m       \u001b[32m0.8930\u001b[0m        \u001b[35m0.2785\u001b[0m  1.3180\n",
            "     12        \u001b[36m0.2572\u001b[0m       \u001b[32m0.8932\u001b[0m        0.2829  1.3292\n",
            "     13        \u001b[36m0.2447\u001b[0m       \u001b[32m0.8985\u001b[0m        \u001b[35m0.2778\u001b[0m  1.3383\n",
            "     14        \u001b[36m0.2366\u001b[0m       0.8967        \u001b[35m0.2742\u001b[0m  1.3306\n",
            "     15        \u001b[36m0.2242\u001b[0m       \u001b[32m0.9023\u001b[0m        \u001b[35m0.2630\u001b[0m  1.3259\n",
            "     16        \u001b[36m0.2131\u001b[0m       \u001b[32m0.9045\u001b[0m        0.2631  1.3273\n",
            "     17        \u001b[36m0.2035\u001b[0m       0.9012        0.2721  1.3237\n",
            "     18        \u001b[36m0.1970\u001b[0m       0.9018        0.2648  1.3368\n",
            "     19        \u001b[36m0.1826\u001b[0m       0.9043        0.2659  1.3398\n",
            "     20        \u001b[36m0.1747\u001b[0m       0.9030        0.2668  1.3388\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.5, module__num_filters_1=32, module__num_filters_2=64; total time=  27.7s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.9047\u001b[0m       \u001b[32m0.6557\u001b[0m        \u001b[35m1.4758\u001b[0m  1.3407\n",
            "      2        \u001b[36m0.5292\u001b[0m       \u001b[32m0.7373\u001b[0m        \u001b[35m0.8594\u001b[0m  1.3366\n",
            "      3        \u001b[36m0.4483\u001b[0m       \u001b[32m0.7657\u001b[0m        \u001b[35m0.7306\u001b[0m  1.3562\n",
            "      4        \u001b[36m0.3993\u001b[0m       \u001b[32m0.7982\u001b[0m        \u001b[35m0.5959\u001b[0m  1.3514\n",
            "      5        \u001b[36m0.3649\u001b[0m       \u001b[32m0.8085\u001b[0m        \u001b[35m0.5585\u001b[0m  1.3563\n",
            "      6        \u001b[36m0.3387\u001b[0m       \u001b[32m0.8132\u001b[0m        \u001b[35m0.5301\u001b[0m  1.3521\n",
            "      7        \u001b[36m0.3173\u001b[0m       \u001b[32m0.8148\u001b[0m        \u001b[35m0.5214\u001b[0m  1.3326\n",
            "      8        \u001b[36m0.2965\u001b[0m       \u001b[32m0.8452\u001b[0m        \u001b[35m0.4479\u001b[0m  1.3241\n",
            "      9        \u001b[36m0.2832\u001b[0m       0.8335        0.4884  1.3379\n",
            "     10        \u001b[36m0.2639\u001b[0m       0.8372        0.4610  1.3340\n",
            "     11        \u001b[36m0.2529\u001b[0m       0.8447        0.4581  1.3257\n",
            "     12        \u001b[36m0.2429\u001b[0m       0.8433        0.4639  1.3224\n",
            "     13        \u001b[36m0.2285\u001b[0m       \u001b[32m0.8508\u001b[0m        \u001b[35m0.4393\u001b[0m  1.3082\n",
            "     14        \u001b[36m0.2196\u001b[0m       \u001b[32m0.8637\u001b[0m        \u001b[35m0.4013\u001b[0m  1.3393\n",
            "     15        \u001b[36m0.2068\u001b[0m       0.8610        0.4097  1.3427\n",
            "     16        \u001b[36m0.1984\u001b[0m       0.8635        0.4038  1.3249\n",
            "     17        \u001b[36m0.1899\u001b[0m       \u001b[32m0.8643\u001b[0m        \u001b[35m0.4006\u001b[0m  1.3315\n",
            "     18        \u001b[36m0.1754\u001b[0m       \u001b[32m0.8690\u001b[0m        \u001b[35m0.3916\u001b[0m  1.3317\n",
            "     19        \u001b[36m0.1683\u001b[0m       \u001b[32m0.8698\u001b[0m        0.3920  1.3137\n",
            "     20        \u001b[36m0.1590\u001b[0m       \u001b[32m0.8765\u001b[0m        0.3969  1.3229\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.5, module__num_filters_1=32, module__num_filters_2=64; total time=  27.7s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.9013\u001b[0m       \u001b[32m0.8042\u001b[0m        \u001b[35m0.5309\u001b[0m  1.7673\n",
            "      2        \u001b[36m0.5443\u001b[0m       \u001b[32m0.8413\u001b[0m        \u001b[35m0.4323\u001b[0m  1.7880\n",
            "      3        \u001b[36m0.4602\u001b[0m       \u001b[32m0.8638\u001b[0m        \u001b[35m0.3780\u001b[0m  1.7540\n",
            "      4        \u001b[36m0.4144\u001b[0m       \u001b[32m0.8745\u001b[0m        \u001b[35m0.3540\u001b[0m  1.7594\n",
            "      5        \u001b[36m0.3763\u001b[0m       \u001b[32m0.8773\u001b[0m        \u001b[35m0.3355\u001b[0m  1.7592\n",
            "      6        \u001b[36m0.3480\u001b[0m       \u001b[32m0.8823\u001b[0m        \u001b[35m0.3197\u001b[0m  1.7780\n",
            "      7        \u001b[36m0.3241\u001b[0m       \u001b[32m0.8855\u001b[0m        \u001b[35m0.3069\u001b[0m  1.7732\n",
            "      8        \u001b[36m0.3059\u001b[0m       \u001b[32m0.8905\u001b[0m        \u001b[35m0.2945\u001b[0m  1.7809\n",
            "      9        \u001b[36m0.2887\u001b[0m       0.8893        \u001b[35m0.2889\u001b[0m  1.7776\n",
            "     10        \u001b[36m0.2707\u001b[0m       \u001b[32m0.8938\u001b[0m        \u001b[35m0.2780\u001b[0m  1.7579\n",
            "     11        \u001b[36m0.2571\u001b[0m       \u001b[32m0.8980\u001b[0m        \u001b[35m0.2687\u001b[0m  1.7628\n",
            "     12        \u001b[36m0.2437\u001b[0m       0.8973        0.2699  1.7785\n",
            "     13        \u001b[36m0.2329\u001b[0m       0.8970        \u001b[35m0.2669\u001b[0m  1.7709\n",
            "     14        \u001b[36m0.2221\u001b[0m       \u001b[32m0.9022\u001b[0m        \u001b[35m0.2637\u001b[0m  1.7652\n",
            "     15        \u001b[36m0.2122\u001b[0m       \u001b[32m0.9035\u001b[0m        \u001b[35m0.2623\u001b[0m  1.7805\n",
            "     16        \u001b[36m0.1966\u001b[0m       \u001b[32m0.9058\u001b[0m        0.2649  1.7671\n",
            "     17        \u001b[36m0.1871\u001b[0m       0.9048        \u001b[35m0.2579\u001b[0m  1.7612\n",
            "     18        \u001b[36m0.1745\u001b[0m       0.9052        0.2641  1.7809\n",
            "     19        \u001b[36m0.1684\u001b[0m       \u001b[32m0.9077\u001b[0m        0.2626  1.7742\n",
            "     20        \u001b[36m0.1588\u001b[0m       0.9042        0.2697  1.7679\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.5, module__num_filters_1=32, module__num_filters_2=128; total time=  36.6s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.9100\u001b[0m       \u001b[32m0.6747\u001b[0m        \u001b[35m1.2705\u001b[0m  1.7633\n",
            "      2        \u001b[36m0.5421\u001b[0m       \u001b[32m0.7135\u001b[0m        \u001b[35m1.0462\u001b[0m  1.7746\n",
            "      3        \u001b[36m0.4496\u001b[0m       \u001b[32m0.7640\u001b[0m        \u001b[35m0.7369\u001b[0m  1.7611\n",
            "      4        \u001b[36m0.4001\u001b[0m       \u001b[32m0.7812\u001b[0m        \u001b[35m0.6561\u001b[0m  1.7699\n",
            "      5        \u001b[36m0.3650\u001b[0m       \u001b[32m0.7950\u001b[0m        \u001b[35m0.5766\u001b[0m  1.7670\n",
            "      6        \u001b[36m0.3394\u001b[0m       \u001b[32m0.8140\u001b[0m        \u001b[35m0.5320\u001b[0m  1.7720\n",
            "      7        \u001b[36m0.3161\u001b[0m       \u001b[32m0.8358\u001b[0m        \u001b[35m0.4817\u001b[0m  1.7636\n",
            "      8        \u001b[36m0.2967\u001b[0m       \u001b[32m0.8370\u001b[0m        \u001b[35m0.4677\u001b[0m  1.7709\n",
            "      9        \u001b[36m0.2774\u001b[0m       0.8357        0.4907  1.7699\n",
            "     10        \u001b[36m0.2648\u001b[0m       \u001b[32m0.8408\u001b[0m        0.4703  1.7674\n",
            "     11        \u001b[36m0.2500\u001b[0m       \u001b[32m0.8552\u001b[0m        \u001b[35m0.4281\u001b[0m  1.7688\n",
            "     12        \u001b[36m0.2357\u001b[0m       \u001b[32m0.8560\u001b[0m        0.4325  1.7782\n",
            "     13        \u001b[36m0.2256\u001b[0m       0.8510        0.4482  1.7606\n",
            "     14        \u001b[36m0.2119\u001b[0m       \u001b[32m0.8647\u001b[0m        \u001b[35m0.4144\u001b[0m  1.7653\n",
            "     15        \u001b[36m0.2021\u001b[0m       0.8518        0.4695  1.7839\n",
            "     16        \u001b[36m0.1913\u001b[0m       \u001b[32m0.8730\u001b[0m        \u001b[35m0.4031\u001b[0m  1.7625\n",
            "     17        \u001b[36m0.1806\u001b[0m       0.8563        0.4547  1.7610\n",
            "     18        \u001b[36m0.1709\u001b[0m       \u001b[32m0.8753\u001b[0m        \u001b[35m0.3916\u001b[0m  1.7687\n",
            "     19        \u001b[36m0.1611\u001b[0m       0.8657        0.4300  1.7768\n",
            "     20        \u001b[36m0.1547\u001b[0m       \u001b[32m0.8757\u001b[0m        \u001b[35m0.3911\u001b[0m  1.7660\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.5, module__num_filters_1=32, module__num_filters_2=128; total time=  36.6s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.8935\u001b[0m       \u001b[32m0.8038\u001b[0m        \u001b[35m0.5419\u001b[0m  1.5798\n",
            "      2        \u001b[36m0.5398\u001b[0m       \u001b[32m0.8545\u001b[0m        \u001b[35m0.4208\u001b[0m  1.5684\n",
            "      3        \u001b[36m0.4556\u001b[0m       \u001b[32m0.8655\u001b[0m        \u001b[35m0.3776\u001b[0m  1.5707\n",
            "      4        \u001b[36m0.4016\u001b[0m       \u001b[32m0.8722\u001b[0m        \u001b[35m0.3547\u001b[0m  1.5718\n",
            "      5        \u001b[36m0.3636\u001b[0m       \u001b[32m0.8772\u001b[0m        \u001b[35m0.3305\u001b[0m  1.5927\n",
            "      6        \u001b[36m0.3400\u001b[0m       \u001b[32m0.8803\u001b[0m        \u001b[35m0.3209\u001b[0m  1.5799\n",
            "      7        \u001b[36m0.3190\u001b[0m       \u001b[32m0.8855\u001b[0m        \u001b[35m0.3107\u001b[0m  1.5751\n",
            "      8        \u001b[36m0.2989\u001b[0m       \u001b[32m0.8887\u001b[0m        \u001b[35m0.2944\u001b[0m  1.5706\n",
            "      9        \u001b[36m0.2812\u001b[0m       \u001b[32m0.8915\u001b[0m        \u001b[35m0.2922\u001b[0m  1.5693\n",
            "     10        \u001b[36m0.2686\u001b[0m       \u001b[32m0.8952\u001b[0m        \u001b[35m0.2806\u001b[0m  1.5612\n",
            "     11        \u001b[36m0.2541\u001b[0m       \u001b[32m0.9007\u001b[0m        \u001b[35m0.2704\u001b[0m  1.5617\n",
            "     12        \u001b[36m0.2408\u001b[0m       0.8977        \u001b[35m0.2696\u001b[0m  1.5707\n",
            "     13        \u001b[36m0.2307\u001b[0m       0.9003        \u001b[35m0.2669\u001b[0m  1.5698\n",
            "     14        \u001b[36m0.2181\u001b[0m       \u001b[32m0.9022\u001b[0m        0.2695  1.5815\n",
            "     15        \u001b[36m0.2082\u001b[0m       \u001b[32m0.9030\u001b[0m        0.2673  1.5755\n",
            "     16        \u001b[36m0.1969\u001b[0m       \u001b[32m0.9048\u001b[0m        \u001b[35m0.2657\u001b[0m  1.5924\n",
            "     17        \u001b[36m0.1850\u001b[0m       \u001b[32m0.9062\u001b[0m        0.2667  1.5748\n",
            "     18        \u001b[36m0.1806\u001b[0m       0.9058        0.2788  1.5703\n",
            "     19        \u001b[36m0.1722\u001b[0m       0.9062        0.2707  1.5902\n",
            "     20        \u001b[36m0.1603\u001b[0m       \u001b[32m0.9072\u001b[0m        0.2853  1.5931\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.5, module__num_filters_1=64, module__num_filters_2=64; total time=  32.7s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.8968\u001b[0m       \u001b[32m0.6593\u001b[0m        \u001b[35m1.3486\u001b[0m  1.6057\n",
            "      2        \u001b[36m0.5354\u001b[0m       \u001b[32m0.6987\u001b[0m        \u001b[35m1.0325\u001b[0m  1.5887\n",
            "      3        \u001b[36m0.4491\u001b[0m       \u001b[32m0.7708\u001b[0m        \u001b[35m0.6755\u001b[0m  1.5787\n",
            "      4        \u001b[36m0.3971\u001b[0m       \u001b[32m0.7890\u001b[0m        \u001b[35m0.6255\u001b[0m  1.5641\n",
            "      5        \u001b[36m0.3629\u001b[0m       \u001b[32m0.8055\u001b[0m        \u001b[35m0.5729\u001b[0m  1.5594\n",
            "      6        \u001b[36m0.3333\u001b[0m       \u001b[32m0.8262\u001b[0m        \u001b[35m0.4969\u001b[0m  1.5700\n",
            "      7        \u001b[36m0.3091\u001b[0m       \u001b[32m0.8265\u001b[0m        0.4979  1.5724\n",
            "      8        \u001b[36m0.2941\u001b[0m       \u001b[32m0.8278\u001b[0m        0.4969  1.5631\n",
            "      9        \u001b[36m0.2752\u001b[0m       \u001b[32m0.8490\u001b[0m        \u001b[35m0.4270\u001b[0m  1.5578\n",
            "     10        \u001b[36m0.2614\u001b[0m       0.8425        0.4621  1.5550\n",
            "     11        \u001b[36m0.2487\u001b[0m       \u001b[32m0.8563\u001b[0m        \u001b[35m0.4151\u001b[0m  1.5502\n",
            "     12        \u001b[36m0.2343\u001b[0m       0.8547        0.4323  1.5583\n",
            "     13        \u001b[36m0.2254\u001b[0m       \u001b[32m0.8623\u001b[0m        \u001b[35m0.4040\u001b[0m  1.5676\n",
            "     14        \u001b[36m0.2129\u001b[0m       \u001b[32m0.8637\u001b[0m        0.4157  1.5621\n",
            "     15        \u001b[36m0.2042\u001b[0m       \u001b[32m0.8735\u001b[0m        \u001b[35m0.3821\u001b[0m  1.5706\n",
            "     16        \u001b[36m0.1962\u001b[0m       0.8683        0.3961  1.5570\n",
            "     17        \u001b[36m0.1828\u001b[0m       0.8635        0.4123  1.5789\n",
            "     18        \u001b[36m0.1748\u001b[0m       0.8585        0.4388  1.5568\n",
            "     19        \u001b[36m0.1673\u001b[0m       \u001b[32m0.8785\u001b[0m        \u001b[35m0.3699\u001b[0m  1.5545\n",
            "     20        \u001b[36m0.1593\u001b[0m       0.8692        0.4149  1.5474\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.5, module__num_filters_1=64, module__num_filters_2=64; total time=  32.5s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.9083\u001b[0m       \u001b[32m0.7928\u001b[0m        \u001b[35m0.5483\u001b[0m  1.9314\n",
            "      2        \u001b[36m0.5390\u001b[0m       \u001b[32m0.8440\u001b[0m        \u001b[35m0.4399\u001b[0m  1.9354\n",
            "      3        \u001b[36m0.4556\u001b[0m       \u001b[32m0.8625\u001b[0m        \u001b[35m0.3865\u001b[0m  1.9269\n",
            "      4        \u001b[36m0.4031\u001b[0m       \u001b[32m0.8698\u001b[0m        \u001b[35m0.3657\u001b[0m  1.9407\n",
            "      5        \u001b[36m0.3660\u001b[0m       \u001b[32m0.8785\u001b[0m        \u001b[35m0.3287\u001b[0m  1.9336\n",
            "      6        \u001b[36m0.3363\u001b[0m       \u001b[32m0.8877\u001b[0m        \u001b[35m0.3120\u001b[0m  1.9281\n",
            "      7        \u001b[36m0.3129\u001b[0m       0.8870        \u001b[35m0.3003\u001b[0m  1.9203\n",
            "      8        \u001b[36m0.2958\u001b[0m       \u001b[32m0.8928\u001b[0m        \u001b[35m0.2871\u001b[0m  1.9301\n",
            "      9        \u001b[36m0.2770\u001b[0m       \u001b[32m0.8955\u001b[0m        \u001b[35m0.2842\u001b[0m  1.9336\n",
            "     10        \u001b[36m0.2628\u001b[0m       \u001b[32m0.8967\u001b[0m        \u001b[35m0.2768\u001b[0m  1.9494\n",
            "     11        \u001b[36m0.2466\u001b[0m       \u001b[32m0.8995\u001b[0m        \u001b[35m0.2699\u001b[0m  1.9311\n",
            "     12        \u001b[36m0.2339\u001b[0m       \u001b[32m0.9007\u001b[0m        \u001b[35m0.2635\u001b[0m  1.9169\n",
            "     13        \u001b[36m0.2246\u001b[0m       \u001b[32m0.9017\u001b[0m        0.2670  1.9275\n",
            "     14        \u001b[36m0.2095\u001b[0m       \u001b[32m0.9060\u001b[0m        \u001b[35m0.2614\u001b[0m  1.9187\n",
            "     15        \u001b[36m0.1961\u001b[0m       0.9057        0.2661  1.9351\n",
            "     16        \u001b[36m0.1900\u001b[0m       0.9037        0.2720  1.9566\n",
            "     17        \u001b[36m0.1768\u001b[0m       0.8988        0.2777  1.9357\n",
            "     18        \u001b[36m0.1689\u001b[0m       0.9052        0.2702  1.9357\n",
            "     19        \u001b[36m0.1588\u001b[0m       \u001b[32m0.9092\u001b[0m        \u001b[35m0.2565\u001b[0m  1.9300\n",
            "     20        \u001b[36m0.1469\u001b[0m       0.9055        0.2839  1.9225\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.5, module__num_filters_1=64, module__num_filters_2=128; total time=  39.9s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.8801\u001b[0m       \u001b[32m0.6520\u001b[0m        \u001b[35m1.5783\u001b[0m  1.9244\n",
            "      2        \u001b[36m0.5247\u001b[0m       \u001b[32m0.7167\u001b[0m        \u001b[35m0.8974\u001b[0m  1.9385\n",
            "      3        \u001b[36m0.4342\u001b[0m       \u001b[32m0.7682\u001b[0m        \u001b[35m0.6957\u001b[0m  1.9091\n",
            "      4        \u001b[36m0.3850\u001b[0m       \u001b[32m0.7798\u001b[0m        \u001b[35m0.6516\u001b[0m  1.9063\n",
            "      5        \u001b[36m0.3495\u001b[0m       \u001b[32m0.8007\u001b[0m        \u001b[35m0.5515\u001b[0m  1.9385\n",
            "      6        \u001b[36m0.3230\u001b[0m       \u001b[32m0.8063\u001b[0m        \u001b[35m0.5437\u001b[0m  1.9372\n",
            "      7        \u001b[36m0.2989\u001b[0m       \u001b[32m0.8272\u001b[0m        \u001b[35m0.4842\u001b[0m  1.9366\n",
            "      8        \u001b[36m0.2829\u001b[0m       \u001b[32m0.8358\u001b[0m        \u001b[35m0.4620\u001b[0m  1.9351\n",
            "      9        \u001b[36m0.2670\u001b[0m       \u001b[32m0.8543\u001b[0m        \u001b[35m0.4174\u001b[0m  1.9174\n",
            "     10        \u001b[36m0.2492\u001b[0m       \u001b[32m0.8593\u001b[0m        0.4176  1.9212\n",
            "     11        \u001b[36m0.2374\u001b[0m       0.8590        \u001b[35m0.4163\u001b[0m  1.9315\n",
            "     12        \u001b[36m0.2221\u001b[0m       \u001b[32m0.8673\u001b[0m        \u001b[35m0.3768\u001b[0m  1.9457\n",
            "     13        \u001b[36m0.2125\u001b[0m       0.8660        0.3944  1.9383\n",
            "     14        \u001b[36m0.2009\u001b[0m       \u001b[32m0.8710\u001b[0m        0.3928  1.9343\n",
            "     15        \u001b[36m0.1898\u001b[0m       \u001b[32m0.8718\u001b[0m        0.3973  1.9157\n",
            "     16        \u001b[36m0.1759\u001b[0m       \u001b[32m0.8758\u001b[0m        0.4097  1.9316\n",
            "     17        \u001b[36m0.1708\u001b[0m       0.8695        0.4170  1.9259\n",
            "     18        \u001b[36m0.1590\u001b[0m       \u001b[32m0.8793\u001b[0m        0.3899  1.9395\n",
            "     19        \u001b[36m0.1512\u001b[0m       \u001b[32m0.8852\u001b[0m        \u001b[35m0.3714\u001b[0m  1.9231\n",
            "     20        \u001b[36m0.1436\u001b[0m       0.8723        0.4176  1.9393\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.5, module__num_filters_1=64, module__num_filters_2=128; total time=  39.9s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.7267\u001b[0m       \u001b[32m0.6643\u001b[0m        \u001b[35m0.8771\u001b[0m  1.3226\n",
            "      2        \u001b[36m0.8179\u001b[0m       \u001b[32m0.7363\u001b[0m        \u001b[35m0.7119\u001b[0m  1.3210\n",
            "      3        \u001b[36m0.7197\u001b[0m       \u001b[32m0.7537\u001b[0m        \u001b[35m0.6527\u001b[0m  1.3165\n",
            "      4        \u001b[36m0.6658\u001b[0m       \u001b[32m0.7733\u001b[0m        \u001b[35m0.6037\u001b[0m  1.3236\n",
            "      5        \u001b[36m0.6233\u001b[0m       \u001b[32m0.7943\u001b[0m        \u001b[35m0.5634\u001b[0m  1.3296\n",
            "      6        \u001b[36m0.5914\u001b[0m       \u001b[32m0.8068\u001b[0m        \u001b[35m0.5318\u001b[0m  1.3380\n",
            "      7        \u001b[36m0.5623\u001b[0m       \u001b[32m0.8172\u001b[0m        \u001b[35m0.5117\u001b[0m  1.3229\n",
            "      8        \u001b[36m0.5345\u001b[0m       \u001b[32m0.8253\u001b[0m        \u001b[35m0.4916\u001b[0m  1.3371\n",
            "      9        \u001b[36m0.5165\u001b[0m       \u001b[32m0.8318\u001b[0m        \u001b[35m0.4746\u001b[0m  1.3220\n",
            "     10        \u001b[36m0.4938\u001b[0m       \u001b[32m0.8373\u001b[0m        \u001b[35m0.4639\u001b[0m  1.3265\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.25, module__num_filters_1=32, module__num_filters_2=64; total time=  14.2s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.5407\u001b[0m       \u001b[32m0.4380\u001b[0m        \u001b[35m2.3202\u001b[0m  1.3316\n",
            "      2        \u001b[36m0.8150\u001b[0m       \u001b[32m0.5512\u001b[0m        \u001b[35m1.6608\u001b[0m  1.3150\n",
            "      3        \u001b[36m0.7156\u001b[0m       \u001b[32m0.6327\u001b[0m        \u001b[35m1.3309\u001b[0m  1.3398\n",
            "      4        \u001b[36m0.6567\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m1.1749\u001b[0m  1.3252\n",
            "      5        \u001b[36m0.6148\u001b[0m       \u001b[32m0.6728\u001b[0m        \u001b[35m1.1009\u001b[0m  1.3203\n",
            "      6        \u001b[36m0.5803\u001b[0m       \u001b[32m0.6868\u001b[0m        \u001b[35m0.9910\u001b[0m  1.3294\n",
            "      7        \u001b[36m0.5504\u001b[0m       \u001b[32m0.6897\u001b[0m        \u001b[35m0.9374\u001b[0m  1.3228\n",
            "      8        \u001b[36m0.5249\u001b[0m       \u001b[32m0.7032\u001b[0m        \u001b[35m0.8805\u001b[0m  1.3331\n",
            "      9        \u001b[36m0.5033\u001b[0m       \u001b[32m0.7173\u001b[0m        \u001b[35m0.8238\u001b[0m  1.3302\n",
            "     10        \u001b[36m0.4853\u001b[0m       \u001b[32m0.7290\u001b[0m        \u001b[35m0.7757\u001b[0m  1.3273\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.25, module__num_filters_1=32, module__num_filters_2=64; total time=  14.2s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.5328\u001b[0m       \u001b[32m0.7063\u001b[0m        \u001b[35m0.8496\u001b[0m  1.7696\n",
            "      2        \u001b[36m0.8133\u001b[0m       \u001b[32m0.7183\u001b[0m        \u001b[35m0.7435\u001b[0m  1.7587\n",
            "      3        \u001b[36m0.7083\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6583\u001b[0m  1.7654\n",
            "      4        \u001b[36m0.6502\u001b[0m       \u001b[32m0.7797\u001b[0m        \u001b[35m0.6054\u001b[0m  1.7701\n",
            "      5        \u001b[36m0.6092\u001b[0m       \u001b[32m0.8013\u001b[0m        \u001b[35m0.5554\u001b[0m  1.7551\n",
            "      6        \u001b[36m0.5749\u001b[0m       \u001b[32m0.8063\u001b[0m        \u001b[35m0.5265\u001b[0m  1.7569\n",
            "      7        \u001b[36m0.5483\u001b[0m       \u001b[32m0.8207\u001b[0m        \u001b[35m0.5077\u001b[0m  1.7747\n",
            "      8        \u001b[36m0.5177\u001b[0m       \u001b[32m0.8273\u001b[0m        \u001b[35m0.4883\u001b[0m  1.7600\n",
            "      9        \u001b[36m0.4995\u001b[0m       \u001b[32m0.8367\u001b[0m        \u001b[35m0.4669\u001b[0m  1.7544\n",
            "     10        \u001b[36m0.4832\u001b[0m       \u001b[32m0.8418\u001b[0m        \u001b[35m0.4519\u001b[0m  1.7691\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.25, module__num_filters_1=32, module__num_filters_2=128; total time=  18.7s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.5206\u001b[0m       \u001b[32m0.4558\u001b[0m        \u001b[35m2.1691\u001b[0m  1.7429\n",
            "      2        \u001b[36m0.7973\u001b[0m       \u001b[32m0.5895\u001b[0m        \u001b[35m1.5034\u001b[0m  1.7586\n",
            "      3        \u001b[36m0.6911\u001b[0m       \u001b[32m0.6370\u001b[0m        \u001b[35m1.3871\u001b[0m  1.7550\n",
            "      4        \u001b[36m0.6344\u001b[0m       \u001b[32m0.6685\u001b[0m        \u001b[35m1.0990\u001b[0m  1.7548\n",
            "      5        \u001b[36m0.5935\u001b[0m       \u001b[32m0.6798\u001b[0m        \u001b[35m1.0261\u001b[0m  1.7525\n",
            "      6        \u001b[36m0.5606\u001b[0m       \u001b[32m0.6952\u001b[0m        \u001b[35m0.9199\u001b[0m  1.7665\n",
            "      7        \u001b[36m0.5315\u001b[0m       \u001b[32m0.7142\u001b[0m        \u001b[35m0.8507\u001b[0m  1.7527\n",
            "      8        \u001b[36m0.5065\u001b[0m       \u001b[32m0.7202\u001b[0m        \u001b[35m0.8138\u001b[0m  1.7695\n",
            "      9        \u001b[36m0.4871\u001b[0m       \u001b[32m0.7343\u001b[0m        \u001b[35m0.7617\u001b[0m  1.7727\n",
            "     10        \u001b[36m0.4668\u001b[0m       \u001b[32m0.7392\u001b[0m        \u001b[35m0.7487\u001b[0m  1.7712\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.25, module__num_filters_1=32, module__num_filters_2=128; total time=  18.7s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.5072\u001b[0m       \u001b[32m0.6952\u001b[0m        \u001b[35m0.8491\u001b[0m  1.5905\n",
            "      2        \u001b[36m0.8039\u001b[0m       \u001b[32m0.7262\u001b[0m        \u001b[35m0.7163\u001b[0m  1.5762\n",
            "      3        \u001b[36m0.7038\u001b[0m       \u001b[32m0.7553\u001b[0m        \u001b[35m0.6381\u001b[0m  1.5747\n",
            "      4        \u001b[36m0.6511\u001b[0m       \u001b[32m0.7840\u001b[0m        \u001b[35m0.5940\u001b[0m  1.5671\n",
            "      5        \u001b[36m0.6081\u001b[0m       \u001b[32m0.7913\u001b[0m        \u001b[35m0.5587\u001b[0m  1.5735\n",
            "      6        \u001b[36m0.5747\u001b[0m       \u001b[32m0.8142\u001b[0m        \u001b[35m0.5243\u001b[0m  1.5737\n",
            "      7        \u001b[36m0.5451\u001b[0m       \u001b[32m0.8163\u001b[0m        \u001b[35m0.5106\u001b[0m  1.5686\n",
            "      8        \u001b[36m0.5220\u001b[0m       \u001b[32m0.8272\u001b[0m        \u001b[35m0.4875\u001b[0m  1.5736\n",
            "      9        \u001b[36m0.5006\u001b[0m       \u001b[32m0.8362\u001b[0m        \u001b[35m0.4642\u001b[0m  1.5558\n",
            "     10        \u001b[36m0.4816\u001b[0m       \u001b[32m0.8418\u001b[0m        \u001b[35m0.4534\u001b[0m  1.5636\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.25, module__num_filters_1=64, module__num_filters_2=64; total time=  16.8s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.4472\u001b[0m       \u001b[32m0.4445\u001b[0m        \u001b[35m2.2999\u001b[0m  1.5796\n",
            "      2        \u001b[36m0.8085\u001b[0m       \u001b[32m0.6095\u001b[0m        \u001b[35m1.4678\u001b[0m  1.5665\n",
            "      3        \u001b[36m0.7007\u001b[0m       \u001b[32m0.6412\u001b[0m        \u001b[35m1.2822\u001b[0m  1.5834\n",
            "      4        \u001b[36m0.6479\u001b[0m       \u001b[32m0.6635\u001b[0m        \u001b[35m1.1639\u001b[0m  1.5742\n",
            "      5        \u001b[36m0.6059\u001b[0m       \u001b[32m0.6825\u001b[0m        \u001b[35m1.0460\u001b[0m  1.5884\n",
            "      6        \u001b[36m0.5757\u001b[0m       \u001b[32m0.6960\u001b[0m        \u001b[35m0.9416\u001b[0m  1.5852\n",
            "      7        \u001b[36m0.5461\u001b[0m       \u001b[32m0.6992\u001b[0m        \u001b[35m0.9231\u001b[0m  1.5739\n",
            "      8        \u001b[36m0.5224\u001b[0m       \u001b[32m0.7170\u001b[0m        \u001b[35m0.8255\u001b[0m  1.5719\n",
            "      9        \u001b[36m0.4996\u001b[0m       \u001b[32m0.7293\u001b[0m        \u001b[35m0.7753\u001b[0m  1.5750\n",
            "     10        \u001b[36m0.4838\u001b[0m       \u001b[32m0.7382\u001b[0m        \u001b[35m0.7485\u001b[0m  1.5712\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.25, module__num_filters_1=64, module__num_filters_2=64; total time=  16.9s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.4032\u001b[0m       \u001b[32m0.7123\u001b[0m        \u001b[35m0.8029\u001b[0m  1.9191\n",
            "      2        \u001b[36m0.7714\u001b[0m       \u001b[32m0.7283\u001b[0m        \u001b[35m0.7019\u001b[0m  1.9207\n",
            "      3        \u001b[36m0.6823\u001b[0m       \u001b[32m0.7570\u001b[0m        \u001b[35m0.6307\u001b[0m  1.9190\n",
            "      4        \u001b[36m0.6317\u001b[0m       \u001b[32m0.7825\u001b[0m        \u001b[35m0.5787\u001b[0m  1.9776\n",
            "      5        \u001b[36m0.5875\u001b[0m       \u001b[32m0.8058\u001b[0m        \u001b[35m0.5349\u001b[0m  1.9118\n",
            "      6        \u001b[36m0.5539\u001b[0m       \u001b[32m0.8260\u001b[0m        \u001b[35m0.5067\u001b[0m  1.9326\n",
            "      7        \u001b[36m0.5286\u001b[0m       0.8210        \u001b[35m0.4917\u001b[0m  1.9239\n",
            "      8        \u001b[36m0.5036\u001b[0m       \u001b[32m0.8372\u001b[0m        \u001b[35m0.4705\u001b[0m  1.9438\n",
            "      9        \u001b[36m0.4821\u001b[0m       \u001b[32m0.8450\u001b[0m        \u001b[35m0.4499\u001b[0m  1.9625\n",
            "     10        \u001b[36m0.4664\u001b[0m       \u001b[32m0.8507\u001b[0m        \u001b[35m0.4337\u001b[0m  1.9205\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.25, module__num_filters_1=64, module__num_filters_2=128; total time=  20.5s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.3726\u001b[0m       \u001b[32m0.4538\u001b[0m        \u001b[35m2.1323\u001b[0m  1.9267\n",
            "      2        \u001b[36m0.7874\u001b[0m       \u001b[32m0.5968\u001b[0m        \u001b[35m1.5271\u001b[0m  1.9395\n",
            "      3        \u001b[36m0.6794\u001b[0m       \u001b[32m0.6478\u001b[0m        \u001b[35m1.2730\u001b[0m  1.9151\n",
            "      4        \u001b[36m0.6262\u001b[0m       \u001b[32m0.6717\u001b[0m        \u001b[35m1.0880\u001b[0m  1.9283\n",
            "      5        \u001b[36m0.5837\u001b[0m       \u001b[32m0.6850\u001b[0m        \u001b[35m1.0110\u001b[0m  1.9455\n",
            "      6        \u001b[36m0.5526\u001b[0m       \u001b[32m0.6998\u001b[0m        \u001b[35m0.9001\u001b[0m  1.9354\n",
            "      7        \u001b[36m0.5200\u001b[0m       \u001b[32m0.7185\u001b[0m        \u001b[35m0.8220\u001b[0m  1.9336\n",
            "      8        \u001b[36m0.4993\u001b[0m       \u001b[32m0.7208\u001b[0m        \u001b[35m0.8141\u001b[0m  1.9384\n",
            "      9        \u001b[36m0.4776\u001b[0m       \u001b[32m0.7338\u001b[0m        \u001b[35m0.7710\u001b[0m  1.9292\n",
            "     10        \u001b[36m0.4592\u001b[0m       \u001b[32m0.7463\u001b[0m        \u001b[35m0.7220\u001b[0m  1.9372\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.25, module__num_filters_1=64, module__num_filters_2=128; total time=  20.6s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.5601\u001b[0m       \u001b[32m0.6968\u001b[0m        \u001b[35m0.8623\u001b[0m  1.3289\n",
            "      2        \u001b[36m0.8562\u001b[0m       \u001b[32m0.7268\u001b[0m        \u001b[35m0.7141\u001b[0m  1.3244\n",
            "      3        \u001b[36m0.7505\u001b[0m       \u001b[32m0.7525\u001b[0m        \u001b[35m0.6505\u001b[0m  1.3199\n",
            "      4        \u001b[36m0.6995\u001b[0m       \u001b[32m0.7650\u001b[0m        \u001b[35m0.6196\u001b[0m  1.3242\n",
            "      5        \u001b[36m0.6587\u001b[0m       \u001b[32m0.7727\u001b[0m        \u001b[35m0.5847\u001b[0m  1.3231\n",
            "      6        \u001b[36m0.6270\u001b[0m       \u001b[32m0.7905\u001b[0m        \u001b[35m0.5510\u001b[0m  1.3490\n",
            "      7        \u001b[36m0.5945\u001b[0m       \u001b[32m0.8070\u001b[0m        \u001b[35m0.5243\u001b[0m  1.3274\n",
            "      8        \u001b[36m0.5671\u001b[0m       \u001b[32m0.8117\u001b[0m        \u001b[35m0.4988\u001b[0m  1.3531\n",
            "      9        \u001b[36m0.5498\u001b[0m       \u001b[32m0.8253\u001b[0m        \u001b[35m0.4863\u001b[0m  1.3260\n",
            "     10        \u001b[36m0.5297\u001b[0m       \u001b[32m0.8267\u001b[0m        \u001b[35m0.4703\u001b[0m  1.3193\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.5, module__num_filters_1=32, module__num_filters_2=64; total time=  14.2s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.6197\u001b[0m       \u001b[32m0.4453\u001b[0m        \u001b[35m2.0712\u001b[0m  1.3052\n",
            "      2        \u001b[36m0.8550\u001b[0m       \u001b[32m0.5847\u001b[0m        \u001b[35m1.5508\u001b[0m  1.3153\n",
            "      3        \u001b[36m0.7487\u001b[0m       \u001b[32m0.6402\u001b[0m        \u001b[35m1.2412\u001b[0m  1.3188\n",
            "      4        \u001b[36m0.6922\u001b[0m       \u001b[32m0.6628\u001b[0m        \u001b[35m1.1583\u001b[0m  1.3432\n",
            "      5        \u001b[36m0.6610\u001b[0m       \u001b[32m0.6753\u001b[0m        \u001b[35m1.0516\u001b[0m  1.3145\n",
            "      6        \u001b[36m0.6300\u001b[0m       \u001b[32m0.6807\u001b[0m        \u001b[35m1.0328\u001b[0m  1.3353\n",
            "      7        \u001b[36m0.6077\u001b[0m       \u001b[32m0.7005\u001b[0m        \u001b[35m0.9078\u001b[0m  1.3292\n",
            "      8        \u001b[36m0.5827\u001b[0m       \u001b[32m0.7087\u001b[0m        \u001b[35m0.8642\u001b[0m  1.3210\n",
            "      9        \u001b[36m0.5599\u001b[0m       \u001b[32m0.7222\u001b[0m        \u001b[35m0.8111\u001b[0m  1.3270\n",
            "     10        \u001b[36m0.5366\u001b[0m       \u001b[32m0.7295\u001b[0m        \u001b[35m0.7939\u001b[0m  1.3302\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.5, module__num_filters_1=32, module__num_filters_2=64; total time=  14.2s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.5213\u001b[0m       \u001b[32m0.6995\u001b[0m        \u001b[35m0.8610\u001b[0m  1.7546\n",
            "      2        \u001b[36m0.8351\u001b[0m       \u001b[32m0.7337\u001b[0m        \u001b[35m0.7175\u001b[0m  1.7649\n",
            "      3        \u001b[36m0.7358\u001b[0m       \u001b[32m0.7575\u001b[0m        \u001b[35m0.6493\u001b[0m  1.7707\n",
            "      4        \u001b[36m0.6788\u001b[0m       \u001b[32m0.7727\u001b[0m        \u001b[35m0.5980\u001b[0m  1.7728\n",
            "      5        \u001b[36m0.6373\u001b[0m       \u001b[32m0.7907\u001b[0m        \u001b[35m0.5647\u001b[0m  1.7554\n",
            "      6        \u001b[36m0.6032\u001b[0m       \u001b[32m0.7928\u001b[0m        \u001b[35m0.5302\u001b[0m  1.7630\n",
            "      7        \u001b[36m0.5759\u001b[0m       \u001b[32m0.8208\u001b[0m        \u001b[35m0.5052\u001b[0m  1.7691\n",
            "      8        \u001b[36m0.5524\u001b[0m       \u001b[32m0.8220\u001b[0m        \u001b[35m0.4985\u001b[0m  1.7717\n",
            "      9        \u001b[36m0.5267\u001b[0m       \u001b[32m0.8343\u001b[0m        \u001b[35m0.4703\u001b[0m  1.7785\n",
            "     10        \u001b[36m0.5077\u001b[0m       \u001b[32m0.8383\u001b[0m        \u001b[35m0.4635\u001b[0m  1.7606\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.5, module__num_filters_1=32, module__num_filters_2=128; total time=  18.8s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.5500\u001b[0m       \u001b[32m0.4395\u001b[0m        \u001b[35m2.1062\u001b[0m  1.7478\n",
            "      2        \u001b[36m0.8496\u001b[0m       \u001b[32m0.5917\u001b[0m        \u001b[35m1.4319\u001b[0m  1.7415\n",
            "      3        \u001b[36m0.7304\u001b[0m       \u001b[32m0.6485\u001b[0m        \u001b[35m1.2348\u001b[0m  1.7495\n",
            "      4        \u001b[36m0.6695\u001b[0m       \u001b[32m0.6753\u001b[0m        \u001b[35m1.0806\u001b[0m  1.7584\n",
            "      5        \u001b[36m0.6305\u001b[0m       \u001b[32m0.6835\u001b[0m        \u001b[35m1.0195\u001b[0m  1.7789\n",
            "      6        \u001b[36m0.5962\u001b[0m       \u001b[32m0.7042\u001b[0m        \u001b[35m0.8953\u001b[0m  1.7645\n",
            "      7        \u001b[36m0.5703\u001b[0m       \u001b[32m0.7122\u001b[0m        \u001b[35m0.8463\u001b[0m  1.7790\n",
            "      8        \u001b[36m0.5448\u001b[0m       \u001b[32m0.7232\u001b[0m        \u001b[35m0.8032\u001b[0m  1.7721\n",
            "      9        \u001b[36m0.5253\u001b[0m       \u001b[32m0.7398\u001b[0m        \u001b[35m0.7374\u001b[0m  1.7631\n",
            "     10        \u001b[36m0.5072\u001b[0m       \u001b[32m0.7412\u001b[0m        0.7396  1.7717\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.5, module__num_filters_1=32, module__num_filters_2=128; total time=  18.7s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.4376\u001b[0m       \u001b[32m0.6820\u001b[0m        \u001b[35m0.8634\u001b[0m  1.5813\n",
            "      2        \u001b[36m0.8335\u001b[0m       \u001b[32m0.7252\u001b[0m        \u001b[35m0.7169\u001b[0m  1.5518\n",
            "      3        \u001b[36m0.7372\u001b[0m       \u001b[32m0.7475\u001b[0m        \u001b[35m0.6528\u001b[0m  1.5927\n",
            "      4        \u001b[36m0.6851\u001b[0m       \u001b[32m0.7632\u001b[0m        \u001b[35m0.6172\u001b[0m  1.5934\n",
            "      5        \u001b[36m0.6481\u001b[0m       \u001b[32m0.7827\u001b[0m        \u001b[35m0.5780\u001b[0m  1.5859\n",
            "      6        \u001b[36m0.6103\u001b[0m       \u001b[32m0.7908\u001b[0m        \u001b[35m0.5503\u001b[0m  1.5625\n",
            "      7        \u001b[36m0.5871\u001b[0m       \u001b[32m0.8028\u001b[0m        \u001b[35m0.5237\u001b[0m  1.5653\n",
            "      8        \u001b[36m0.5611\u001b[0m       \u001b[32m0.8167\u001b[0m        \u001b[35m0.5023\u001b[0m  1.5857\n",
            "      9        \u001b[36m0.5413\u001b[0m       \u001b[32m0.8212\u001b[0m        \u001b[35m0.4884\u001b[0m  1.5702\n",
            "     10        \u001b[36m0.5184\u001b[0m       \u001b[32m0.8377\u001b[0m        \u001b[35m0.4649\u001b[0m  1.5729\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.5, module__num_filters_1=64, module__num_filters_2=64; total time=  16.8s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.4715\u001b[0m       \u001b[32m0.4613\u001b[0m        \u001b[35m1.9839\u001b[0m  1.5580\n",
            "      2        \u001b[36m0.8267\u001b[0m       \u001b[32m0.5900\u001b[0m        \u001b[35m1.4820\u001b[0m  1.5571\n",
            "      3        \u001b[36m0.7229\u001b[0m       \u001b[32m0.6415\u001b[0m        \u001b[35m1.2784\u001b[0m  1.5483\n",
            "      4        \u001b[36m0.6644\u001b[0m       \u001b[32m0.6758\u001b[0m        \u001b[35m1.0594\u001b[0m  1.5787\n",
            "      5        \u001b[36m0.6276\u001b[0m       \u001b[32m0.6890\u001b[0m        \u001b[35m0.9847\u001b[0m  1.5685\n",
            "      6        \u001b[36m0.5935\u001b[0m       \u001b[32m0.7045\u001b[0m        \u001b[35m0.8817\u001b[0m  1.5579\n",
            "      7        \u001b[36m0.5671\u001b[0m       \u001b[32m0.7205\u001b[0m        \u001b[35m0.8303\u001b[0m  1.5597\n",
            "      8        \u001b[36m0.5461\u001b[0m       \u001b[32m0.7240\u001b[0m        \u001b[35m0.7879\u001b[0m  1.5654\n",
            "      9        \u001b[36m0.5270\u001b[0m       \u001b[32m0.7292\u001b[0m        \u001b[35m0.7686\u001b[0m  1.5535\n",
            "     10        \u001b[36m0.5065\u001b[0m       \u001b[32m0.7503\u001b[0m        \u001b[35m0.7131\u001b[0m  1.5503\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.5, module__num_filters_1=64, module__num_filters_2=64; total time=  16.7s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.4480\u001b[0m       \u001b[32m0.7060\u001b[0m        \u001b[35m0.8535\u001b[0m  1.9419\n",
            "      2        \u001b[36m0.8403\u001b[0m       \u001b[32m0.7227\u001b[0m        \u001b[35m0.7282\u001b[0m  1.9344\n",
            "      3        \u001b[36m0.7311\u001b[0m       \u001b[32m0.7373\u001b[0m        \u001b[35m0.6744\u001b[0m  1.9282\n",
            "      4        \u001b[36m0.6759\u001b[0m       \u001b[32m0.7670\u001b[0m        \u001b[35m0.6015\u001b[0m  1.9211\n",
            "      5        \u001b[36m0.6338\u001b[0m       \u001b[32m0.7830\u001b[0m        \u001b[35m0.5615\u001b[0m  1.9219\n",
            "      6        \u001b[36m0.6008\u001b[0m       \u001b[32m0.8043\u001b[0m        \u001b[35m0.5263\u001b[0m  1.9173\n",
            "      7        \u001b[36m0.5697\u001b[0m       \u001b[32m0.8183\u001b[0m        \u001b[35m0.5025\u001b[0m  1.9266\n",
            "      8        \u001b[36m0.5475\u001b[0m       \u001b[32m0.8287\u001b[0m        \u001b[35m0.4871\u001b[0m  1.9202\n",
            "      9        \u001b[36m0.5270\u001b[0m       \u001b[32m0.8340\u001b[0m        \u001b[35m0.4682\u001b[0m  1.9208\n",
            "     10        \u001b[36m0.5068\u001b[0m       \u001b[32m0.8405\u001b[0m        \u001b[35m0.4559\u001b[0m  1.9210\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.5, module__num_filters_1=64, module__num_filters_2=128; total time=  20.5s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.4221\u001b[0m       \u001b[32m0.4487\u001b[0m        \u001b[35m2.0557\u001b[0m  1.9268\n",
            "      2        \u001b[36m0.8287\u001b[0m       \u001b[32m0.5903\u001b[0m        \u001b[35m1.4705\u001b[0m  1.9205\n",
            "      3        \u001b[36m0.7272\u001b[0m       \u001b[32m0.6508\u001b[0m        \u001b[35m1.2011\u001b[0m  1.9230\n",
            "      4        \u001b[36m0.6691\u001b[0m       \u001b[32m0.6708\u001b[0m        \u001b[35m1.0963\u001b[0m  1.9089\n",
            "      5        \u001b[36m0.6267\u001b[0m       \u001b[32m0.6858\u001b[0m        \u001b[35m0.9810\u001b[0m  1.9099\n",
            "      6        \u001b[36m0.5979\u001b[0m       \u001b[32m0.6997\u001b[0m        \u001b[35m0.9074\u001b[0m  1.9097\n",
            "      7        \u001b[36m0.5686\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.8128\u001b[0m  1.9276\n",
            "      8        \u001b[36m0.5464\u001b[0m       \u001b[32m0.7268\u001b[0m        \u001b[35m0.7675\u001b[0m  1.9293\n",
            "      9        \u001b[36m0.5274\u001b[0m       \u001b[32m0.7395\u001b[0m        \u001b[35m0.7368\u001b[0m  1.9244\n",
            "     10        \u001b[36m0.5054\u001b[0m       \u001b[32m0.7457\u001b[0m        \u001b[35m0.7158\u001b[0m  1.9292\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.5, module__num_filters_1=64, module__num_filters_2=128; total time=  20.4s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.4803\u001b[0m       \u001b[32m0.7068\u001b[0m        \u001b[35m0.8449\u001b[0m  1.3285\n",
            "      2        \u001b[36m0.8131\u001b[0m       0.6987        \u001b[35m0.7533\u001b[0m  1.2990\n",
            "      3        \u001b[36m0.7047\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.6511\u001b[0m  1.3128\n",
            "      4        \u001b[36m0.6483\u001b[0m       \u001b[32m0.7800\u001b[0m        \u001b[35m0.5845\u001b[0m  1.3140\n",
            "      5        \u001b[36m0.6039\u001b[0m       \u001b[32m0.7967\u001b[0m        \u001b[35m0.5560\u001b[0m  1.3206\n",
            "      6        \u001b[36m0.5691\u001b[0m       \u001b[32m0.8165\u001b[0m        \u001b[35m0.5148\u001b[0m  1.3311\n",
            "      7        \u001b[36m0.5428\u001b[0m       \u001b[32m0.8228\u001b[0m        \u001b[35m0.5013\u001b[0m  1.3310\n",
            "      8        \u001b[36m0.5204\u001b[0m       \u001b[32m0.8252\u001b[0m        \u001b[35m0.4867\u001b[0m  1.3290\n",
            "      9        \u001b[36m0.5027\u001b[0m       \u001b[32m0.8387\u001b[0m        \u001b[35m0.4618\u001b[0m  1.3399\n",
            "     10        \u001b[36m0.4833\u001b[0m       \u001b[32m0.8400\u001b[0m        \u001b[35m0.4524\u001b[0m  1.3302\n",
            "     11        \u001b[36m0.4666\u001b[0m       \u001b[32m0.8468\u001b[0m        \u001b[35m0.4385\u001b[0m  1.3160\n",
            "     12        \u001b[36m0.4527\u001b[0m       0.8467        \u001b[35m0.4310\u001b[0m  1.3165\n",
            "     13        \u001b[36m0.4416\u001b[0m       \u001b[32m0.8523\u001b[0m        \u001b[35m0.4217\u001b[0m  1.3073\n",
            "     14        \u001b[36m0.4324\u001b[0m       \u001b[32m0.8603\u001b[0m        \u001b[35m0.4035\u001b[0m  1.3072\n",
            "     15        \u001b[36m0.4204\u001b[0m       \u001b[32m0.8620\u001b[0m        \u001b[35m0.3995\u001b[0m  1.3220\n",
            "     16        \u001b[36m0.4125\u001b[0m       0.8617        \u001b[35m0.3931\u001b[0m  1.3084\n",
            "     17        \u001b[36m0.4037\u001b[0m       \u001b[32m0.8648\u001b[0m        \u001b[35m0.3862\u001b[0m  1.3394\n",
            "     18        \u001b[36m0.3957\u001b[0m       \u001b[32m0.8673\u001b[0m        \u001b[35m0.3813\u001b[0m  1.3179\n",
            "     19        \u001b[36m0.3886\u001b[0m       \u001b[32m0.8705\u001b[0m        \u001b[35m0.3741\u001b[0m  1.3268\n",
            "     20        \u001b[36m0.3823\u001b[0m       \u001b[32m0.8740\u001b[0m        \u001b[35m0.3691\u001b[0m  1.3225\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.25, module__num_filters_1=32, module__num_filters_2=64; total time=  27.4s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.6135\u001b[0m       \u001b[32m0.4287\u001b[0m        \u001b[35m2.2892\u001b[0m  1.3045\n",
            "      2        \u001b[36m0.8564\u001b[0m       \u001b[32m0.5472\u001b[0m        \u001b[35m1.5982\u001b[0m  1.3144\n",
            "      3        \u001b[36m0.7346\u001b[0m       \u001b[32m0.6235\u001b[0m        \u001b[35m1.4062\u001b[0m  1.3184\n",
            "      4        \u001b[36m0.6639\u001b[0m       \u001b[32m0.6612\u001b[0m        \u001b[35m1.1696\u001b[0m  1.3323\n",
            "      5        \u001b[36m0.6173\u001b[0m       \u001b[32m0.6743\u001b[0m        \u001b[35m1.0614\u001b[0m  1.3193\n",
            "      6        \u001b[36m0.5810\u001b[0m       \u001b[32m0.6900\u001b[0m        \u001b[35m0.9946\u001b[0m  1.3292\n",
            "      7        \u001b[36m0.5492\u001b[0m       \u001b[32m0.7077\u001b[0m        \u001b[35m0.8831\u001b[0m  1.3303\n",
            "      8        \u001b[36m0.5253\u001b[0m       \u001b[32m0.7125\u001b[0m        \u001b[35m0.8499\u001b[0m  1.3314\n",
            "      9        \u001b[36m0.5012\u001b[0m       \u001b[32m0.7177\u001b[0m        \u001b[35m0.8358\u001b[0m  1.3246\n",
            "     10        \u001b[36m0.4834\u001b[0m       \u001b[32m0.7368\u001b[0m        \u001b[35m0.7533\u001b[0m  1.3198\n",
            "     11        \u001b[36m0.4673\u001b[0m       \u001b[32m0.7432\u001b[0m        \u001b[35m0.7400\u001b[0m  1.3138\n",
            "     12        \u001b[36m0.4523\u001b[0m       \u001b[32m0.7532\u001b[0m        \u001b[35m0.6915\u001b[0m  1.3318\n",
            "     13        \u001b[36m0.4403\u001b[0m       \u001b[32m0.7598\u001b[0m        \u001b[35m0.6638\u001b[0m  1.3212\n",
            "     14        \u001b[36m0.4255\u001b[0m       \u001b[32m0.7680\u001b[0m        \u001b[35m0.6410\u001b[0m  1.3071\n",
            "     15        \u001b[36m0.4145\u001b[0m       \u001b[32m0.7810\u001b[0m        \u001b[35m0.6157\u001b[0m  1.3248\n",
            "     16        \u001b[36m0.4064\u001b[0m       \u001b[32m0.7818\u001b[0m        \u001b[35m0.6034\u001b[0m  1.3233\n",
            "     17        \u001b[36m0.3960\u001b[0m       \u001b[32m0.7858\u001b[0m        \u001b[35m0.5942\u001b[0m  1.3170\n",
            "     18        \u001b[36m0.3862\u001b[0m       \u001b[32m0.7902\u001b[0m        \u001b[35m0.5895\u001b[0m  1.3068\n",
            "     19        \u001b[36m0.3806\u001b[0m       0.7900        \u001b[35m0.5806\u001b[0m  1.3277\n",
            "     20        \u001b[36m0.3768\u001b[0m       \u001b[32m0.7922\u001b[0m        \u001b[35m0.5616\u001b[0m  1.3370\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.25, module__num_filters_1=32, module__num_filters_2=64; total time=  27.5s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.4461\u001b[0m       \u001b[32m0.6992\u001b[0m        \u001b[35m0.8377\u001b[0m  1.7480\n",
            "      2        \u001b[36m0.7876\u001b[0m       \u001b[32m0.7220\u001b[0m        \u001b[35m0.7233\u001b[0m  1.7587\n",
            "      3        \u001b[36m0.6920\u001b[0m       \u001b[32m0.7662\u001b[0m        \u001b[35m0.6385\u001b[0m  1.7725\n",
            "      4        \u001b[36m0.6372\u001b[0m       \u001b[32m0.7887\u001b[0m        \u001b[35m0.5784\u001b[0m  1.7627\n",
            "      5        \u001b[36m0.5917\u001b[0m       \u001b[32m0.8080\u001b[0m        \u001b[35m0.5452\u001b[0m  1.7641\n",
            "      6        \u001b[36m0.5572\u001b[0m       \u001b[32m0.8170\u001b[0m        \u001b[35m0.5203\u001b[0m  1.7602\n",
            "      7        \u001b[36m0.5273\u001b[0m       \u001b[32m0.8270\u001b[0m        \u001b[35m0.4869\u001b[0m  1.7687\n",
            "      8        \u001b[36m0.5039\u001b[0m       \u001b[32m0.8373\u001b[0m        \u001b[35m0.4671\u001b[0m  1.7566\n",
            "      9        \u001b[36m0.4835\u001b[0m       \u001b[32m0.8438\u001b[0m        \u001b[35m0.4484\u001b[0m  1.7646\n",
            "     10        \u001b[36m0.4637\u001b[0m       \u001b[32m0.8478\u001b[0m        \u001b[35m0.4343\u001b[0m  1.7647\n",
            "     11        \u001b[36m0.4488\u001b[0m       \u001b[32m0.8557\u001b[0m        \u001b[35m0.4172\u001b[0m  1.7488\n",
            "     12        \u001b[36m0.4358\u001b[0m       \u001b[32m0.8592\u001b[0m        \u001b[35m0.4077\u001b[0m  1.7603\n",
            "     13        \u001b[36m0.4243\u001b[0m       \u001b[32m0.8593\u001b[0m        \u001b[35m0.3971\u001b[0m  1.7565\n",
            "     14        \u001b[36m0.4138\u001b[0m       \u001b[32m0.8648\u001b[0m        \u001b[35m0.3886\u001b[0m  1.7587\n",
            "     15        \u001b[36m0.4047\u001b[0m       \u001b[32m0.8687\u001b[0m        \u001b[35m0.3810\u001b[0m  1.7589\n",
            "     16        \u001b[36m0.3955\u001b[0m       \u001b[32m0.8695\u001b[0m        \u001b[35m0.3724\u001b[0m  1.7572\n",
            "     17        \u001b[36m0.3854\u001b[0m       \u001b[32m0.8713\u001b[0m        \u001b[35m0.3696\u001b[0m  1.7537\n",
            "     18        \u001b[36m0.3802\u001b[0m       \u001b[32m0.8745\u001b[0m        \u001b[35m0.3620\u001b[0m  1.7518\n",
            "     19        \u001b[36m0.3732\u001b[0m       0.8713        \u001b[35m0.3601\u001b[0m  1.7489\n",
            "     20        \u001b[36m0.3650\u001b[0m       \u001b[32m0.8795\u001b[0m        \u001b[35m0.3543\u001b[0m  1.7552\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.25, module__num_filters_1=32, module__num_filters_2=128; total time=  36.3s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.5190\u001b[0m       \u001b[32m0.4382\u001b[0m        \u001b[35m2.3935\u001b[0m  1.7634\n",
            "      2        \u001b[36m0.8215\u001b[0m       \u001b[32m0.5758\u001b[0m        \u001b[35m1.6753\u001b[0m  1.7452\n",
            "      3        \u001b[36m0.7130\u001b[0m       \u001b[32m0.6372\u001b[0m        \u001b[35m1.3233\u001b[0m  1.7567\n",
            "      4        \u001b[36m0.6534\u001b[0m       \u001b[32m0.6662\u001b[0m        \u001b[35m1.1591\u001b[0m  1.7586\n",
            "      5        \u001b[36m0.6107\u001b[0m       \u001b[32m0.6812\u001b[0m        \u001b[35m1.0399\u001b[0m  1.7596\n",
            "      6        \u001b[36m0.5771\u001b[0m       \u001b[32m0.6942\u001b[0m        \u001b[35m0.9572\u001b[0m  1.7566\n",
            "      7        \u001b[36m0.5475\u001b[0m       \u001b[32m0.6992\u001b[0m        \u001b[35m0.9483\u001b[0m  1.7720\n",
            "      8        \u001b[36m0.5231\u001b[0m       \u001b[32m0.7115\u001b[0m        \u001b[35m0.8676\u001b[0m  1.7645\n",
            "      9        \u001b[36m0.5027\u001b[0m       \u001b[32m0.7168\u001b[0m        \u001b[35m0.8413\u001b[0m  1.7641\n",
            "     10        \u001b[36m0.4824\u001b[0m       \u001b[32m0.7417\u001b[0m        \u001b[35m0.7424\u001b[0m  1.7630\n",
            "     11        \u001b[36m0.4677\u001b[0m       0.7403        \u001b[35m0.7379\u001b[0m  1.7501\n",
            "     12        \u001b[36m0.4500\u001b[0m       \u001b[32m0.7617\u001b[0m        \u001b[35m0.6616\u001b[0m  1.7499\n",
            "     13        \u001b[36m0.4386\u001b[0m       0.7583        0.6821  1.7685\n",
            "     14        \u001b[36m0.4243\u001b[0m       \u001b[32m0.7707\u001b[0m        \u001b[35m0.6432\u001b[0m  1.7646\n",
            "     15        \u001b[36m0.4134\u001b[0m       \u001b[32m0.7827\u001b[0m        \u001b[35m0.6136\u001b[0m  1.7562\n",
            "     16        \u001b[36m0.4049\u001b[0m       \u001b[32m0.7847\u001b[0m        \u001b[35m0.5955\u001b[0m  1.7631\n",
            "     17        \u001b[36m0.3964\u001b[0m       0.7813        0.6043  1.7431\n",
            "     18        \u001b[36m0.3877\u001b[0m       \u001b[32m0.7908\u001b[0m        \u001b[35m0.5711\u001b[0m  1.7458\n",
            "     19        \u001b[36m0.3830\u001b[0m       \u001b[32m0.7982\u001b[0m        \u001b[35m0.5505\u001b[0m  1.7482\n",
            "     20        \u001b[36m0.3731\u001b[0m       0.7912        0.5716  1.7581\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.25, module__num_filters_1=32, module__num_filters_2=128; total time=  36.3s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.3926\u001b[0m       \u001b[32m0.6980\u001b[0m        \u001b[35m0.8308\u001b[0m  1.5643\n",
            "      2        \u001b[36m0.7856\u001b[0m       \u001b[32m0.7367\u001b[0m        \u001b[35m0.7020\u001b[0m  1.5746\n",
            "      3        \u001b[36m0.6941\u001b[0m       \u001b[32m0.7670\u001b[0m        \u001b[35m0.6283\u001b[0m  1.5661\n",
            "      4        \u001b[36m0.6385\u001b[0m       \u001b[32m0.7925\u001b[0m        \u001b[35m0.5774\u001b[0m  1.5623\n",
            "      5        \u001b[36m0.5957\u001b[0m       \u001b[32m0.8037\u001b[0m        \u001b[35m0.5478\u001b[0m  1.5637\n",
            "      6        \u001b[36m0.5637\u001b[0m       \u001b[32m0.8185\u001b[0m        \u001b[35m0.5127\u001b[0m  1.5693\n",
            "      7        \u001b[36m0.5356\u001b[0m       \u001b[32m0.8272\u001b[0m        \u001b[35m0.4961\u001b[0m  1.5540\n",
            "      8        \u001b[36m0.5114\u001b[0m       \u001b[32m0.8353\u001b[0m        \u001b[35m0.4688\u001b[0m  1.5457\n",
            "      9        \u001b[36m0.4882\u001b[0m       \u001b[32m0.8407\u001b[0m        \u001b[35m0.4553\u001b[0m  1.5639\n",
            "     10        \u001b[36m0.4711\u001b[0m       \u001b[32m0.8488\u001b[0m        \u001b[35m0.4398\u001b[0m  1.5857\n",
            "     11        \u001b[36m0.4554\u001b[0m       0.8482        \u001b[35m0.4322\u001b[0m  1.5546\n",
            "     12        \u001b[36m0.4411\u001b[0m       \u001b[32m0.8572\u001b[0m        \u001b[35m0.4134\u001b[0m  1.5489\n",
            "     13        \u001b[36m0.4275\u001b[0m       \u001b[32m0.8622\u001b[0m        \u001b[35m0.4036\u001b[0m  1.5585\n",
            "     14        \u001b[36m0.4214\u001b[0m       \u001b[32m0.8630\u001b[0m        \u001b[35m0.3974\u001b[0m  1.5599\n",
            "     15        \u001b[36m0.4073\u001b[0m       \u001b[32m0.8648\u001b[0m        \u001b[35m0.3863\u001b[0m  1.5574\n",
            "     16        \u001b[36m0.3997\u001b[0m       \u001b[32m0.8692\u001b[0m        \u001b[35m0.3779\u001b[0m  1.5474\n",
            "     17        \u001b[36m0.3912\u001b[0m       \u001b[32m0.8693\u001b[0m        \u001b[35m0.3746\u001b[0m  1.5589\n",
            "     18        \u001b[36m0.3833\u001b[0m       \u001b[32m0.8698\u001b[0m        \u001b[35m0.3695\u001b[0m  1.5603\n",
            "     19        \u001b[36m0.3768\u001b[0m       \u001b[32m0.8722\u001b[0m        \u001b[35m0.3665\u001b[0m  1.5553\n",
            "     20        \u001b[36m0.3688\u001b[0m       \u001b[32m0.8728\u001b[0m        \u001b[35m0.3605\u001b[0m  1.5866\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.25, module__num_filters_1=64, module__num_filters_2=64; total time=  32.4s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.4181\u001b[0m       \u001b[32m0.4272\u001b[0m        \u001b[35m2.4537\u001b[0m  1.5687\n",
            "      2        \u001b[36m0.8012\u001b[0m       \u001b[32m0.5772\u001b[0m        \u001b[35m1.5476\u001b[0m  1.5624\n",
            "      3        \u001b[36m0.6945\u001b[0m       \u001b[32m0.6450\u001b[0m        \u001b[35m1.2547\u001b[0m  1.5729\n",
            "      4        \u001b[36m0.6366\u001b[0m       \u001b[32m0.6622\u001b[0m        \u001b[35m1.0987\u001b[0m  1.5609\n",
            "      5        \u001b[36m0.5987\u001b[0m       \u001b[32m0.6758\u001b[0m        \u001b[35m1.0394\u001b[0m  1.5577\n",
            "      6        \u001b[36m0.5654\u001b[0m       \u001b[32m0.6908\u001b[0m        \u001b[35m0.9452\u001b[0m  1.5544\n",
            "      7        \u001b[36m0.5384\u001b[0m       \u001b[32m0.7065\u001b[0m        \u001b[35m0.8732\u001b[0m  1.5680\n",
            "      8        \u001b[36m0.5142\u001b[0m       0.7007        0.8919  1.5540\n",
            "      9        \u001b[36m0.4938\u001b[0m       \u001b[32m0.7198\u001b[0m        \u001b[35m0.8081\u001b[0m  1.5665\n",
            "     10        \u001b[36m0.4762\u001b[0m       \u001b[32m0.7350\u001b[0m        \u001b[35m0.7636\u001b[0m  1.5623\n",
            "     11        \u001b[36m0.4597\u001b[0m       \u001b[32m0.7420\u001b[0m        \u001b[35m0.7328\u001b[0m  1.5777\n",
            "     12        \u001b[36m0.4466\u001b[0m       \u001b[32m0.7522\u001b[0m        \u001b[35m0.7009\u001b[0m  1.5552\n",
            "     13        \u001b[36m0.4345\u001b[0m       \u001b[32m0.7615\u001b[0m        \u001b[35m0.6804\u001b[0m  1.5579\n",
            "     14        \u001b[36m0.4226\u001b[0m       \u001b[32m0.7778\u001b[0m        \u001b[35m0.6381\u001b[0m  1.5726\n",
            "     15        \u001b[36m0.4126\u001b[0m       0.7733        0.6382  1.5619\n",
            "     16        \u001b[36m0.4026\u001b[0m       \u001b[32m0.7822\u001b[0m        \u001b[35m0.6076\u001b[0m  1.5626\n",
            "     17        \u001b[36m0.3933\u001b[0m       \u001b[32m0.7848\u001b[0m        0.6117  1.5544\n",
            "     18        \u001b[36m0.3892\u001b[0m       \u001b[32m0.7910\u001b[0m        \u001b[35m0.5874\u001b[0m  1.5543\n",
            "     19        \u001b[36m0.3818\u001b[0m       \u001b[32m0.7937\u001b[0m        \u001b[35m0.5723\u001b[0m  1.5725\n",
            "     20        \u001b[36m0.3737\u001b[0m       \u001b[32m0.7938\u001b[0m        \u001b[35m0.5718\u001b[0m  1.5629\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.25, module__num_filters_1=64, module__num_filters_2=64; total time=  32.4s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.3764\u001b[0m       \u001b[32m0.6800\u001b[0m        \u001b[35m0.8482\u001b[0m  1.9279\n",
            "      2        \u001b[36m0.7930\u001b[0m       \u001b[32m0.7018\u001b[0m        \u001b[35m0.7535\u001b[0m  1.9243\n",
            "      3        \u001b[36m0.7028\u001b[0m       \u001b[32m0.7605\u001b[0m        \u001b[35m0.6424\u001b[0m  1.9175\n",
            "      4        \u001b[36m0.6487\u001b[0m       \u001b[32m0.7697\u001b[0m        \u001b[35m0.6103\u001b[0m  1.9213\n",
            "      5        \u001b[36m0.6082\u001b[0m       \u001b[32m0.7930\u001b[0m        \u001b[35m0.5589\u001b[0m  1.9311\n",
            "      6        \u001b[36m0.5773\u001b[0m       \u001b[32m0.8062\u001b[0m        \u001b[35m0.5288\u001b[0m  1.9256\n",
            "      7        \u001b[36m0.5449\u001b[0m       \u001b[32m0.8145\u001b[0m        \u001b[35m0.5212\u001b[0m  1.9254\n",
            "      8        \u001b[36m0.5197\u001b[0m       \u001b[32m0.8290\u001b[0m        \u001b[35m0.4778\u001b[0m  1.9231\n",
            "      9        \u001b[36m0.4984\u001b[0m       \u001b[32m0.8335\u001b[0m        \u001b[35m0.4696\u001b[0m  1.9249\n",
            "     10        \u001b[36m0.4769\u001b[0m       \u001b[32m0.8390\u001b[0m        \u001b[35m0.4524\u001b[0m  1.9147\n",
            "     11        \u001b[36m0.4646\u001b[0m       \u001b[32m0.8497\u001b[0m        \u001b[35m0.4353\u001b[0m  1.9149\n",
            "     12        \u001b[36m0.4456\u001b[0m       \u001b[32m0.8523\u001b[0m        \u001b[35m0.4238\u001b[0m  1.9164\n",
            "     13        \u001b[36m0.4357\u001b[0m       \u001b[32m0.8605\u001b[0m        \u001b[35m0.4095\u001b[0m  1.9117\n",
            "     14        \u001b[36m0.4254\u001b[0m       \u001b[32m0.8622\u001b[0m        \u001b[35m0.4016\u001b[0m  1.9330\n",
            "     15        \u001b[36m0.4128\u001b[0m       \u001b[32m0.8673\u001b[0m        \u001b[35m0.3886\u001b[0m  1.9289\n",
            "     16        \u001b[36m0.4030\u001b[0m       0.8668        \u001b[35m0.3834\u001b[0m  1.9385\n",
            "     17        \u001b[36m0.3934\u001b[0m       \u001b[32m0.8693\u001b[0m        \u001b[35m0.3766\u001b[0m  1.9375\n",
            "     18        \u001b[36m0.3854\u001b[0m       \u001b[32m0.8708\u001b[0m        \u001b[35m0.3709\u001b[0m  1.9233\n",
            "     19        \u001b[36m0.3796\u001b[0m       \u001b[32m0.8715\u001b[0m        \u001b[35m0.3654\u001b[0m  1.9299\n",
            "     20        \u001b[36m0.3706\u001b[0m       \u001b[32m0.8720\u001b[0m        \u001b[35m0.3648\u001b[0m  1.9111\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.25, module__num_filters_1=64, module__num_filters_2=128; total time=  39.8s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.3500\u001b[0m       \u001b[32m0.4640\u001b[0m        \u001b[35m2.2431\u001b[0m  1.9390\n",
            "      2        \u001b[36m0.7877\u001b[0m       \u001b[32m0.6070\u001b[0m        \u001b[35m1.5135\u001b[0m  1.9301\n",
            "      3        \u001b[36m0.6778\u001b[0m       \u001b[32m0.6508\u001b[0m        \u001b[35m1.2820\u001b[0m  1.9366\n",
            "      4        \u001b[36m0.6242\u001b[0m       \u001b[32m0.6688\u001b[0m        \u001b[35m1.1424\u001b[0m  1.9115\n",
            "      5        \u001b[36m0.5831\u001b[0m       \u001b[32m0.6820\u001b[0m        \u001b[35m1.0258\u001b[0m  1.9367\n",
            "      6        \u001b[36m0.5499\u001b[0m       \u001b[32m0.6872\u001b[0m        \u001b[35m0.9836\u001b[0m  1.9192\n",
            "      7        \u001b[36m0.5241\u001b[0m       \u001b[32m0.7093\u001b[0m        \u001b[35m0.8815\u001b[0m  1.9287\n",
            "      8        \u001b[36m0.5035\u001b[0m       \u001b[32m0.7133\u001b[0m        \u001b[35m0.8291\u001b[0m  1.9232\n",
            "      9        \u001b[36m0.4859\u001b[0m       \u001b[32m0.7318\u001b[0m        \u001b[35m0.7623\u001b[0m  1.9281\n",
            "     10        \u001b[36m0.4670\u001b[0m       \u001b[32m0.7457\u001b[0m        \u001b[35m0.7176\u001b[0m  1.9188\n",
            "     11        \u001b[36m0.4527\u001b[0m       \u001b[32m0.7512\u001b[0m        0.7176  1.9189\n",
            "     12        \u001b[36m0.4368\u001b[0m       \u001b[32m0.7605\u001b[0m        \u001b[35m0.6686\u001b[0m  1.9257\n",
            "     13        \u001b[36m0.4250\u001b[0m       \u001b[32m0.7653\u001b[0m        \u001b[35m0.6570\u001b[0m  1.9347\n",
            "     14        \u001b[36m0.4115\u001b[0m       \u001b[32m0.7728\u001b[0m        \u001b[35m0.6366\u001b[0m  1.9350\n",
            "     15        \u001b[36m0.4039\u001b[0m       \u001b[32m0.7753\u001b[0m        \u001b[35m0.6204\u001b[0m  1.9218\n",
            "     16        \u001b[36m0.3937\u001b[0m       \u001b[32m0.7858\u001b[0m        \u001b[35m0.6007\u001b[0m  1.9293\n",
            "     17        \u001b[36m0.3849\u001b[0m       0.7858        \u001b[35m0.5941\u001b[0m  1.9228\n",
            "     18        \u001b[36m0.3788\u001b[0m       \u001b[32m0.7952\u001b[0m        \u001b[35m0.5735\u001b[0m  1.9162\n",
            "     19        \u001b[36m0.3698\u001b[0m       \u001b[32m0.7968\u001b[0m        \u001b[35m0.5591\u001b[0m  1.9592\n",
            "     20        \u001b[36m0.3661\u001b[0m       \u001b[32m0.8033\u001b[0m        \u001b[35m0.5443\u001b[0m  1.9306\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.25, module__num_filters_1=64, module__num_filters_2=128; total time=  39.9s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.5188\u001b[0m       \u001b[32m0.6743\u001b[0m        \u001b[35m0.8904\u001b[0m  1.3375\n",
            "      2        \u001b[36m0.8737\u001b[0m       \u001b[32m0.7100\u001b[0m        \u001b[35m0.7713\u001b[0m  1.3280\n",
            "      3        \u001b[36m0.7663\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6807\u001b[0m  1.3230\n",
            "      4        \u001b[36m0.7095\u001b[0m       \u001b[32m0.7697\u001b[0m        \u001b[35m0.6222\u001b[0m  1.3159\n",
            "      5        \u001b[36m0.6719\u001b[0m       \u001b[32m0.7810\u001b[0m        \u001b[35m0.6004\u001b[0m  1.3205\n",
            "      6        \u001b[36m0.6426\u001b[0m       \u001b[32m0.7912\u001b[0m        \u001b[35m0.5711\u001b[0m  1.3167\n",
            "      7        \u001b[36m0.6098\u001b[0m       \u001b[32m0.7957\u001b[0m        \u001b[35m0.5572\u001b[0m  1.3260\n",
            "      8        \u001b[36m0.5895\u001b[0m       \u001b[32m0.8127\u001b[0m        \u001b[35m0.5223\u001b[0m  1.3203\n",
            "      9        \u001b[36m0.5660\u001b[0m       \u001b[32m0.8210\u001b[0m        \u001b[35m0.5038\u001b[0m  1.3231\n",
            "     10        \u001b[36m0.5480\u001b[0m       \u001b[32m0.8298\u001b[0m        \u001b[35m0.4879\u001b[0m  1.3222\n",
            "     11        \u001b[36m0.5256\u001b[0m       \u001b[32m0.8400\u001b[0m        \u001b[35m0.4704\u001b[0m  1.3181\n",
            "     12        \u001b[36m0.5109\u001b[0m       \u001b[32m0.8453\u001b[0m        \u001b[35m0.4506\u001b[0m  1.3174\n",
            "     13        \u001b[36m0.4949\u001b[0m       \u001b[32m0.8470\u001b[0m        \u001b[35m0.4447\u001b[0m  1.3208\n",
            "     14        \u001b[36m0.4830\u001b[0m       \u001b[32m0.8502\u001b[0m        \u001b[35m0.4335\u001b[0m  1.3199\n",
            "     15        \u001b[36m0.4675\u001b[0m       \u001b[32m0.8528\u001b[0m        \u001b[35m0.4292\u001b[0m  1.3294\n",
            "     16        \u001b[36m0.4625\u001b[0m       \u001b[32m0.8560\u001b[0m        \u001b[35m0.4191\u001b[0m  1.3299\n",
            "     17        \u001b[36m0.4505\u001b[0m       \u001b[32m0.8577\u001b[0m        \u001b[35m0.4137\u001b[0m  1.3182\n",
            "     18        \u001b[36m0.4422\u001b[0m       \u001b[32m0.8618\u001b[0m        \u001b[35m0.4011\u001b[0m  1.3210\n",
            "     19        \u001b[36m0.4337\u001b[0m       0.8603        \u001b[35m0.3981\u001b[0m  1.3103\n",
            "     20        \u001b[36m0.4266\u001b[0m       \u001b[32m0.8632\u001b[0m        \u001b[35m0.3900\u001b[0m  1.3278\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.5, module__num_filters_1=32, module__num_filters_2=64; total time=  27.5s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.5693\u001b[0m       \u001b[32m0.4610\u001b[0m        \u001b[35m1.9827\u001b[0m  1.3303\n",
            "      2        \u001b[36m0.8401\u001b[0m       \u001b[32m0.5633\u001b[0m        \u001b[35m1.6018\u001b[0m  1.3128\n",
            "      3        \u001b[36m0.7408\u001b[0m       \u001b[32m0.6390\u001b[0m        \u001b[35m1.2841\u001b[0m  1.3200\n",
            "      4        \u001b[36m0.6816\u001b[0m       \u001b[32m0.6577\u001b[0m        \u001b[35m1.1705\u001b[0m  1.3364\n",
            "      5        \u001b[36m0.6415\u001b[0m       \u001b[32m0.6840\u001b[0m        \u001b[35m1.0206\u001b[0m  1.3268\n",
            "      6        \u001b[36m0.6119\u001b[0m       \u001b[32m0.6928\u001b[0m        \u001b[35m0.9320\u001b[0m  1.3225\n",
            "      7        \u001b[36m0.5855\u001b[0m       \u001b[32m0.7097\u001b[0m        \u001b[35m0.8680\u001b[0m  1.3201\n",
            "      8        \u001b[36m0.5607\u001b[0m       \u001b[32m0.7113\u001b[0m        \u001b[35m0.8565\u001b[0m  1.3197\n",
            "      9        \u001b[36m0.5418\u001b[0m       \u001b[32m0.7328\u001b[0m        \u001b[35m0.7585\u001b[0m  1.3037\n",
            "     10        \u001b[36m0.5237\u001b[0m       \u001b[32m0.7412\u001b[0m        \u001b[35m0.7286\u001b[0m  1.3166\n",
            "     11        \u001b[36m0.5083\u001b[0m       \u001b[32m0.7480\u001b[0m        \u001b[35m0.7029\u001b[0m  1.3272\n",
            "     12        \u001b[36m0.4931\u001b[0m       \u001b[32m0.7552\u001b[0m        \u001b[35m0.6707\u001b[0m  1.3227\n",
            "     13        \u001b[36m0.4766\u001b[0m       \u001b[32m0.7602\u001b[0m        \u001b[35m0.6687\u001b[0m  1.3288\n",
            "     14        \u001b[36m0.4693\u001b[0m       \u001b[32m0.7713\u001b[0m        \u001b[35m0.6366\u001b[0m  1.3296\n",
            "     15        \u001b[36m0.4595\u001b[0m       \u001b[32m0.7740\u001b[0m        \u001b[35m0.6090\u001b[0m  1.3378\n",
            "     16        \u001b[36m0.4481\u001b[0m       \u001b[32m0.7752\u001b[0m        0.6199  1.3267\n",
            "     17        \u001b[36m0.4400\u001b[0m       \u001b[32m0.7828\u001b[0m        \u001b[35m0.5914\u001b[0m  1.3213\n",
            "     18        \u001b[36m0.4313\u001b[0m       \u001b[32m0.7870\u001b[0m        \u001b[35m0.5758\u001b[0m  1.3293\n",
            "     19        \u001b[36m0.4199\u001b[0m       \u001b[32m0.7872\u001b[0m        \u001b[35m0.5706\u001b[0m  1.3280\n",
            "     20        \u001b[36m0.4130\u001b[0m       \u001b[32m0.8013\u001b[0m        \u001b[35m0.5377\u001b[0m  1.3247\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.5, module__num_filters_1=32, module__num_filters_2=64; total time=  27.5s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.4609\u001b[0m       \u001b[32m0.7095\u001b[0m        \u001b[35m0.8364\u001b[0m  1.7668\n",
            "      2        \u001b[36m0.8195\u001b[0m       \u001b[32m0.7350\u001b[0m        \u001b[35m0.7116\u001b[0m  1.7510\n",
            "      3        \u001b[36m0.7287\u001b[0m       \u001b[32m0.7693\u001b[0m        \u001b[35m0.6335\u001b[0m  1.7499\n",
            "      4        \u001b[36m0.6760\u001b[0m       \u001b[32m0.7720\u001b[0m        \u001b[35m0.5982\u001b[0m  1.7569\n",
            "      5        \u001b[36m0.6403\u001b[0m       \u001b[32m0.7932\u001b[0m        \u001b[35m0.5563\u001b[0m  1.7469\n",
            "      6        \u001b[36m0.6035\u001b[0m       \u001b[32m0.8072\u001b[0m        \u001b[35m0.5364\u001b[0m  1.7600\n",
            "      7        \u001b[36m0.5766\u001b[0m       \u001b[32m0.8203\u001b[0m        \u001b[35m0.5085\u001b[0m  1.7490\n",
            "      8        \u001b[36m0.5516\u001b[0m       \u001b[32m0.8305\u001b[0m        \u001b[35m0.4871\u001b[0m  1.7533\n",
            "      9        \u001b[36m0.5308\u001b[0m       \u001b[32m0.8325\u001b[0m        \u001b[35m0.4722\u001b[0m  1.7683\n",
            "     10        \u001b[36m0.5108\u001b[0m       \u001b[32m0.8435\u001b[0m        \u001b[35m0.4508\u001b[0m  1.7493\n",
            "     11        \u001b[36m0.4941\u001b[0m       \u001b[32m0.8470\u001b[0m        \u001b[35m0.4406\u001b[0m  1.7570\n",
            "     12        \u001b[36m0.4816\u001b[0m       \u001b[32m0.8485\u001b[0m        \u001b[35m0.4389\u001b[0m  1.7507\n",
            "     13        \u001b[36m0.4667\u001b[0m       \u001b[32m0.8533\u001b[0m        \u001b[35m0.4285\u001b[0m  1.7487\n",
            "     14        \u001b[36m0.4566\u001b[0m       \u001b[32m0.8582\u001b[0m        \u001b[35m0.4117\u001b[0m  1.7595\n",
            "     15        \u001b[36m0.4448\u001b[0m       \u001b[32m0.8602\u001b[0m        \u001b[35m0.4030\u001b[0m  1.7683\n",
            "     16        \u001b[36m0.4356\u001b[0m       0.8602        \u001b[35m0.3977\u001b[0m  1.7666\n",
            "     17        \u001b[36m0.4249\u001b[0m       \u001b[32m0.8670\u001b[0m        \u001b[35m0.3862\u001b[0m  1.7619\n",
            "     18        \u001b[36m0.4188\u001b[0m       0.8665        \u001b[35m0.3846\u001b[0m  1.7764\n",
            "     19        \u001b[36m0.4127\u001b[0m       \u001b[32m0.8718\u001b[0m        \u001b[35m0.3746\u001b[0m  1.7615\n",
            "     20        \u001b[36m0.4024\u001b[0m       0.8687        \u001b[35m0.3713\u001b[0m  1.7673\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.5, module__num_filters_1=32, module__num_filters_2=128; total time=  36.3s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.4155\u001b[0m       \u001b[32m0.4715\u001b[0m        \u001b[35m2.0625\u001b[0m  1.7581\n",
            "      2        \u001b[36m0.8258\u001b[0m       \u001b[32m0.6068\u001b[0m        \u001b[35m1.4309\u001b[0m  1.7617\n",
            "      3        \u001b[36m0.7271\u001b[0m       \u001b[32m0.6455\u001b[0m        \u001b[35m1.2390\u001b[0m  1.7547\n",
            "      4        \u001b[36m0.6738\u001b[0m       \u001b[32m0.6690\u001b[0m        \u001b[35m1.1107\u001b[0m  1.7538\n",
            "      5        \u001b[36m0.6395\u001b[0m       \u001b[32m0.6785\u001b[0m        \u001b[35m1.0198\u001b[0m  1.7552\n",
            "      6        \u001b[36m0.6096\u001b[0m       \u001b[32m0.6950\u001b[0m        \u001b[35m0.9347\u001b[0m  1.7508\n",
            "      7        \u001b[36m0.5811\u001b[0m       \u001b[32m0.7068\u001b[0m        \u001b[35m0.8693\u001b[0m  1.7684\n",
            "      8        \u001b[36m0.5587\u001b[0m       \u001b[32m0.7193\u001b[0m        \u001b[35m0.8019\u001b[0m  1.7574\n",
            "      9        \u001b[36m0.5370\u001b[0m       \u001b[32m0.7352\u001b[0m        \u001b[35m0.7729\u001b[0m  1.7584\n",
            "     10        \u001b[36m0.5191\u001b[0m       \u001b[32m0.7402\u001b[0m        \u001b[35m0.7409\u001b[0m  1.7528\n",
            "     11        \u001b[36m0.5052\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6988\u001b[0m  1.7491\n",
            "     12        \u001b[36m0.4894\u001b[0m       \u001b[32m0.7565\u001b[0m        \u001b[35m0.6769\u001b[0m  1.7474\n",
            "     13        \u001b[36m0.4739\u001b[0m       \u001b[32m0.7677\u001b[0m        \u001b[35m0.6436\u001b[0m  1.7602\n",
            "     14        \u001b[36m0.4609\u001b[0m       \u001b[32m0.7775\u001b[0m        \u001b[35m0.6181\u001b[0m  1.7741\n",
            "     15        \u001b[36m0.4516\u001b[0m       \u001b[32m0.7805\u001b[0m        \u001b[35m0.5986\u001b[0m  1.7832\n",
            "     16        \u001b[36m0.4416\u001b[0m       \u001b[32m0.7860\u001b[0m        \u001b[35m0.5963\u001b[0m  1.7593\n",
            "     17        \u001b[36m0.4329\u001b[0m       \u001b[32m0.7890\u001b[0m        \u001b[35m0.5720\u001b[0m  1.7687\n",
            "     18        \u001b[36m0.4243\u001b[0m       \u001b[32m0.7900\u001b[0m        0.5767  1.7547\n",
            "     19        \u001b[36m0.4190\u001b[0m       \u001b[32m0.7975\u001b[0m        \u001b[35m0.5484\u001b[0m  1.9167\n",
            "     20        \u001b[36m0.4089\u001b[0m       \u001b[32m0.7978\u001b[0m        0.5508  1.7650\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.5, module__num_filters_1=32, module__num_filters_2=128; total time=  36.5s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.4662\u001b[0m       \u001b[32m0.7022\u001b[0m        \u001b[35m0.8196\u001b[0m  1.5581\n",
            "      2        \u001b[36m0.8077\u001b[0m       \u001b[32m0.7263\u001b[0m        \u001b[35m0.7036\u001b[0m  1.5836\n",
            "      3        \u001b[36m0.7224\u001b[0m       \u001b[32m0.7617\u001b[0m        \u001b[35m0.6351\u001b[0m  1.5641\n",
            "      4        \u001b[36m0.6673\u001b[0m       \u001b[32m0.7750\u001b[0m        \u001b[35m0.6016\u001b[0m  1.5570\n",
            "      5        \u001b[36m0.6265\u001b[0m       \u001b[32m0.7955\u001b[0m        \u001b[35m0.5592\u001b[0m  1.5539\n",
            "      6        \u001b[36m0.5962\u001b[0m       \u001b[32m0.8148\u001b[0m        \u001b[35m0.5262\u001b[0m  1.5594\n",
            "      7        \u001b[36m0.5680\u001b[0m       \u001b[32m0.8230\u001b[0m        \u001b[35m0.5039\u001b[0m  1.5494\n",
            "      8        \u001b[36m0.5467\u001b[0m       \u001b[32m0.8253\u001b[0m        \u001b[35m0.4859\u001b[0m  1.5509\n",
            "      9        \u001b[36m0.5227\u001b[0m       \u001b[32m0.8375\u001b[0m        \u001b[35m0.4649\u001b[0m  1.5505\n",
            "     10        \u001b[36m0.5068\u001b[0m       \u001b[32m0.8458\u001b[0m        \u001b[35m0.4525\u001b[0m  1.5522\n",
            "     11        \u001b[36m0.4916\u001b[0m       \u001b[32m0.8498\u001b[0m        \u001b[35m0.4386\u001b[0m  1.5395\n",
            "     12        \u001b[36m0.4783\u001b[0m       \u001b[32m0.8513\u001b[0m        \u001b[35m0.4323\u001b[0m  1.5375\n",
            "     13        \u001b[36m0.4685\u001b[0m       \u001b[32m0.8580\u001b[0m        \u001b[35m0.4192\u001b[0m  1.5688\n",
            "     14        \u001b[36m0.4578\u001b[0m       \u001b[32m0.8612\u001b[0m        \u001b[35m0.4110\u001b[0m  1.5487\n",
            "     15        \u001b[36m0.4447\u001b[0m       \u001b[32m0.8622\u001b[0m        \u001b[35m0.4050\u001b[0m  1.5532\n",
            "     16        \u001b[36m0.4369\u001b[0m       \u001b[32m0.8643\u001b[0m        \u001b[35m0.3965\u001b[0m  1.5483\n",
            "     17        \u001b[36m0.4278\u001b[0m       \u001b[32m0.8687\u001b[0m        \u001b[35m0.3886\u001b[0m  1.5648\n",
            "     18        \u001b[36m0.4209\u001b[0m       \u001b[32m0.8708\u001b[0m        \u001b[35m0.3821\u001b[0m  1.5577\n",
            "     19        \u001b[36m0.4175\u001b[0m       0.8690        \u001b[35m0.3790\u001b[0m  1.5377\n",
            "     20        \u001b[36m0.4103\u001b[0m       \u001b[32m0.8740\u001b[0m        \u001b[35m0.3744\u001b[0m  1.5405\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.5, module__num_filters_1=64, module__num_filters_2=64; total time=  32.2s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.3974\u001b[0m       \u001b[32m0.4368\u001b[0m        \u001b[35m2.0786\u001b[0m  1.5481\n",
            "      2        \u001b[36m0.8575\u001b[0m       \u001b[32m0.5757\u001b[0m        \u001b[35m1.4608\u001b[0m  1.5621\n",
            "      3        \u001b[36m0.7372\u001b[0m       \u001b[32m0.6417\u001b[0m        \u001b[35m1.2843\u001b[0m  1.5759\n",
            "      4        \u001b[36m0.6727\u001b[0m       \u001b[32m0.6652\u001b[0m        \u001b[35m1.1263\u001b[0m  1.5721\n",
            "      5        \u001b[36m0.6368\u001b[0m       \u001b[32m0.6868\u001b[0m        \u001b[35m0.9758\u001b[0m  1.5668\n",
            "      6        \u001b[36m0.6027\u001b[0m       \u001b[32m0.7038\u001b[0m        \u001b[35m0.8878\u001b[0m  1.5727\n",
            "      7        \u001b[36m0.5763\u001b[0m       \u001b[32m0.7052\u001b[0m        \u001b[35m0.8580\u001b[0m  1.5720\n",
            "      8        \u001b[36m0.5500\u001b[0m       \u001b[32m0.7228\u001b[0m        \u001b[35m0.7848\u001b[0m  1.5635\n",
            "      9        \u001b[36m0.5327\u001b[0m       \u001b[32m0.7307\u001b[0m        \u001b[35m0.7598\u001b[0m  1.5646\n",
            "     10        \u001b[36m0.5140\u001b[0m       \u001b[32m0.7410\u001b[0m        \u001b[35m0.7234\u001b[0m  1.5598\n",
            "     11        \u001b[36m0.4988\u001b[0m       \u001b[32m0.7423\u001b[0m        \u001b[35m0.7171\u001b[0m  1.5555\n",
            "     12        \u001b[36m0.4846\u001b[0m       \u001b[32m0.7682\u001b[0m        \u001b[35m0.6383\u001b[0m  1.5707\n",
            "     13        \u001b[36m0.4720\u001b[0m       0.7615        0.6569  1.5827\n",
            "     14        \u001b[36m0.4600\u001b[0m       0.7618        0.6453  1.5629\n",
            "     15        \u001b[36m0.4516\u001b[0m       \u001b[32m0.7742\u001b[0m        \u001b[35m0.6044\u001b[0m  1.5528\n",
            "     16        \u001b[36m0.4420\u001b[0m       0.7720        0.6203  1.5602\n",
            "     17        \u001b[36m0.4304\u001b[0m       \u001b[32m0.7780\u001b[0m        \u001b[35m0.5951\u001b[0m  1.5712\n",
            "     18        \u001b[36m0.4227\u001b[0m       \u001b[32m0.7787\u001b[0m        0.5964  1.5680\n",
            "     19        \u001b[36m0.4205\u001b[0m       \u001b[32m0.7913\u001b[0m        \u001b[35m0.5531\u001b[0m  1.5637\n",
            "     20        \u001b[36m0.4101\u001b[0m       \u001b[32m0.8002\u001b[0m        \u001b[35m0.5308\u001b[0m  1.5664\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.5, module__num_filters_1=64, module__num_filters_2=64; total time=  32.5s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.5030\u001b[0m       \u001b[32m0.7087\u001b[0m        \u001b[35m0.8251\u001b[0m  1.9577\n",
            "      2        \u001b[36m0.8104\u001b[0m       \u001b[32m0.7370\u001b[0m        \u001b[35m0.6842\u001b[0m  1.9776\n",
            "      3        \u001b[36m0.7085\u001b[0m       \u001b[32m0.7680\u001b[0m        \u001b[35m0.6191\u001b[0m  1.9657\n",
            "      4        \u001b[36m0.6499\u001b[0m       \u001b[32m0.7863\u001b[0m        \u001b[35m0.5738\u001b[0m  1.9265\n",
            "      5        \u001b[36m0.6102\u001b[0m       \u001b[32m0.7983\u001b[0m        \u001b[35m0.5383\u001b[0m  1.9346\n",
            "      6        \u001b[36m0.5768\u001b[0m       \u001b[32m0.8087\u001b[0m        \u001b[35m0.5164\u001b[0m  1.9464\n",
            "      7        \u001b[36m0.5481\u001b[0m       \u001b[32m0.8195\u001b[0m        \u001b[35m0.4929\u001b[0m  1.9355\n",
            "      8        \u001b[36m0.5245\u001b[0m       \u001b[32m0.8320\u001b[0m        \u001b[35m0.4724\u001b[0m  1.9333\n",
            "      9        \u001b[36m0.5096\u001b[0m       \u001b[32m0.8412\u001b[0m        \u001b[35m0.4564\u001b[0m  1.9408\n",
            "     10        \u001b[36m0.4896\u001b[0m       \u001b[32m0.8455\u001b[0m        \u001b[35m0.4454\u001b[0m  1.9148\n",
            "     11        \u001b[36m0.4774\u001b[0m       \u001b[32m0.8523\u001b[0m        \u001b[35m0.4300\u001b[0m  1.9209\n",
            "     12        \u001b[36m0.4599\u001b[0m       \u001b[32m0.8562\u001b[0m        \u001b[35m0.4231\u001b[0m  1.9247\n",
            "     13        \u001b[36m0.4514\u001b[0m       0.8552        \u001b[35m0.4133\u001b[0m  1.9341\n",
            "     14        \u001b[36m0.4429\u001b[0m       0.8555        \u001b[35m0.4079\u001b[0m  1.9405\n",
            "     15        \u001b[36m0.4326\u001b[0m       \u001b[32m0.8648\u001b[0m        \u001b[35m0.3927\u001b[0m  1.9452\n",
            "     16        \u001b[36m0.4240\u001b[0m       0.8643        \u001b[35m0.3889\u001b[0m  1.9547\n",
            "     17        \u001b[36m0.4153\u001b[0m       \u001b[32m0.8690\u001b[0m        \u001b[35m0.3797\u001b[0m  1.9449\n",
            "     18        \u001b[36m0.4098\u001b[0m       0.8678        \u001b[35m0.3772\u001b[0m  1.9410\n",
            "     19        \u001b[36m0.4008\u001b[0m       \u001b[32m0.8723\u001b[0m        \u001b[35m0.3684\u001b[0m  1.9421\n",
            "     20        \u001b[36m0.3955\u001b[0m       0.8717        \u001b[35m0.3649\u001b[0m  1.9339\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.5, module__num_filters_1=64, module__num_filters_2=128; total time=  40.1s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.3764\u001b[0m       \u001b[32m0.4577\u001b[0m        \u001b[35m2.0241\u001b[0m  1.9378\n",
            "      2        \u001b[36m0.8098\u001b[0m       \u001b[32m0.6087\u001b[0m        \u001b[35m1.3962\u001b[0m  1.9431\n",
            "      3        \u001b[36m0.7119\u001b[0m       \u001b[32m0.6495\u001b[0m        \u001b[35m1.1997\u001b[0m  1.9415\n",
            "      4        \u001b[36m0.6604\u001b[0m       \u001b[32m0.6700\u001b[0m        \u001b[35m1.1116\u001b[0m  1.9367\n",
            "      5        \u001b[36m0.6234\u001b[0m       \u001b[32m0.6962\u001b[0m        \u001b[35m0.9687\u001b[0m  1.9315\n",
            "      6        \u001b[36m0.5889\u001b[0m       \u001b[32m0.7118\u001b[0m        \u001b[35m0.8675\u001b[0m  1.9369\n",
            "      7        \u001b[36m0.5623\u001b[0m       \u001b[32m0.7233\u001b[0m        \u001b[35m0.8119\u001b[0m  1.9603\n",
            "      8        \u001b[36m0.5402\u001b[0m       \u001b[32m0.7263\u001b[0m        \u001b[35m0.7872\u001b[0m  1.9393\n",
            "      9        \u001b[36m0.5184\u001b[0m       \u001b[32m0.7358\u001b[0m        \u001b[35m0.7497\u001b[0m  1.9191\n",
            "     10        \u001b[36m0.5031\u001b[0m       \u001b[32m0.7527\u001b[0m        \u001b[35m0.7030\u001b[0m  1.9304\n",
            "     11        \u001b[36m0.4853\u001b[0m       \u001b[32m0.7627\u001b[0m        \u001b[35m0.6650\u001b[0m  1.9348\n",
            "     12        \u001b[36m0.4753\u001b[0m       \u001b[32m0.7737\u001b[0m        \u001b[35m0.6387\u001b[0m  1.9307\n",
            "     13        \u001b[36m0.4633\u001b[0m       \u001b[32m0.7767\u001b[0m        \u001b[35m0.6192\u001b[0m  1.9332\n",
            "     14        \u001b[36m0.4515\u001b[0m       0.7743        0.6230  1.9192\n",
            "     15        \u001b[36m0.4399\u001b[0m       \u001b[32m0.7775\u001b[0m        \u001b[35m0.5973\u001b[0m  1.9148\n",
            "     16        \u001b[36m0.4320\u001b[0m       \u001b[32m0.7845\u001b[0m        \u001b[35m0.5843\u001b[0m  1.9233\n",
            "     17        \u001b[36m0.4245\u001b[0m       0.7832        \u001b[35m0.5828\u001b[0m  1.9308\n",
            "     18        \u001b[36m0.4149\u001b[0m       \u001b[32m0.7950\u001b[0m        \u001b[35m0.5614\u001b[0m  1.9277\n",
            "     19        \u001b[36m0.4099\u001b[0m       \u001b[32m0.7963\u001b[0m        \u001b[35m0.5410\u001b[0m  1.9379\n",
            "     20        \u001b[36m0.4028\u001b[0m       \u001b[32m0.8007\u001b[0m        \u001b[35m0.5401\u001b[0m  1.9399\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.5, module__num_filters_1=64, module__num_filters_2=128; total time=  40.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6994\u001b[0m       \u001b[32m0.8500\u001b[0m        \u001b[35m0.4139\u001b[0m  2.7095\n",
            "      2        \u001b[36m0.4096\u001b[0m       \u001b[32m0.8731\u001b[0m        \u001b[35m0.3431\u001b[0m  2.7204\n",
            "      3        \u001b[36m0.3447\u001b[0m       \u001b[32m0.8859\u001b[0m        \u001b[35m0.3092\u001b[0m  2.7110\n",
            "      4        \u001b[36m0.3071\u001b[0m       \u001b[32m0.8932\u001b[0m        \u001b[35m0.2877\u001b[0m  2.7245\n",
            "      5        \u001b[36m0.2787\u001b[0m       \u001b[32m0.8958\u001b[0m        \u001b[35m0.2759\u001b[0m  2.7140\n",
            "      6        \u001b[36m0.2564\u001b[0m       \u001b[32m0.9038\u001b[0m        \u001b[35m0.2597\u001b[0m  2.7248\n",
            "      7        \u001b[36m0.2392\u001b[0m       0.9032        \u001b[35m0.2556\u001b[0m  2.7012\n",
            "      8        \u001b[36m0.2220\u001b[0m       \u001b[32m0.9080\u001b[0m        \u001b[35m0.2451\u001b[0m  2.7161\n",
            "      9        \u001b[36m0.2078\u001b[0m       0.9066        0.2452  2.7107\n",
            "     10        \u001b[36m0.1938\u001b[0m       \u001b[32m0.9133\u001b[0m        \u001b[35m0.2358\u001b[0m  2.7125\n",
            "     11        \u001b[36m0.1800\u001b[0m       0.9083        0.2468  2.6909\n",
            "     12        \u001b[36m0.1675\u001b[0m       \u001b[32m0.9136\u001b[0m        \u001b[35m0.2357\u001b[0m  2.7403\n",
            "     13        \u001b[36m0.1574\u001b[0m       \u001b[32m0.9148\u001b[0m        0.2394  2.7072\n",
            "     14        \u001b[36m0.1444\u001b[0m       \u001b[32m0.9165\u001b[0m        0.2379  2.6931\n",
            "     15        \u001b[36m0.1350\u001b[0m       0.9163        0.2412  2.6992\n",
            "     16        \u001b[36m0.1248\u001b[0m       \u001b[32m0.9173\u001b[0m        0.2381  2.7217\n",
            "     17        \u001b[36m0.1158\u001b[0m       \u001b[32m0.9176\u001b[0m        0.2436  2.7460\n",
            "     18        \u001b[36m0.1064\u001b[0m       0.9170        0.2597  2.7216\n",
            "     19        \u001b[36m0.0978\u001b[0m       0.9172        0.2629  2.7223\n",
            "     20        \u001b[36m0.0912\u001b[0m       0.9166        0.2636  2.7411\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=2,\n",
              "             estimator=<class 'skorch.classifier.NeuralNetClassifier'>[uninitialized](\n",
              "  module=<class '__main__.CNN'>,\n",
              "  module__dropout_rate=0.5,\n",
              "  module__num_filters_1=32,\n",
              "  module__num_filters_2=64,\n",
              "),\n",
              "             param_grid={'lr': [0.1, 0.01], 'max_epochs': [10, 20],\n",
              "                         'module__dropout_rate': [0.25, 0.5],\n",
              "                         'module__num_filters_1': [32, 64],\n",
              "                         'module__num_filters_2': [64, 128]},\n",
              "             scoring='accuracy', verbose=2)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2,\n",
              "             estimator=&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
              "  module=&lt;class &#x27;__main__.CNN&#x27;&gt;,\n",
              "  module__dropout_rate=0.5,\n",
              "  module__num_filters_1=32,\n",
              "  module__num_filters_2=64,\n",
              "),\n",
              "             param_grid={&#x27;lr&#x27;: [0.1, 0.01], &#x27;max_epochs&#x27;: [10, 20],\n",
              "                         &#x27;module__dropout_rate&#x27;: [0.25, 0.5],\n",
              "                         &#x27;module__num_filters_1&#x27;: [32, 64],\n",
              "                         &#x27;module__num_filters_2&#x27;: [64, 128]},\n",
              "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2,\n",
              "             estimator=&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
              "  module=&lt;class &#x27;__main__.CNN&#x27;&gt;,\n",
              "  module__dropout_rate=0.5,\n",
              "  module__num_filters_1=32,\n",
              "  module__num_filters_2=64,\n",
              "),\n",
              "             param_grid={&#x27;lr&#x27;: [0.1, 0.01], &#x27;max_epochs&#x27;: [10, 20],\n",
              "                         &#x27;module__dropout_rate&#x27;: [0.25, 0.5],\n",
              "                         &#x27;module__num_filters_1&#x27;: [32, 64],\n",
              "                         &#x27;module__num_filters_2&#x27;: [64, 128]},\n",
              "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: NeuralNetClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
              "  module=&lt;class &#x27;__main__.CNN&#x27;&gt;,\n",
              "  module__dropout_rate=0.5,\n",
              "  module__num_filters_1=32,\n",
              "  module__num_filters_2=64,\n",
              ")</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NeuralNetClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
              "  module=&lt;class &#x27;__main__.CNN&#x27;&gt;,\n",
              "  module__dropout_rate=0.5,\n",
              "  module__num_filters_1=32,\n",
              "  module__num_filters_2=64,\n",
              ")</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "#model is trained with the parameters. the final model is trained using the best hyperparameters obtained\n",
        "trained_model.fit(X_train_flipped, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained CNN hyper model model\n",
        "joblib.dump(trained_model, 'trained_cnn_hyper_model.pkl')"
      ],
      "metadata": {
        "id": "y_en1dE3JpXd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "fb1224a2-9146-4539-a7ef-713dd19b5455"
      },
      "id": "y_en1dE3JpXd",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['trained_cnn_hyper_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "23584b35-e52b-4358-b9d1-92094852b1f1",
      "metadata": {
        "id": "23584b35-e52b-4358-b9d1-92094852b1f1",
        "outputId": "a4444430-9ee8-467b-a250-6b7ebdfb1158",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters set found during training:\n",
            "{'lr': 0.1, 'max_epochs': 20, 'module__dropout_rate': 0.25, 'module__num_filters_1': 32, 'module__num_filters_2': 64}\n",
            "Grid scores while training:\n",
            "0.866 (+/-0.059) for {'lr': 0.1, 'max_epochs': 10, 'module__dropout_rate': 0.25, 'module__num_filters_1': 32, 'module__num_filters_2': 64}\n",
            "0.867 (+/-0.047) for {'lr': 0.1, 'max_epochs': 10, 'module__dropout_rate': 0.25, 'module__num_filters_1': 32, 'module__num_filters_2': 128}\n",
            "0.864 (+/-0.061) for {'lr': 0.1, 'max_epochs': 10, 'module__dropout_rate': 0.25, 'module__num_filters_1': 64, 'module__num_filters_2': 64}\n",
            "0.873 (+/-0.053) for {'lr': 0.1, 'max_epochs': 10, 'module__dropout_rate': 0.25, 'module__num_filters_1': 64, 'module__num_filters_2': 128}\n",
            "0.875 (+/-0.038) for {'lr': 0.1, 'max_epochs': 10, 'module__dropout_rate': 0.5, 'module__num_filters_1': 32, 'module__num_filters_2': 64}\n",
            "0.873 (+/-0.044) for {'lr': 0.1, 'max_epochs': 10, 'module__dropout_rate': 0.5, 'module__num_filters_1': 32, 'module__num_filters_2': 128}\n",
            "0.877 (+/-0.040) for {'lr': 0.1, 'max_epochs': 10, 'module__dropout_rate': 0.5, 'module__num_filters_1': 64, 'module__num_filters_2': 64}\n",
            "0.877 (+/-0.050) for {'lr': 0.1, 'max_epochs': 10, 'module__dropout_rate': 0.5, 'module__num_filters_1': 64, 'module__num_filters_2': 128}\n",
            "0.892 (+/-0.024) for {'lr': 0.1, 'max_epochs': 20, 'module__dropout_rate': 0.25, 'module__num_filters_1': 32, 'module__num_filters_2': 64}\n",
            "0.888 (+/-0.036) for {'lr': 0.1, 'max_epochs': 20, 'module__dropout_rate': 0.25, 'module__num_filters_1': 32, 'module__num_filters_2': 128}\n",
            "0.885 (+/-0.036) for {'lr': 0.1, 'max_epochs': 20, 'module__dropout_rate': 0.25, 'module__num_filters_1': 64, 'module__num_filters_2': 64}\n",
            "0.889 (+/-0.037) for {'lr': 0.1, 'max_epochs': 20, 'module__dropout_rate': 0.25, 'module__num_filters_1': 64, 'module__num_filters_2': 128}\n",
            "0.889 (+/-0.028) for {'lr': 0.1, 'max_epochs': 20, 'module__dropout_rate': 0.5, 'module__num_filters_1': 32, 'module__num_filters_2': 64}\n",
            "0.890 (+/-0.031) for {'lr': 0.1, 'max_epochs': 20, 'module__dropout_rate': 0.5, 'module__num_filters_1': 32, 'module__num_filters_2': 128}\n",
            "0.886 (+/-0.041) for {'lr': 0.1, 'max_epochs': 20, 'module__dropout_rate': 0.5, 'module__num_filters_1': 64, 'module__num_filters_2': 64}\n",
            "0.891 (+/-0.036) for {'lr': 0.1, 'max_epochs': 20, 'module__dropout_rate': 0.5, 'module__num_filters_1': 64, 'module__num_filters_2': 128}\n",
            "0.782 (+/-0.107) for {'lr': 0.01, 'max_epochs': 10, 'module__dropout_rate': 0.25, 'module__num_filters_1': 32, 'module__num_filters_2': 64}\n",
            "0.790 (+/-0.104) for {'lr': 0.01, 'max_epochs': 10, 'module__dropout_rate': 0.25, 'module__num_filters_1': 32, 'module__num_filters_2': 128}\n",
            "0.789 (+/-0.103) for {'lr': 0.01, 'max_epochs': 10, 'module__dropout_rate': 0.25, 'module__num_filters_1': 64, 'module__num_filters_2': 64}\n",
            "0.797 (+/-0.100) for {'lr': 0.01, 'max_epochs': 10, 'module__dropout_rate': 0.25, 'module__num_filters_1': 64, 'module__num_filters_2': 128}\n",
            "0.778 (+/-0.102) for {'lr': 0.01, 'max_epochs': 10, 'module__dropout_rate': 0.5, 'module__num_filters_1': 32, 'module__num_filters_2': 64}\n",
            "0.787 (+/-0.096) for {'lr': 0.01, 'max_epochs': 10, 'module__dropout_rate': 0.5, 'module__num_filters_1': 32, 'module__num_filters_2': 128}\n",
            "0.790 (+/-0.088) for {'lr': 0.01, 'max_epochs': 10, 'module__dropout_rate': 0.5, 'module__num_filters_1': 64, 'module__num_filters_2': 64}\n",
            "0.791 (+/-0.093) for {'lr': 0.01, 'max_epochs': 10, 'module__dropout_rate': 0.5, 'module__num_filters_1': 64, 'module__num_filters_2': 128}\n",
            "0.831 (+/-0.079) for {'lr': 0.01, 'max_epochs': 20, 'module__dropout_rate': 0.25, 'module__num_filters_1': 32, 'module__num_filters_2': 64}\n",
            "0.833 (+/-0.081) for {'lr': 0.01, 'max_epochs': 20, 'module__dropout_rate': 0.25, 'module__num_filters_1': 32, 'module__num_filters_2': 128}\n",
            "0.833 (+/-0.081) for {'lr': 0.01, 'max_epochs': 20, 'module__dropout_rate': 0.25, 'module__num_filters_1': 64, 'module__num_filters_2': 64}\n",
            "0.836 (+/-0.069) for {'lr': 0.01, 'max_epochs': 20, 'module__dropout_rate': 0.25, 'module__num_filters_1': 64, 'module__num_filters_2': 128}\n",
            "0.830 (+/-0.062) for {'lr': 0.01, 'max_epochs': 20, 'module__dropout_rate': 0.5, 'module__num_filters_1': 32, 'module__num_filters_2': 64}\n",
            "0.831 (+/-0.072) for {'lr': 0.01, 'max_epochs': 20, 'module__dropout_rate': 0.5, 'module__num_filters_1': 32, 'module__num_filters_2': 128}\n",
            "0.833 (+/-0.067) for {'lr': 0.01, 'max_epochs': 20, 'module__dropout_rate': 0.5, 'module__num_filters_1': 64, 'module__num_filters_2': 64}\n",
            "0.833 (+/-0.072) for {'lr': 0.01, 'max_epochs': 20, 'module__dropout_rate': 0.5, 'module__num_filters_1': 64, 'module__num_filters_2': 128}\n"
          ]
        }
      ],
      "source": [
        "#This prints the best parameters found during training along with the mean and standard deviation scores for the hyperparameters\n",
        "print(\"Best parameters set found during training:\")\n",
        "print(trained_model.best_params_)\n",
        "print(\"Grid scores while training:\")\n",
        "means = trained_model.cv_results_['mean_test_score']\n",
        "stds = trained_model.cv_results_['std_test_score']\n",
        "for mean, std, params in zip(means, stds, trained_model.cv_results_['params']):\n",
        "    print(f\"{mean:.3f} (+/-{std * 2:.3f}) for {params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "5224704e",
      "metadata": {
        "scrolled": true,
        "id": "5224704e",
        "outputId": "7be375d7-4c1e-4215-9c11-76eef9d8027e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best cross-validation accuracy: 89.21%\n"
          ]
        }
      ],
      "source": [
        "#Printing the best accuracy obtained during cross validation\n",
        "print(\"Best cross-validation accuracy: {:.2f}%\".format(trained_model.best_score_ * 100))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "2351a6b5",
      "metadata": {
        "id": "2351a6b5"
      },
      "outputs": [],
      "source": [
        "#MLP Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "e3b882f4-dedf-4273-8b25-cd88a2ea191e",
      "metadata": {
        "id": "e3b882f4-dedf-4273-8b25-cd88a2ea191e"
      },
      "outputs": [],
      "source": [
        "#features and labels from the training and test datasets are separeted nd normalised\n",
        "X_train = train_data.iloc[:, 1:].values.astype('float32') / 255.0\n",
        "y_train = train_data.iloc[:, 0].values.astype('int64')\n",
        "X_test = test_data.iloc[:, 1:].values.astype('float32') / 255.0\n",
        "y_test = test_data.iloc[:, 0].values.astype('int64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "7138b3ad-49c2-4401-b77c-c20ab2176f97",
      "metadata": {
        "id": "7138b3ad-49c2-4401-b77c-c20ab2176f97"
      },
      "outputs": [],
      "source": [
        "#Multi layer perceptron of 3 hidden layers with ReLU activation is implemented.\n",
        "#it returns output of size 10 which corresponds to the 10 output features of the dataset.\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 512)  # First hidden layer\n",
        "        self.fc2 = nn.Linear(512, 256)  # Second hidden layer\n",
        "        self.fc3 = nn.Linear(256, 128)  # Third hidden layer\n",
        "        self.fc4 = nn.Linear(128, 10)   # Output layer\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "#forward pass is implemented to define the sequence of operations\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "02d5ede0-07f3-4972-a118-5e96f58f928f",
      "metadata": {
        "id": "02d5ede0-07f3-4972-a118-5e96f58f928f"
      },
      "outputs": [],
      "source": [
        "#NeuralNetClassifier is defined encapsulating the MLP architecture along with training parameters and optimization.\n",
        "# L2 regularisation for the optimiser is implemeented to prevent overfitting.\n",
        "MLP_model = NeuralNetClassifier(\n",
        "    MLP,\n",
        "    max_epochs=20,\n",
        "    lr=0.1,\n",
        "    optimizer=torch.optim.SGD,\n",
        "    optimizer__momentum=0.9,\n",
        "    optimizer__weight_decay=1e-4,\n",
        "    criterion=nn.CrossEntropyLoss,\n",
        "    batch_size=64,\n",
        "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "2573caa8-ea7e-4825-97e5-2a210f25d898",
      "metadata": {
        "id": "2573caa8-ea7e-4825-97e5-2a210f25d898",
        "outputId": "f2cbd082-a1e0-4084-a44b-feca33b8eb99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.7118\u001b[0m       \u001b[32m0.7807\u001b[0m        \u001b[35m0.5848\u001b[0m  2.0055\n",
            "      2        \u001b[36m0.5077\u001b[0m       \u001b[32m0.8197\u001b[0m        \u001b[35m0.4928\u001b[0m  1.9865\n",
            "      3        \u001b[36m0.4483\u001b[0m       \u001b[32m0.8373\u001b[0m        \u001b[35m0.4530\u001b[0m  1.9392\n",
            "      4        \u001b[36m0.4211\u001b[0m       0.8165        0.4921  1.9032\n",
            "      5        \u001b[36m0.3999\u001b[0m       0.8304        \u001b[35m0.4477\u001b[0m  1.9295\n",
            "      6        \u001b[36m0.3848\u001b[0m       0.8347        \u001b[35m0.4319\u001b[0m  1.9155\n",
            "      7        \u001b[36m0.3744\u001b[0m       \u001b[32m0.8496\u001b[0m        \u001b[35m0.4256\u001b[0m  1.9546\n",
            "      8        \u001b[36m0.3734\u001b[0m       0.8392        0.4280  1.9677\n",
            "      9        \u001b[36m0.3654\u001b[0m       0.8447        \u001b[35m0.4120\u001b[0m  1.9548\n",
            "     10        \u001b[36m0.3639\u001b[0m       0.8454        \u001b[35m0.4017\u001b[0m  1.9442\n",
            "     11        \u001b[36m0.3486\u001b[0m       0.8486        0.4232  1.8918\n",
            "     12        \u001b[36m0.3474\u001b[0m       \u001b[32m0.8568\u001b[0m        0.4107  1.9396\n",
            "     13        \u001b[36m0.3433\u001b[0m       0.8563        0.4171  1.9284\n",
            "     14        \u001b[36m0.3354\u001b[0m       \u001b[32m0.8578\u001b[0m        0.4075  1.9592\n",
            "     15        0.3370       0.8562        0.4122  1.9026\n",
            "     16        \u001b[36m0.3325\u001b[0m       0.8501        0.4173  1.9142\n",
            "     17        \u001b[36m0.3312\u001b[0m       0.8482        0.4303  1.9717\n",
            "     18        \u001b[36m0.3279\u001b[0m       0.8527        \u001b[35m0.3987\u001b[0m  1.9495\n",
            "     19        0.3281       \u001b[32m0.8626\u001b[0m        \u001b[35m0.3896\u001b[0m  1.9727\n",
            "     20        \u001b[36m0.3253\u001b[0m       \u001b[32m0.8711\u001b[0m        \u001b[35m0.3759\u001b[0m  1.9537\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
              "  module_=MLP(\n",
              "    (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
              "    (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (fc4): Linear(in_features=128, out_features=10, bias=True)\n",
              "    (relu): ReLU()\n",
              "  ),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# The model is fit for training\n",
        "MLP_model.fit(X_train, y_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained mlp base model\n",
        "joblib.dump(MLP_model, 'trained_mlp_base_model.pkl')"
      ],
      "metadata": {
        "id": "fdgRASgAKHpo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f55ac07e-08b9-48e9-d44a-06544b4e764a"
      },
      "id": "fdgRASgAKHpo",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['trained_mlp_base_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "cc63e74b-fbc6-4ec3-94f7-30e323da7449",
      "metadata": {
        "id": "cc63e74b-fbc6-4ec3-94f7-30e323da7449"
      },
      "outputs": [],
      "source": [
        "#MLP with hyperparameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "7d35a229-e7be-49d5-883d-a781f234848b",
      "metadata": {
        "id": "7d35a229-e7be-49d5-883d-a781f234848b"
      },
      "outputs": [],
      "source": [
        "#Multilayer perceptron is defined with 4 fully connected layers with ReLU activation.\n",
        "#the output layer produces 10 units output representing the 10 classes of the dataset.\n",
        "#This model is created with Dropout regularisation to prevent overfiting and encourage robustness.\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, dropout_rate=0.5):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "212a9323-664d-4585-b926-52af23c0a05d",
      "metadata": {
        "id": "212a9323-664d-4585-b926-52af23c0a05d"
      },
      "outputs": [],
      "source": [
        "#MLP based neural classifier is configured with all its parameters\n",
        "hyper_MLP_model = NeuralNetClassifier(\n",
        "    MLP,\n",
        "    criterion=nn.CrossEntropyLoss,\n",
        "    optimizer=torch.optim.SGD,\n",
        "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    iterator_train__shuffle=True\n",
        ")\n",
        "\n",
        "#hyperparameters for grid search implmentation is defined\n",
        "hyper_parameters = {\n",
        "    'max_epochs': [10, 20],\n",
        "    'lr': [0.01, 0.05, 0.1],\n",
        "    'optimizer__momentum': [0.7, 0.9],\n",
        "    'optimizer__weight_decay': [1e-4, 1e-3],\n",
        "    'module__dropout_rate': [0.5, 0.6]\n",
        "}\n",
        "\n",
        "MLP_hyper_model = GridSearchCV(hyper_MLP_model, hyper_parameters, refit=True, cv=3, scoring='accuracy', verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "65a93aec-8d5c-4b77-8d22-1affe1047d15",
      "metadata": {
        "id": "65a93aec-8d5c-4b77-8d22-1affe1047d15",
        "outputId": "99768ed3-d883-495e-f21c-1ffd9f9a26d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46840
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.0813\u001b[0m       \u001b[32m0.5546\u001b[0m        \u001b[35m1.4385\u001b[0m  0.8201\n",
            "      2        \u001b[36m1.2780\u001b[0m       \u001b[32m0.6252\u001b[0m        \u001b[35m0.9193\u001b[0m  0.8433\n",
            "      3        \u001b[36m0.9712\u001b[0m       \u001b[32m0.6917\u001b[0m        \u001b[35m0.7687\u001b[0m  0.8288\n",
            "      4        \u001b[36m0.8596\u001b[0m       \u001b[32m0.7239\u001b[0m        \u001b[35m0.7132\u001b[0m  0.8311\n",
            "      5        \u001b[36m0.7964\u001b[0m       0.7228        \u001b[35m0.6724\u001b[0m  0.8288\n",
            "      6        \u001b[36m0.7448\u001b[0m       \u001b[32m0.7622\u001b[0m        \u001b[35m0.6264\u001b[0m  0.8285\n",
            "      7        \u001b[36m0.7015\u001b[0m       \u001b[32m0.7720\u001b[0m        \u001b[35m0.5880\u001b[0m  0.8318\n",
            "      8        \u001b[36m0.6650\u001b[0m       \u001b[32m0.7870\u001b[0m        \u001b[35m0.5618\u001b[0m  0.8370\n",
            "      9        \u001b[36m0.6322\u001b[0m       \u001b[32m0.7951\u001b[0m        \u001b[35m0.5380\u001b[0m  0.8294\n",
            "     10        \u001b[36m0.6036\u001b[0m       \u001b[32m0.8119\u001b[0m        \u001b[35m0.5157\u001b[0m  0.8390\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=   8.8s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.0567\u001b[0m       \u001b[32m0.4976\u001b[0m        \u001b[35m1.3681\u001b[0m  0.8544\n",
            "      2        \u001b[36m1.2532\u001b[0m       \u001b[32m0.5876\u001b[0m        \u001b[35m0.9470\u001b[0m  0.8379\n",
            "      3        \u001b[36m0.9991\u001b[0m       \u001b[32m0.7010\u001b[0m        \u001b[35m0.7811\u001b[0m  0.8485\n",
            "      4        \u001b[36m0.8676\u001b[0m       \u001b[32m0.7312\u001b[0m        \u001b[35m0.7009\u001b[0m  0.8316\n",
            "      5        \u001b[36m0.8004\u001b[0m       \u001b[32m0.7649\u001b[0m        \u001b[35m0.6512\u001b[0m  0.8277\n",
            "      6        \u001b[36m0.7453\u001b[0m       \u001b[32m0.7721\u001b[0m        \u001b[35m0.6033\u001b[0m  0.8219\n",
            "      7        \u001b[36m0.6958\u001b[0m       \u001b[32m0.7931\u001b[0m        \u001b[35m0.5670\u001b[0m  0.8161\n",
            "      8        \u001b[36m0.6602\u001b[0m       \u001b[32m0.8043\u001b[0m        \u001b[35m0.5313\u001b[0m  0.8413\n",
            "      9        \u001b[36m0.6292\u001b[0m       \u001b[32m0.8209\u001b[0m        \u001b[35m0.5061\u001b[0m  0.8297\n",
            "     10        \u001b[36m0.6028\u001b[0m       \u001b[32m0.8249\u001b[0m        \u001b[35m0.4847\u001b[0m  0.8341\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=   8.8s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.0437\u001b[0m       \u001b[32m0.5467\u001b[0m        \u001b[35m1.3065\u001b[0m  0.8284\n",
            "      2        \u001b[36m1.2250\u001b[0m       \u001b[32m0.6284\u001b[0m        \u001b[35m0.9317\u001b[0m  0.8321\n",
            "      3        \u001b[36m0.9777\u001b[0m       \u001b[32m0.7057\u001b[0m        \u001b[35m0.7784\u001b[0m  0.8694\n",
            "      4        \u001b[36m0.8568\u001b[0m       \u001b[32m0.7170\u001b[0m        \u001b[35m0.7006\u001b[0m  0.8751\n",
            "      5        \u001b[36m0.7821\u001b[0m       \u001b[32m0.7444\u001b[0m        \u001b[35m0.6465\u001b[0m  0.8483\n",
            "      6        \u001b[36m0.7293\u001b[0m       \u001b[32m0.7728\u001b[0m        \u001b[35m0.6010\u001b[0m  0.8610\n",
            "      7        \u001b[36m0.6851\u001b[0m       \u001b[32m0.7880\u001b[0m        \u001b[35m0.5654\u001b[0m  0.8387\n",
            "      8        \u001b[36m0.6522\u001b[0m       \u001b[32m0.8150\u001b[0m        \u001b[35m0.5299\u001b[0m  0.8294\n",
            "      9        \u001b[36m0.6238\u001b[0m       \u001b[32m0.8189\u001b[0m        \u001b[35m0.5074\u001b[0m  0.8118\n",
            "     10        \u001b[36m0.5925\u001b[0m       \u001b[32m0.8276\u001b[0m        \u001b[35m0.4876\u001b[0m  0.8229\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=   8.9s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.1288\u001b[0m       \u001b[32m0.5065\u001b[0m        \u001b[35m1.5206\u001b[0m  0.8265\n",
            "      2        \u001b[36m1.3164\u001b[0m       \u001b[32m0.6070\u001b[0m        \u001b[35m0.9668\u001b[0m  0.8300\n",
            "      3        \u001b[36m1.0117\u001b[0m       \u001b[32m0.6806\u001b[0m        \u001b[35m0.8040\u001b[0m  0.8288\n",
            "      4        \u001b[36m0.8824\u001b[0m       \u001b[32m0.7111\u001b[0m        \u001b[35m0.7306\u001b[0m  0.8375\n",
            "      5        \u001b[36m0.8126\u001b[0m       \u001b[32m0.7238\u001b[0m        \u001b[35m0.6925\u001b[0m  0.8472\n",
            "      6        \u001b[36m0.7622\u001b[0m       \u001b[32m0.7318\u001b[0m        \u001b[35m0.6560\u001b[0m  0.8597\n",
            "      7        \u001b[36m0.7189\u001b[0m       \u001b[32m0.7806\u001b[0m        \u001b[35m0.6126\u001b[0m  0.8583\n",
            "      8        \u001b[36m0.6841\u001b[0m       \u001b[32m0.7931\u001b[0m        \u001b[35m0.5841\u001b[0m  0.8560\n",
            "      9        \u001b[36m0.6516\u001b[0m       \u001b[32m0.8013\u001b[0m        \u001b[35m0.5598\u001b[0m  0.8360\n",
            "     10        \u001b[36m0.6214\u001b[0m       \u001b[32m0.8129\u001b[0m        \u001b[35m0.5287\u001b[0m  0.8548\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=   8.9s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.0873\u001b[0m       \u001b[32m0.4611\u001b[0m        \u001b[35m1.4521\u001b[0m  0.8265\n",
            "      2        \u001b[36m1.2923\u001b[0m       \u001b[32m0.6255\u001b[0m        \u001b[35m0.9644\u001b[0m  0.8151\n",
            "      3        \u001b[36m1.0104\u001b[0m       \u001b[32m0.6521\u001b[0m        \u001b[35m0.8043\u001b[0m  0.8284\n",
            "      4        \u001b[36m0.8785\u001b[0m       \u001b[32m0.7040\u001b[0m        \u001b[35m0.7201\u001b[0m  0.8198\n",
            "      5        \u001b[36m0.8112\u001b[0m       \u001b[32m0.7326\u001b[0m        \u001b[35m0.6701\u001b[0m  0.8178\n",
            "      6        \u001b[36m0.7587\u001b[0m       \u001b[32m0.7780\u001b[0m        \u001b[35m0.6263\u001b[0m  0.8363\n",
            "      7        \u001b[36m0.7176\u001b[0m       \u001b[32m0.7886\u001b[0m        \u001b[35m0.5849\u001b[0m  0.8139\n",
            "      8        \u001b[36m0.6808\u001b[0m       \u001b[32m0.7961\u001b[0m        \u001b[35m0.5508\u001b[0m  0.8302\n",
            "      9        \u001b[36m0.6532\u001b[0m       \u001b[32m0.8170\u001b[0m        \u001b[35m0.5254\u001b[0m  0.8397\n",
            "     10        \u001b[36m0.6233\u001b[0m       \u001b[32m0.8243\u001b[0m        \u001b[35m0.5004\u001b[0m  0.8322\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=   8.8s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.1034\u001b[0m       \u001b[32m0.5354\u001b[0m        \u001b[35m1.4320\u001b[0m  0.8501\n",
            "      2        \u001b[36m1.2705\u001b[0m       \u001b[32m0.6190\u001b[0m        \u001b[35m0.9303\u001b[0m  0.8494\n",
            "      3        \u001b[36m0.9844\u001b[0m       \u001b[32m0.6927\u001b[0m        \u001b[35m0.7775\u001b[0m  0.8373\n",
            "      4        \u001b[36m0.8634\u001b[0m       \u001b[32m0.7215\u001b[0m        \u001b[35m0.7036\u001b[0m  0.8200\n",
            "      5        \u001b[36m0.7959\u001b[0m       \u001b[32m0.7548\u001b[0m        \u001b[35m0.6584\u001b[0m  0.8205\n",
            "      6        \u001b[36m0.7424\u001b[0m       \u001b[32m0.7749\u001b[0m        \u001b[35m0.6123\u001b[0m  0.8185\n",
            "      7        \u001b[36m0.7036\u001b[0m       0.7749        \u001b[35m0.5812\u001b[0m  0.8193\n",
            "      8        \u001b[36m0.6633\u001b[0m       \u001b[32m0.8109\u001b[0m        \u001b[35m0.5472\u001b[0m  0.8303\n",
            "      9        \u001b[36m0.6374\u001b[0m       \u001b[32m0.8129\u001b[0m        \u001b[35m0.5138\u001b[0m  0.8375\n",
            "     10        \u001b[36m0.6078\u001b[0m       \u001b[32m0.8269\u001b[0m        \u001b[35m0.4960\u001b[0m  0.8389\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=   8.8s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.5792\u001b[0m       \u001b[32m0.6446\u001b[0m        \u001b[35m0.8730\u001b[0m  0.8623\n",
            "      2        \u001b[36m0.8590\u001b[0m       \u001b[32m0.7588\u001b[0m        \u001b[35m0.6537\u001b[0m  0.8324\n",
            "      3        \u001b[36m0.7012\u001b[0m       \u001b[32m0.7859\u001b[0m        \u001b[35m0.5640\u001b[0m  0.8446\n",
            "      4        \u001b[36m0.6162\u001b[0m       \u001b[32m0.8116\u001b[0m        \u001b[35m0.5211\u001b[0m  0.8449\n",
            "      5        \u001b[36m0.5642\u001b[0m       \u001b[32m0.8287\u001b[0m        \u001b[35m0.4564\u001b[0m  0.8261\n",
            "      6        \u001b[36m0.5260\u001b[0m       \u001b[32m0.8395\u001b[0m        \u001b[35m0.4352\u001b[0m  0.8314\n",
            "      7        \u001b[36m0.5058\u001b[0m       0.8351        0.4380  0.8246\n",
            "      8        \u001b[36m0.4843\u001b[0m       \u001b[32m0.8465\u001b[0m        \u001b[35m0.4107\u001b[0m  0.8363\n",
            "      9        \u001b[36m0.4696\u001b[0m       \u001b[32m0.8546\u001b[0m        \u001b[35m0.3978\u001b[0m  0.8166\n",
            "     10        \u001b[36m0.4523\u001b[0m       \u001b[32m0.8568\u001b[0m        \u001b[35m0.3888\u001b[0m  0.8189\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=   8.8s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.5809\u001b[0m       \u001b[32m0.6606\u001b[0m        \u001b[35m0.8561\u001b[0m  0.8204\n",
            "      2        \u001b[36m0.8620\u001b[0m       \u001b[32m0.7685\u001b[0m        \u001b[35m0.6495\u001b[0m  0.8176\n",
            "      3        \u001b[36m0.7178\u001b[0m       \u001b[32m0.7921\u001b[0m        \u001b[35m0.5455\u001b[0m  0.8386\n",
            "      4        \u001b[36m0.6389\u001b[0m       \u001b[32m0.8244\u001b[0m        \u001b[35m0.4915\u001b[0m  0.8347\n",
            "      5        \u001b[36m0.5877\u001b[0m       \u001b[32m0.8415\u001b[0m        \u001b[35m0.4540\u001b[0m  0.8271\n",
            "      6        \u001b[36m0.5435\u001b[0m       \u001b[32m0.8454\u001b[0m        \u001b[35m0.4340\u001b[0m  0.8279\n",
            "      7        \u001b[36m0.5145\u001b[0m       \u001b[32m0.8482\u001b[0m        \u001b[35m0.4090\u001b[0m  0.8287\n",
            "      8        \u001b[36m0.4930\u001b[0m       \u001b[32m0.8539\u001b[0m        \u001b[35m0.3989\u001b[0m  0.8481\n",
            "      9        \u001b[36m0.4775\u001b[0m       \u001b[32m0.8599\u001b[0m        \u001b[35m0.3876\u001b[0m  0.8227\n",
            "     10        \u001b[36m0.4616\u001b[0m       0.8566        0.3925  0.8469\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=   8.8s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.5988\u001b[0m       \u001b[32m0.6306\u001b[0m        \u001b[35m0.8946\u001b[0m  0.8315\n",
            "      2        \u001b[36m0.8703\u001b[0m       \u001b[32m0.7614\u001b[0m        \u001b[35m0.6466\u001b[0m  0.8177\n",
            "      3        \u001b[36m0.7061\u001b[0m       \u001b[32m0.8091\u001b[0m        \u001b[35m0.5301\u001b[0m  0.8163\n",
            "      4        \u001b[36m0.6125\u001b[0m       \u001b[32m0.8323\u001b[0m        \u001b[35m0.4709\u001b[0m  0.8141\n",
            "      5        \u001b[36m0.5629\u001b[0m       \u001b[32m0.8411\u001b[0m        \u001b[35m0.4402\u001b[0m  0.8247\n",
            "      6        \u001b[36m0.5289\u001b[0m       \u001b[32m0.8469\u001b[0m        \u001b[35m0.4193\u001b[0m  0.8449\n",
            "      7        \u001b[36m0.5017\u001b[0m       \u001b[32m0.8481\u001b[0m        \u001b[35m0.4142\u001b[0m  0.8251\n",
            "      8        \u001b[36m0.4852\u001b[0m       \u001b[32m0.8530\u001b[0m        \u001b[35m0.4010\u001b[0m  0.8195\n",
            "      9        \u001b[36m0.4635\u001b[0m       \u001b[32m0.8610\u001b[0m        \u001b[35m0.3858\u001b[0m  0.8219\n",
            "     10        \u001b[36m0.4561\u001b[0m       \u001b[32m0.8631\u001b[0m        \u001b[35m0.3813\u001b[0m  0.8405\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=   8.8s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.6550\u001b[0m       \u001b[32m0.6315\u001b[0m        \u001b[35m0.8995\u001b[0m  0.8528\n",
            "      2        \u001b[36m0.8785\u001b[0m       \u001b[32m0.7279\u001b[0m        \u001b[35m0.6920\u001b[0m  0.8400\n",
            "      3        \u001b[36m0.7231\u001b[0m       \u001b[32m0.7808\u001b[0m        \u001b[35m0.5909\u001b[0m  0.8434\n",
            "      4        \u001b[36m0.6389\u001b[0m       \u001b[32m0.8103\u001b[0m        \u001b[35m0.5254\u001b[0m  0.8265\n",
            "      5        \u001b[36m0.5827\u001b[0m       \u001b[32m0.8261\u001b[0m        \u001b[35m0.4730\u001b[0m  0.8587\n",
            "      6        \u001b[36m0.5439\u001b[0m       \u001b[32m0.8336\u001b[0m        \u001b[35m0.4522\u001b[0m  0.8412\n",
            "      7        \u001b[36m0.5190\u001b[0m       \u001b[32m0.8393\u001b[0m        \u001b[35m0.4410\u001b[0m  0.8300\n",
            "      8        \u001b[36m0.5027\u001b[0m       \u001b[32m0.8465\u001b[0m        \u001b[35m0.4238\u001b[0m  0.8309\n",
            "      9        \u001b[36m0.4818\u001b[0m       \u001b[32m0.8474\u001b[0m        \u001b[35m0.4154\u001b[0m  0.8376\n",
            "     10        \u001b[36m0.4708\u001b[0m       \u001b[32m0.8544\u001b[0m        \u001b[35m0.3983\u001b[0m  0.8327\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=   8.9s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.5844\u001b[0m       \u001b[32m0.6312\u001b[0m        \u001b[35m0.8605\u001b[0m  0.8254\n",
            "      2        \u001b[36m0.8631\u001b[0m       \u001b[32m0.7501\u001b[0m        \u001b[35m0.6675\u001b[0m  0.8286\n",
            "      3        \u001b[36m0.7304\u001b[0m       \u001b[32m0.7844\u001b[0m        \u001b[35m0.5640\u001b[0m  0.8371\n",
            "      4        \u001b[36m0.6405\u001b[0m       \u001b[32m0.8190\u001b[0m        \u001b[35m0.5094\u001b[0m  0.8271\n",
            "      5        \u001b[36m0.5861\u001b[0m       \u001b[32m0.8223\u001b[0m        \u001b[35m0.4831\u001b[0m  0.8362\n",
            "      6        \u001b[36m0.5464\u001b[0m       \u001b[32m0.8449\u001b[0m        \u001b[35m0.4325\u001b[0m  0.8201\n",
            "      7        \u001b[36m0.5221\u001b[0m       \u001b[32m0.8455\u001b[0m        \u001b[35m0.4271\u001b[0m  0.8286\n",
            "      8        \u001b[36m0.4991\u001b[0m       \u001b[32m0.8578\u001b[0m        \u001b[35m0.4032\u001b[0m  0.8299\n",
            "      9        \u001b[36m0.4821\u001b[0m       0.8555        \u001b[35m0.4013\u001b[0m  0.8374\n",
            "     10        \u001b[36m0.4700\u001b[0m       \u001b[32m0.8582\u001b[0m        \u001b[35m0.3930\u001b[0m  0.8350\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=   8.8s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.5936\u001b[0m       \u001b[32m0.6556\u001b[0m        \u001b[35m0.8335\u001b[0m  0.8439\n",
            "      2        \u001b[36m0.8369\u001b[0m       \u001b[32m0.7602\u001b[0m        \u001b[35m0.6245\u001b[0m  0.8357\n",
            "      3        \u001b[36m0.6927\u001b[0m       \u001b[32m0.8156\u001b[0m        \u001b[35m0.5331\u001b[0m  0.8267\n",
            "      4        \u001b[36m0.6079\u001b[0m       \u001b[32m0.8226\u001b[0m        \u001b[35m0.4900\u001b[0m  0.8287\n",
            "      5        \u001b[36m0.5666\u001b[0m       \u001b[32m0.8410\u001b[0m        \u001b[35m0.4490\u001b[0m  0.8295\n",
            "      6        \u001b[36m0.5313\u001b[0m       \u001b[32m0.8460\u001b[0m        \u001b[35m0.4265\u001b[0m  0.8317\n",
            "      7        \u001b[36m0.5069\u001b[0m       \u001b[32m0.8486\u001b[0m        \u001b[35m0.4195\u001b[0m  0.8457\n",
            "      8        \u001b[36m0.4902\u001b[0m       0.8454        \u001b[35m0.4192\u001b[0m  0.8548\n",
            "      9        \u001b[36m0.4698\u001b[0m       \u001b[32m0.8560\u001b[0m        \u001b[35m0.3948\u001b[0m  0.8306\n",
            "     10        \u001b[36m0.4637\u001b[0m       0.8549        \u001b[35m0.3907\u001b[0m  0.8412\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=   8.9s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.1690\u001b[0m       \u001b[32m0.4110\u001b[0m        \u001b[35m1.5874\u001b[0m  0.8194\n",
            "      2        \u001b[36m1.4078\u001b[0m       \u001b[32m0.5774\u001b[0m        \u001b[35m1.0360\u001b[0m  0.8363\n",
            "      3        \u001b[36m1.1033\u001b[0m       \u001b[32m0.6567\u001b[0m        \u001b[35m0.8437\u001b[0m  0.8762\n",
            "      4        \u001b[36m0.9424\u001b[0m       \u001b[32m0.7056\u001b[0m        \u001b[35m0.7602\u001b[0m  0.8748\n",
            "      5        \u001b[36m0.8601\u001b[0m       \u001b[32m0.7325\u001b[0m        \u001b[35m0.7083\u001b[0m  0.8211\n",
            "      6        \u001b[36m0.8044\u001b[0m       \u001b[32m0.7489\u001b[0m        \u001b[35m0.6629\u001b[0m  0.8361\n",
            "      7        \u001b[36m0.7624\u001b[0m       \u001b[32m0.7678\u001b[0m        \u001b[35m0.6261\u001b[0m  0.8259\n",
            "      8        \u001b[36m0.7197\u001b[0m       \u001b[32m0.7755\u001b[0m        \u001b[35m0.5981\u001b[0m  0.8181\n",
            "      9        \u001b[36m0.6907\u001b[0m       \u001b[32m0.7977\u001b[0m        \u001b[35m0.5639\u001b[0m  0.8227\n",
            "     10        \u001b[36m0.6612\u001b[0m       \u001b[32m0.8015\u001b[0m        \u001b[35m0.5370\u001b[0m  0.8539\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=   8.9s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.1113\u001b[0m       \u001b[32m0.4140\u001b[0m        \u001b[35m1.4663\u001b[0m  0.8495\n",
            "      2        \u001b[36m1.3554\u001b[0m       \u001b[32m0.5897\u001b[0m        \u001b[35m1.0510\u001b[0m  0.8314\n",
            "      3        \u001b[36m1.1194\u001b[0m       \u001b[32m0.6296\u001b[0m        \u001b[35m0.8927\u001b[0m  0.8466\n",
            "      4        \u001b[36m0.9876\u001b[0m       \u001b[32m0.6740\u001b[0m        \u001b[35m0.7844\u001b[0m  0.8186\n",
            "      5        \u001b[36m0.8958\u001b[0m       \u001b[32m0.7241\u001b[0m        \u001b[35m0.7073\u001b[0m  0.8260\n",
            "      6        \u001b[36m0.8329\u001b[0m       \u001b[32m0.7506\u001b[0m        \u001b[35m0.6647\u001b[0m  0.8311\n",
            "      7        \u001b[36m0.7825\u001b[0m       \u001b[32m0.7701\u001b[0m        \u001b[35m0.6301\u001b[0m  0.8328\n",
            "      8        \u001b[36m0.7485\u001b[0m       \u001b[32m0.7748\u001b[0m        \u001b[35m0.5991\u001b[0m  0.8251\n",
            "      9        \u001b[36m0.7167\u001b[0m       \u001b[32m0.7937\u001b[0m        \u001b[35m0.5683\u001b[0m  0.8138\n",
            "     10        \u001b[36m0.6835\u001b[0m       \u001b[32m0.8081\u001b[0m        \u001b[35m0.5423\u001b[0m  0.8271\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=   8.8s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.1441\u001b[0m       \u001b[32m0.4605\u001b[0m        \u001b[35m1.5622\u001b[0m  0.8382\n",
            "      2        \u001b[36m1.4044\u001b[0m       \u001b[32m0.5925\u001b[0m        \u001b[35m1.0441\u001b[0m  0.8220\n",
            "      3        \u001b[36m1.1332\u001b[0m       \u001b[32m0.6054\u001b[0m        \u001b[35m0.9041\u001b[0m  0.8264\n",
            "      4        \u001b[36m1.0054\u001b[0m       \u001b[32m0.7134\u001b[0m        \u001b[35m0.7952\u001b[0m  0.8301\n",
            "      5        \u001b[36m0.9046\u001b[0m       \u001b[32m0.7361\u001b[0m        \u001b[35m0.7105\u001b[0m  0.8593\n",
            "      6        \u001b[36m0.8325\u001b[0m       \u001b[32m0.7571\u001b[0m        \u001b[35m0.6585\u001b[0m  0.8369\n",
            "      7        \u001b[36m0.7782\u001b[0m       \u001b[32m0.7716\u001b[0m        \u001b[35m0.6189\u001b[0m  0.8271\n",
            "      8        \u001b[36m0.7372\u001b[0m       \u001b[32m0.7825\u001b[0m        \u001b[35m0.5802\u001b[0m  0.8335\n",
            "      9        \u001b[36m0.6979\u001b[0m       \u001b[32m0.7919\u001b[0m        \u001b[35m0.5503\u001b[0m  0.8216\n",
            "     10        \u001b[36m0.6675\u001b[0m       \u001b[32m0.8134\u001b[0m        \u001b[35m0.5225\u001b[0m  0.8261\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=   8.8s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.1295\u001b[0m       \u001b[32m0.4181\u001b[0m        \u001b[35m1.5190\u001b[0m  0.8122\n",
            "      2        \u001b[36m1.3800\u001b[0m       \u001b[32m0.5637\u001b[0m        \u001b[35m1.0323\u001b[0m  0.8166\n",
            "      3        \u001b[36m1.1072\u001b[0m       \u001b[32m0.6284\u001b[0m        \u001b[35m0.8707\u001b[0m  0.8159\n",
            "      4        \u001b[36m0.9700\u001b[0m       \u001b[32m0.6844\u001b[0m        \u001b[35m0.7733\u001b[0m  0.8378\n",
            "      5        \u001b[36m0.8829\u001b[0m       \u001b[32m0.7334\u001b[0m        \u001b[35m0.7088\u001b[0m  0.8283\n",
            "      6        \u001b[36m0.8192\u001b[0m       0.7306        \u001b[35m0.6716\u001b[0m  0.8087\n",
            "      7        \u001b[36m0.7715\u001b[0m       \u001b[32m0.7548\u001b[0m        \u001b[35m0.6313\u001b[0m  0.8356\n",
            "      8        \u001b[36m0.7290\u001b[0m       \u001b[32m0.7725\u001b[0m        \u001b[35m0.6014\u001b[0m  0.8446\n",
            "      9        \u001b[36m0.6949\u001b[0m       0.7685        \u001b[35m0.5805\u001b[0m  0.8589\n",
            "     10        \u001b[36m0.6695\u001b[0m       \u001b[32m0.7867\u001b[0m        \u001b[35m0.5507\u001b[0m  0.8397\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=   8.8s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.2244\u001b[0m       \u001b[32m0.3509\u001b[0m        \u001b[35m1.8543\u001b[0m  0.8380\n",
            "      2        \u001b[36m1.4998\u001b[0m       \u001b[32m0.5803\u001b[0m        \u001b[35m1.0742\u001b[0m  0.8490\n",
            "      3        \u001b[36m1.1362\u001b[0m       \u001b[32m0.6252\u001b[0m        \u001b[35m0.8742\u001b[0m  0.8292\n",
            "      4        \u001b[36m0.9789\u001b[0m       \u001b[32m0.6860\u001b[0m        \u001b[35m0.7717\u001b[0m  0.8316\n",
            "      5        \u001b[36m0.8903\u001b[0m       \u001b[32m0.7149\u001b[0m        \u001b[35m0.7128\u001b[0m  0.8338\n",
            "      6        \u001b[36m0.8326\u001b[0m       \u001b[32m0.7490\u001b[0m        \u001b[35m0.6727\u001b[0m  0.8298\n",
            "      7        \u001b[36m0.7862\u001b[0m       \u001b[32m0.7714\u001b[0m        \u001b[35m0.6339\u001b[0m  0.8575\n",
            "      8        \u001b[36m0.7474\u001b[0m       \u001b[32m0.7782\u001b[0m        \u001b[35m0.6015\u001b[0m  0.8498\n",
            "      9        \u001b[36m0.7108\u001b[0m       \u001b[32m0.7881\u001b[0m        \u001b[35m0.5634\u001b[0m  0.8277\n",
            "     10        \u001b[36m0.6844\u001b[0m       \u001b[32m0.7975\u001b[0m        \u001b[35m0.5391\u001b[0m  0.8244\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=   8.9s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.1461\u001b[0m       \u001b[32m0.5351\u001b[0m        \u001b[35m1.5483\u001b[0m  0.8243\n",
            "      2        \u001b[36m1.4043\u001b[0m       \u001b[32m0.5735\u001b[0m        \u001b[35m1.0523\u001b[0m  0.8519\n",
            "      3        \u001b[36m1.1286\u001b[0m       \u001b[32m0.6492\u001b[0m        \u001b[35m0.8921\u001b[0m  0.8467\n",
            "      4        \u001b[36m0.9816\u001b[0m       \u001b[32m0.6844\u001b[0m        \u001b[35m0.7887\u001b[0m  0.8363\n",
            "      5        \u001b[36m0.8891\u001b[0m       \u001b[32m0.7202\u001b[0m        \u001b[35m0.7203\u001b[0m  0.8251\n",
            "      6        \u001b[36m0.8334\u001b[0m       \u001b[32m0.7502\u001b[0m        \u001b[35m0.6759\u001b[0m  0.8248\n",
            "      7        \u001b[36m0.7822\u001b[0m       \u001b[32m0.7605\u001b[0m        \u001b[35m0.6498\u001b[0m  0.8263\n",
            "      8        \u001b[36m0.7484\u001b[0m       \u001b[32m0.7731\u001b[0m        \u001b[35m0.6114\u001b[0m  0.8191\n",
            "      9        \u001b[36m0.7137\u001b[0m       \u001b[32m0.7815\u001b[0m        \u001b[35m0.5818\u001b[0m  0.8270\n",
            "     10        \u001b[36m0.6900\u001b[0m       \u001b[32m0.7867\u001b[0m        \u001b[35m0.5570\u001b[0m  0.8225\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=   8.8s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.7029\u001b[0m       \u001b[32m0.6072\u001b[0m        \u001b[35m0.9547\u001b[0m  0.8243\n",
            "      2        \u001b[36m0.9519\u001b[0m       \u001b[32m0.7169\u001b[0m        \u001b[35m0.7191\u001b[0m  0.8280\n",
            "      3        \u001b[36m0.7844\u001b[0m       \u001b[32m0.7604\u001b[0m        \u001b[35m0.6296\u001b[0m  0.8344\n",
            "      4        \u001b[36m0.6995\u001b[0m       \u001b[32m0.7866\u001b[0m        \u001b[35m0.5485\u001b[0m  0.8389\n",
            "      5        \u001b[36m0.6431\u001b[0m       \u001b[32m0.8010\u001b[0m        \u001b[35m0.5136\u001b[0m  0.8732\n",
            "      6        \u001b[36m0.6081\u001b[0m       \u001b[32m0.8241\u001b[0m        \u001b[35m0.4795\u001b[0m  0.8460\n",
            "      7        \u001b[36m0.5725\u001b[0m       \u001b[32m0.8269\u001b[0m        \u001b[35m0.4597\u001b[0m  0.8506\n",
            "      8        \u001b[36m0.5442\u001b[0m       \u001b[32m0.8386\u001b[0m        \u001b[35m0.4337\u001b[0m  0.8240\n",
            "      9        \u001b[36m0.5251\u001b[0m       \u001b[32m0.8454\u001b[0m        \u001b[35m0.4228\u001b[0m  0.8060\n",
            "     10        \u001b[36m0.5122\u001b[0m       0.8454        \u001b[35m0.4179\u001b[0m  0.8160\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=   8.8s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.6560\u001b[0m       \u001b[32m0.6185\u001b[0m        \u001b[35m0.9261\u001b[0m  0.8227\n",
            "      2        \u001b[36m0.9386\u001b[0m       \u001b[32m0.7570\u001b[0m        \u001b[35m0.6796\u001b[0m  0.8118\n",
            "      3        \u001b[36m0.7707\u001b[0m       \u001b[32m0.7890\u001b[0m        \u001b[35m0.5812\u001b[0m  0.8217\n",
            "      4        \u001b[36m0.6932\u001b[0m       \u001b[32m0.8044\u001b[0m        \u001b[35m0.5244\u001b[0m  0.8249\n",
            "      5        \u001b[36m0.6333\u001b[0m       \u001b[32m0.8257\u001b[0m        \u001b[35m0.4798\u001b[0m  0.8228\n",
            "      6        \u001b[36m0.6012\u001b[0m       \u001b[32m0.8335\u001b[0m        \u001b[35m0.4707\u001b[0m  0.8177\n",
            "      7        \u001b[36m0.5708\u001b[0m       \u001b[32m0.8424\u001b[0m        \u001b[35m0.4371\u001b[0m  0.8269\n",
            "      8        \u001b[36m0.5514\u001b[0m       \u001b[32m0.8496\u001b[0m        \u001b[35m0.4239\u001b[0m  0.8304\n",
            "      9        \u001b[36m0.5317\u001b[0m       0.8488        \u001b[35m0.4157\u001b[0m  0.8671\n",
            "     10        \u001b[36m0.5156\u001b[0m       \u001b[32m0.8518\u001b[0m        \u001b[35m0.4057\u001b[0m  0.8466\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=   8.8s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.6616\u001b[0m       \u001b[32m0.6132\u001b[0m        \u001b[35m0.9412\u001b[0m  0.8417\n",
            "      2        \u001b[36m0.9434\u001b[0m       \u001b[32m0.7392\u001b[0m        \u001b[35m0.6784\u001b[0m  0.8298\n",
            "      3        \u001b[36m0.7715\u001b[0m       \u001b[32m0.7705\u001b[0m        \u001b[35m0.5882\u001b[0m  0.8379\n",
            "      4        \u001b[36m0.6861\u001b[0m       \u001b[32m0.8010\u001b[0m        \u001b[35m0.5230\u001b[0m  0.8200\n",
            "      5        \u001b[36m0.6306\u001b[0m       \u001b[32m0.8225\u001b[0m        \u001b[35m0.4808\u001b[0m  0.8233\n",
            "      6        \u001b[36m0.5925\u001b[0m       \u001b[32m0.8355\u001b[0m        \u001b[35m0.4566\u001b[0m  0.8285\n",
            "      7        \u001b[36m0.5627\u001b[0m       \u001b[32m0.8426\u001b[0m        \u001b[35m0.4356\u001b[0m  0.8266\n",
            "      8        \u001b[36m0.5406\u001b[0m       \u001b[32m0.8490\u001b[0m        \u001b[35m0.4169\u001b[0m  0.8289\n",
            "      9        \u001b[36m0.5268\u001b[0m       \u001b[32m0.8505\u001b[0m        \u001b[35m0.4097\u001b[0m  0.8311\n",
            "     10        \u001b[36m0.5126\u001b[0m       0.8450        \u001b[35m0.4074\u001b[0m  0.8300\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=   8.8s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.6943\u001b[0m       \u001b[32m0.5464\u001b[0m        \u001b[35m0.9921\u001b[0m  0.8449\n",
            "      2        \u001b[36m0.9675\u001b[0m       \u001b[32m0.7200\u001b[0m        \u001b[35m0.7170\u001b[0m  0.8696\n",
            "      3        \u001b[36m0.7946\u001b[0m       \u001b[32m0.7655\u001b[0m        \u001b[35m0.6230\u001b[0m  0.8371\n",
            "      4        \u001b[36m0.7130\u001b[0m       \u001b[32m0.7799\u001b[0m        \u001b[35m0.5683\u001b[0m  0.8397\n",
            "      5        \u001b[36m0.6548\u001b[0m       \u001b[32m0.7959\u001b[0m        \u001b[35m0.5259\u001b[0m  0.8228\n",
            "      6        \u001b[36m0.6125\u001b[0m       \u001b[32m0.8219\u001b[0m        \u001b[35m0.4795\u001b[0m  0.8270\n",
            "      7        \u001b[36m0.5815\u001b[0m       \u001b[32m0.8254\u001b[0m        \u001b[35m0.4693\u001b[0m  0.8291\n",
            "      8        \u001b[36m0.5592\u001b[0m       \u001b[32m0.8355\u001b[0m        \u001b[35m0.4528\u001b[0m  0.8231\n",
            "      9        \u001b[36m0.5406\u001b[0m       \u001b[32m0.8419\u001b[0m        \u001b[35m0.4374\u001b[0m  0.8277\n",
            "     10        \u001b[36m0.5262\u001b[0m       \u001b[32m0.8449\u001b[0m        \u001b[35m0.4187\u001b[0m  0.8194\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=   8.8s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.7626\u001b[0m       \u001b[32m0.5711\u001b[0m        \u001b[35m0.9865\u001b[0m  0.8213\n",
            "      2        \u001b[36m0.9784\u001b[0m       \u001b[32m0.7405\u001b[0m        \u001b[35m0.7030\u001b[0m  0.8468\n",
            "      3        \u001b[36m0.7940\u001b[0m       \u001b[32m0.7722\u001b[0m        \u001b[35m0.6056\u001b[0m  0.8191\n",
            "      4        \u001b[36m0.7056\u001b[0m       \u001b[32m0.7906\u001b[0m        \u001b[35m0.5432\u001b[0m  0.8530\n",
            "      5        \u001b[36m0.6541\u001b[0m       \u001b[32m0.8194\u001b[0m        \u001b[35m0.5083\u001b[0m  0.8697\n",
            "      6        \u001b[36m0.6128\u001b[0m       \u001b[32m0.8319\u001b[0m        \u001b[35m0.4754\u001b[0m  0.8513\n",
            "      7        \u001b[36m0.5793\u001b[0m       \u001b[32m0.8391\u001b[0m        \u001b[35m0.4499\u001b[0m  0.8443\n",
            "      8        \u001b[36m0.5578\u001b[0m       \u001b[32m0.8454\u001b[0m        \u001b[35m0.4284\u001b[0m  0.8357\n",
            "      9        \u001b[36m0.5419\u001b[0m       \u001b[32m0.8478\u001b[0m        \u001b[35m0.4168\u001b[0m  0.8336\n",
            "     10        \u001b[36m0.5230\u001b[0m       \u001b[32m0.8539\u001b[0m        \u001b[35m0.4095\u001b[0m  0.8472\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=   8.9s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.6718\u001b[0m       \u001b[32m0.5978\u001b[0m        \u001b[35m0.9514\u001b[0m  0.8397\n",
            "      2        \u001b[36m0.9549\u001b[0m       \u001b[32m0.7195\u001b[0m        \u001b[35m0.7056\u001b[0m  0.8469\n",
            "      3        \u001b[36m0.7848\u001b[0m       \u001b[32m0.7738\u001b[0m        \u001b[35m0.6076\u001b[0m  0.8490\n",
            "      4        \u001b[36m0.6970\u001b[0m       \u001b[32m0.7936\u001b[0m        \u001b[35m0.5466\u001b[0m  0.8908\n",
            "      5        \u001b[36m0.6484\u001b[0m       \u001b[32m0.8024\u001b[0m        \u001b[35m0.5106\u001b[0m  0.8609\n",
            "      6        \u001b[36m0.6096\u001b[0m       \u001b[32m0.8274\u001b[0m        \u001b[35m0.4778\u001b[0m  0.8684\n",
            "      7        \u001b[36m0.5806\u001b[0m       \u001b[32m0.8427\u001b[0m        \u001b[35m0.4538\u001b[0m  0.8689\n",
            "      8        \u001b[36m0.5532\u001b[0m       \u001b[32m0.8476\u001b[0m        \u001b[35m0.4334\u001b[0m  0.8631\n",
            "      9        \u001b[36m0.5356\u001b[0m       \u001b[32m0.8491\u001b[0m        \u001b[35m0.4233\u001b[0m  0.8840\n",
            "     10        \u001b[36m0.5204\u001b[0m       \u001b[32m0.8511\u001b[0m        \u001b[35m0.4062\u001b[0m  0.8619\n",
            "[CV] END lr=0.01, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=   9.1s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.1539\u001b[0m       \u001b[32m0.4510\u001b[0m        \u001b[35m1.5207\u001b[0m  0.8362\n",
            "      2        \u001b[36m1.2906\u001b[0m       \u001b[32m0.5899\u001b[0m        \u001b[35m0.9610\u001b[0m  0.8236\n",
            "      3        \u001b[36m1.0099\u001b[0m       \u001b[32m0.7019\u001b[0m        \u001b[35m0.8071\u001b[0m  0.8253\n",
            "      4        \u001b[36m0.8680\u001b[0m       \u001b[32m0.7324\u001b[0m        \u001b[35m0.7151\u001b[0m  0.8352\n",
            "      5        \u001b[36m0.7869\u001b[0m       \u001b[32m0.7501\u001b[0m        \u001b[35m0.6548\u001b[0m  0.8177\n",
            "      6        \u001b[36m0.7311\u001b[0m       \u001b[32m0.7652\u001b[0m        \u001b[35m0.6106\u001b[0m  0.8370\n",
            "      7        \u001b[36m0.6834\u001b[0m       \u001b[32m0.7811\u001b[0m        \u001b[35m0.5738\u001b[0m  0.8355\n",
            "      8        \u001b[36m0.6480\u001b[0m       \u001b[32m0.7930\u001b[0m        \u001b[35m0.5448\u001b[0m  0.8432\n",
            "      9        \u001b[36m0.6179\u001b[0m       \u001b[32m0.8077\u001b[0m        \u001b[35m0.5215\u001b[0m  0.8464\n",
            "     10        \u001b[36m0.5915\u001b[0m       \u001b[32m0.8136\u001b[0m        \u001b[35m0.4956\u001b[0m  0.8427\n",
            "     11        \u001b[36m0.5675\u001b[0m       \u001b[32m0.8209\u001b[0m        \u001b[35m0.4862\u001b[0m  0.8660\n",
            "     12        \u001b[36m0.5466\u001b[0m       \u001b[32m0.8315\u001b[0m        \u001b[35m0.4592\u001b[0m  0.8679\n",
            "     13        \u001b[36m0.5293\u001b[0m       \u001b[32m0.8355\u001b[0m        \u001b[35m0.4494\u001b[0m  0.8445\n",
            "     14        \u001b[36m0.5165\u001b[0m       \u001b[32m0.8375\u001b[0m        \u001b[35m0.4429\u001b[0m  0.8471\n",
            "     15        \u001b[36m0.5029\u001b[0m       \u001b[32m0.8433\u001b[0m        \u001b[35m0.4267\u001b[0m  0.8289\n",
            "     16        \u001b[36m0.4924\u001b[0m       0.8410        0.4277  0.8189\n",
            "     17        \u001b[36m0.4867\u001b[0m       \u001b[32m0.8478\u001b[0m        \u001b[35m0.4117\u001b[0m  0.8148\n",
            "     18        \u001b[36m0.4720\u001b[0m       \u001b[32m0.8536\u001b[0m        \u001b[35m0.4030\u001b[0m  0.8184\n",
            "     19        \u001b[36m0.4642\u001b[0m       0.8535        0.4046  0.8244\n",
            "     20        \u001b[36m0.4513\u001b[0m       \u001b[32m0.8561\u001b[0m        \u001b[35m0.3937\u001b[0m  0.8475\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=  17.3s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.1064\u001b[0m       \u001b[32m0.5095\u001b[0m        \u001b[35m1.4299\u001b[0m  0.8253\n",
            "      2        \u001b[36m1.2606\u001b[0m       \u001b[32m0.6190\u001b[0m        \u001b[35m0.9307\u001b[0m  0.8350\n",
            "      3        \u001b[36m0.9932\u001b[0m       \u001b[32m0.6567\u001b[0m        \u001b[35m0.7881\u001b[0m  0.8377\n",
            "      4        \u001b[36m0.8693\u001b[0m       \u001b[32m0.7341\u001b[0m        \u001b[35m0.7038\u001b[0m  0.8412\n",
            "      5        \u001b[36m0.7906\u001b[0m       \u001b[32m0.7704\u001b[0m        \u001b[35m0.6436\u001b[0m  0.8341\n",
            "      6        \u001b[36m0.7417\u001b[0m       \u001b[32m0.7786\u001b[0m        \u001b[35m0.6014\u001b[0m  0.8547\n",
            "      7        \u001b[36m0.6965\u001b[0m       \u001b[32m0.7985\u001b[0m        \u001b[35m0.5584\u001b[0m  0.8714\n",
            "      8        \u001b[36m0.6561\u001b[0m       \u001b[32m0.8027\u001b[0m        \u001b[35m0.5346\u001b[0m  0.8347\n",
            "      9        \u001b[36m0.6265\u001b[0m       \u001b[32m0.8190\u001b[0m        \u001b[35m0.5086\u001b[0m  0.8330\n",
            "     10        \u001b[36m0.5999\u001b[0m       \u001b[32m0.8247\u001b[0m        \u001b[35m0.4835\u001b[0m  0.8510\n",
            "     11        \u001b[36m0.5773\u001b[0m       \u001b[32m0.8319\u001b[0m        \u001b[35m0.4630\u001b[0m  0.8311\n",
            "     12        \u001b[36m0.5547\u001b[0m       \u001b[32m0.8356\u001b[0m        \u001b[35m0.4615\u001b[0m  0.8411\n",
            "     13        \u001b[36m0.5406\u001b[0m       \u001b[32m0.8413\u001b[0m        \u001b[35m0.4378\u001b[0m  0.8255\n",
            "     14        \u001b[36m0.5256\u001b[0m       \u001b[32m0.8450\u001b[0m        \u001b[35m0.4272\u001b[0m  0.8264\n",
            "     15        \u001b[36m0.5103\u001b[0m       \u001b[32m0.8471\u001b[0m        \u001b[35m0.4199\u001b[0m  0.8429\n",
            "     16        \u001b[36m0.5004\u001b[0m       \u001b[32m0.8504\u001b[0m        \u001b[35m0.4089\u001b[0m  0.8342\n",
            "     17        \u001b[36m0.4860\u001b[0m       \u001b[32m0.8564\u001b[0m        \u001b[35m0.4037\u001b[0m  0.8362\n",
            "     18        \u001b[36m0.4780\u001b[0m       0.8564        \u001b[35m0.3934\u001b[0m  0.8502\n",
            "     19        \u001b[36m0.4651\u001b[0m       \u001b[32m0.8579\u001b[0m        \u001b[35m0.3921\u001b[0m  0.8343\n",
            "     20        \u001b[36m0.4623\u001b[0m       \u001b[32m0.8606\u001b[0m        \u001b[35m0.3861\u001b[0m  0.8594\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=  17.4s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.0777\u001b[0m       \u001b[32m0.4990\u001b[0m        \u001b[35m1.3777\u001b[0m  0.8565\n",
            "      2        \u001b[36m1.2539\u001b[0m       \u001b[32m0.6090\u001b[0m        \u001b[35m0.9471\u001b[0m  0.8147\n",
            "      3        \u001b[36m0.9954\u001b[0m       \u001b[32m0.6993\u001b[0m        \u001b[35m0.7815\u001b[0m  0.8279\n",
            "      4        \u001b[36m0.8608\u001b[0m       \u001b[32m0.7384\u001b[0m        \u001b[35m0.6926\u001b[0m  0.8167\n",
            "      5        \u001b[36m0.7853\u001b[0m       \u001b[32m0.7674\u001b[0m        \u001b[35m0.6369\u001b[0m  0.8292\n",
            "      6        \u001b[36m0.7304\u001b[0m       \u001b[32m0.7804\u001b[0m        \u001b[35m0.5887\u001b[0m  0.8330\n",
            "      7        \u001b[36m0.6816\u001b[0m       \u001b[32m0.8011\u001b[0m        \u001b[35m0.5550\u001b[0m  0.8332\n",
            "      8        \u001b[36m0.6471\u001b[0m       \u001b[32m0.8081\u001b[0m        \u001b[35m0.5278\u001b[0m  0.8549\n",
            "      9        \u001b[36m0.6196\u001b[0m       \u001b[32m0.8134\u001b[0m        \u001b[35m0.5048\u001b[0m  0.8367\n",
            "     10        \u001b[36m0.5916\u001b[0m       \u001b[32m0.8273\u001b[0m        \u001b[35m0.4820\u001b[0m  0.8309\n",
            "     11        \u001b[36m0.5713\u001b[0m       \u001b[32m0.8357\u001b[0m        \u001b[35m0.4660\u001b[0m  0.8449\n",
            "     12        \u001b[36m0.5519\u001b[0m       0.8340        \u001b[35m0.4546\u001b[0m  0.8515\n",
            "     13        \u001b[36m0.5333\u001b[0m       \u001b[32m0.8425\u001b[0m        \u001b[35m0.4433\u001b[0m  0.8650\n",
            "     14        \u001b[36m0.5167\u001b[0m       \u001b[32m0.8462\u001b[0m        \u001b[35m0.4224\u001b[0m  0.8757\n",
            "     15        \u001b[36m0.5087\u001b[0m       \u001b[32m0.8485\u001b[0m        \u001b[35m0.4179\u001b[0m  0.8411\n",
            "     16        \u001b[36m0.4997\u001b[0m       \u001b[32m0.8538\u001b[0m        \u001b[35m0.4089\u001b[0m  0.8286\n",
            "     17        \u001b[36m0.4848\u001b[0m       0.8521        \u001b[35m0.4047\u001b[0m  0.8179\n",
            "     18        \u001b[36m0.4760\u001b[0m       \u001b[32m0.8575\u001b[0m        \u001b[35m0.3970\u001b[0m  0.8271\n",
            "     19        \u001b[36m0.4685\u001b[0m       \u001b[32m0.8596\u001b[0m        \u001b[35m0.3912\u001b[0m  0.8297\n",
            "     20        \u001b[36m0.4594\u001b[0m       \u001b[32m0.8620\u001b[0m        \u001b[35m0.3811\u001b[0m  0.8259\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=  17.3s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.0576\u001b[0m       \u001b[32m0.4879\u001b[0m        \u001b[35m1.4056\u001b[0m  0.8560\n",
            "      2        \u001b[36m1.2738\u001b[0m       \u001b[32m0.6240\u001b[0m        \u001b[35m0.9671\u001b[0m  0.8203\n",
            "      3        \u001b[36m1.0090\u001b[0m       \u001b[32m0.6831\u001b[0m        \u001b[35m0.8116\u001b[0m  0.8312\n",
            "      4        \u001b[36m0.8864\u001b[0m       \u001b[32m0.7106\u001b[0m        \u001b[35m0.7312\u001b[0m  0.8306\n",
            "      5        \u001b[36m0.8118\u001b[0m       \u001b[32m0.7264\u001b[0m        \u001b[35m0.6871\u001b[0m  0.8710\n",
            "      6        \u001b[36m0.7532\u001b[0m       \u001b[32m0.7591\u001b[0m        \u001b[35m0.6388\u001b[0m  0.8710\n",
            "      7        \u001b[36m0.7137\u001b[0m       \u001b[32m0.7863\u001b[0m        \u001b[35m0.5999\u001b[0m  0.8783\n",
            "      8        \u001b[36m0.6753\u001b[0m       \u001b[32m0.7981\u001b[0m        \u001b[35m0.5677\u001b[0m  0.8586\n",
            "      9        \u001b[36m0.6406\u001b[0m       \u001b[32m0.8096\u001b[0m        \u001b[35m0.5380\u001b[0m  0.8305\n",
            "     10        \u001b[36m0.6110\u001b[0m       \u001b[32m0.8141\u001b[0m        \u001b[35m0.5144\u001b[0m  0.8278\n",
            "     11        \u001b[36m0.5872\u001b[0m       \u001b[32m0.8227\u001b[0m        \u001b[35m0.4950\u001b[0m  0.8219\n",
            "     12        \u001b[36m0.5671\u001b[0m       \u001b[32m0.8230\u001b[0m        \u001b[35m0.4776\u001b[0m  0.8339\n",
            "     13        \u001b[36m0.5490\u001b[0m       \u001b[32m0.8309\u001b[0m        \u001b[35m0.4718\u001b[0m  0.8438\n",
            "     14        \u001b[36m0.5350\u001b[0m       \u001b[32m0.8376\u001b[0m        \u001b[35m0.4553\u001b[0m  0.8535\n",
            "     15        \u001b[36m0.5240\u001b[0m       \u001b[32m0.8395\u001b[0m        \u001b[35m0.4395\u001b[0m  0.8509\n",
            "     16        \u001b[36m0.5118\u001b[0m       \u001b[32m0.8439\u001b[0m        \u001b[35m0.4359\u001b[0m  0.8366\n",
            "     17        \u001b[36m0.5026\u001b[0m       \u001b[32m0.8480\u001b[0m        \u001b[35m0.4249\u001b[0m  0.8381\n",
            "     18        \u001b[36m0.4932\u001b[0m       0.8439        \u001b[35m0.4206\u001b[0m  0.8455\n",
            "     19        \u001b[36m0.4781\u001b[0m       \u001b[32m0.8494\u001b[0m        \u001b[35m0.4136\u001b[0m  0.8357\n",
            "     20        \u001b[36m0.4704\u001b[0m       \u001b[32m0.8509\u001b[0m        \u001b[35m0.4066\u001b[0m  0.8543\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=  17.5s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.0762\u001b[0m       \u001b[32m0.4963\u001b[0m        \u001b[35m1.4173\u001b[0m  0.8591\n",
            "      2        \u001b[36m1.2893\u001b[0m       \u001b[32m0.5927\u001b[0m        \u001b[35m0.9702\u001b[0m  0.8515\n",
            "      3        \u001b[36m1.0239\u001b[0m       \u001b[32m0.6723\u001b[0m        \u001b[35m0.8018\u001b[0m  0.8304\n",
            "      4        \u001b[36m0.8849\u001b[0m       \u001b[32m0.7192\u001b[0m        \u001b[35m0.7127\u001b[0m  0.8359\n",
            "      5        \u001b[36m0.8019\u001b[0m       \u001b[32m0.7585\u001b[0m        \u001b[35m0.6597\u001b[0m  0.8339\n",
            "      6        \u001b[36m0.7516\u001b[0m       \u001b[32m0.7709\u001b[0m        \u001b[35m0.6144\u001b[0m  0.8454\n",
            "      7        \u001b[36m0.7122\u001b[0m       \u001b[32m0.7798\u001b[0m        \u001b[35m0.5817\u001b[0m  0.8477\n",
            "      8        \u001b[36m0.6733\u001b[0m       \u001b[32m0.8036\u001b[0m        \u001b[35m0.5427\u001b[0m  0.8280\n",
            "      9        \u001b[36m0.6390\u001b[0m       \u001b[32m0.8125\u001b[0m        \u001b[35m0.5217\u001b[0m  0.8235\n",
            "     10        \u001b[36m0.6141\u001b[0m       \u001b[32m0.8267\u001b[0m        \u001b[35m0.4952\u001b[0m  0.8327\n",
            "     11        \u001b[36m0.5911\u001b[0m       \u001b[32m0.8301\u001b[0m        \u001b[35m0.4732\u001b[0m  0.8305\n",
            "     12        \u001b[36m0.5685\u001b[0m       \u001b[32m0.8304\u001b[0m        \u001b[35m0.4653\u001b[0m  0.8261\n",
            "     13        \u001b[36m0.5518\u001b[0m       \u001b[32m0.8373\u001b[0m        \u001b[35m0.4505\u001b[0m  0.8497\n",
            "     14        \u001b[36m0.5399\u001b[0m       \u001b[32m0.8449\u001b[0m        \u001b[35m0.4366\u001b[0m  0.8580\n",
            "     15        \u001b[36m0.5205\u001b[0m       \u001b[32m0.8502\u001b[0m        \u001b[35m0.4251\u001b[0m  0.8572\n",
            "     16        \u001b[36m0.5082\u001b[0m       \u001b[32m0.8514\u001b[0m        \u001b[35m0.4154\u001b[0m  0.8420\n",
            "     17        \u001b[36m0.4988\u001b[0m       \u001b[32m0.8525\u001b[0m        \u001b[35m0.4067\u001b[0m  0.8366\n",
            "     18        \u001b[36m0.4903\u001b[0m       \u001b[32m0.8556\u001b[0m        \u001b[35m0.4044\u001b[0m  0.8340\n",
            "     19        \u001b[36m0.4814\u001b[0m       \u001b[32m0.8580\u001b[0m        \u001b[35m0.3975\u001b[0m  0.8649\n",
            "     20        \u001b[36m0.4687\u001b[0m       \u001b[32m0.8635\u001b[0m        \u001b[35m0.3860\u001b[0m  0.8779\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=  17.5s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.1000\u001b[0m       \u001b[32m0.4529\u001b[0m        \u001b[35m1.4476\u001b[0m  0.8453\n",
            "      2        \u001b[36m1.2920\u001b[0m       \u001b[32m0.6029\u001b[0m        \u001b[35m0.9678\u001b[0m  0.8332\n",
            "      3        \u001b[36m1.0074\u001b[0m       \u001b[32m0.6815\u001b[0m        \u001b[35m0.7821\u001b[0m  0.8590\n",
            "      4        \u001b[36m0.8662\u001b[0m       \u001b[32m0.7174\u001b[0m        \u001b[35m0.7029\u001b[0m  0.8446\n",
            "      5        \u001b[36m0.7930\u001b[0m       \u001b[32m0.7714\u001b[0m        \u001b[35m0.6447\u001b[0m  0.8482\n",
            "      6        \u001b[36m0.7346\u001b[0m       \u001b[32m0.7781\u001b[0m        \u001b[35m0.5982\u001b[0m  0.8625\n",
            "      7        \u001b[36m0.6930\u001b[0m       \u001b[32m0.7847\u001b[0m        \u001b[35m0.5669\u001b[0m  0.8655\n",
            "      8        \u001b[36m0.6546\u001b[0m       \u001b[32m0.7994\u001b[0m        \u001b[35m0.5399\u001b[0m  0.8852\n",
            "      9        \u001b[36m0.6303\u001b[0m       \u001b[32m0.8111\u001b[0m        \u001b[35m0.5139\u001b[0m  0.8422\n",
            "     10        \u001b[36m0.6072\u001b[0m       \u001b[32m0.8260\u001b[0m        \u001b[35m0.4951\u001b[0m  0.8401\n",
            "     11        \u001b[36m0.5874\u001b[0m       \u001b[32m0.8341\u001b[0m        \u001b[35m0.4731\u001b[0m  0.8618\n",
            "     12        \u001b[36m0.5664\u001b[0m       \u001b[32m0.8365\u001b[0m        \u001b[35m0.4694\u001b[0m  0.8642\n",
            "     13        \u001b[36m0.5477\u001b[0m       \u001b[32m0.8386\u001b[0m        \u001b[35m0.4569\u001b[0m  0.8458\n",
            "     14        \u001b[36m0.5338\u001b[0m       \u001b[32m0.8430\u001b[0m        \u001b[35m0.4368\u001b[0m  0.8415\n",
            "     15        \u001b[36m0.5226\u001b[0m       \u001b[32m0.8450\u001b[0m        \u001b[35m0.4282\u001b[0m  0.8391\n",
            "     16        \u001b[36m0.5073\u001b[0m       \u001b[32m0.8516\u001b[0m        \u001b[35m0.4189\u001b[0m  0.8435\n",
            "     17        \u001b[36m0.4993\u001b[0m       \u001b[32m0.8530\u001b[0m        \u001b[35m0.4109\u001b[0m  0.8399\n",
            "     18        \u001b[36m0.4946\u001b[0m       \u001b[32m0.8550\u001b[0m        \u001b[35m0.4081\u001b[0m  0.8370\n",
            "     19        \u001b[36m0.4806\u001b[0m       0.8535        \u001b[35m0.4071\u001b[0m  0.8662\n",
            "     20        \u001b[36m0.4688\u001b[0m       \u001b[32m0.8595\u001b[0m        \u001b[35m0.3933\u001b[0m  0.8518\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=  17.6s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.5685\u001b[0m       \u001b[32m0.6325\u001b[0m        \u001b[35m0.8312\u001b[0m  0.8650\n",
            "      2        \u001b[36m0.8428\u001b[0m       \u001b[32m0.7492\u001b[0m        \u001b[35m0.6590\u001b[0m  0.8571\n",
            "      3        \u001b[36m0.7036\u001b[0m       \u001b[32m0.7924\u001b[0m        \u001b[35m0.5539\u001b[0m  0.8383\n",
            "      4        \u001b[36m0.6145\u001b[0m       \u001b[32m0.8193\u001b[0m        \u001b[35m0.4961\u001b[0m  0.8469\n",
            "      5        \u001b[36m0.5680\u001b[0m       \u001b[32m0.8230\u001b[0m        \u001b[35m0.4715\u001b[0m  0.8534\n",
            "      6        \u001b[36m0.5314\u001b[0m       \u001b[32m0.8334\u001b[0m        \u001b[35m0.4485\u001b[0m  0.8410\n",
            "      7        \u001b[36m0.5076\u001b[0m       \u001b[32m0.8417\u001b[0m        \u001b[35m0.4231\u001b[0m  0.8321\n",
            "      8        \u001b[36m0.4869\u001b[0m       \u001b[32m0.8434\u001b[0m        \u001b[35m0.4192\u001b[0m  0.8289\n",
            "      9        \u001b[36m0.4701\u001b[0m       0.8407        0.4251  0.8315\n",
            "     10        \u001b[36m0.4569\u001b[0m       \u001b[32m0.8575\u001b[0m        \u001b[35m0.3889\u001b[0m  0.8435\n",
            "     11        \u001b[36m0.4460\u001b[0m       \u001b[32m0.8620\u001b[0m        \u001b[35m0.3791\u001b[0m  0.8280\n",
            "     12        \u001b[36m0.4381\u001b[0m       0.8571        0.3866  0.8371\n",
            "     13        \u001b[36m0.4262\u001b[0m       0.8579        0.3792  0.8352\n",
            "     14        \u001b[36m0.4204\u001b[0m       \u001b[32m0.8622\u001b[0m        \u001b[35m0.3694\u001b[0m  0.8548\n",
            "     15        \u001b[36m0.4085\u001b[0m       \u001b[32m0.8705\u001b[0m        \u001b[35m0.3651\u001b[0m  0.8840\n",
            "     16        \u001b[36m0.4035\u001b[0m       0.8691        \u001b[35m0.3543\u001b[0m  0.8452\n",
            "     17        \u001b[36m0.3930\u001b[0m       0.8680        0.3575  0.8350\n",
            "     18        \u001b[36m0.3883\u001b[0m       \u001b[32m0.8718\u001b[0m        0.3574  0.8519\n",
            "     19        \u001b[36m0.3809\u001b[0m       \u001b[32m0.8781\u001b[0m        \u001b[35m0.3511\u001b[0m  0.8315\n",
            "     20        \u001b[36m0.3795\u001b[0m       0.8770        0.3570  0.8452\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=  17.5s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.6057\u001b[0m       \u001b[32m0.6464\u001b[0m        \u001b[35m0.8748\u001b[0m  0.8481\n",
            "      2        \u001b[36m0.8582\u001b[0m       \u001b[32m0.7716\u001b[0m        \u001b[35m0.6389\u001b[0m  0.8422\n",
            "      3        \u001b[36m0.7098\u001b[0m       \u001b[32m0.8050\u001b[0m        \u001b[35m0.5626\u001b[0m  0.8566\n",
            "      4        \u001b[36m0.6250\u001b[0m       \u001b[32m0.8307\u001b[0m        \u001b[35m0.4781\u001b[0m  0.8665\n",
            "      5        \u001b[36m0.5730\u001b[0m       \u001b[32m0.8400\u001b[0m        \u001b[35m0.4522\u001b[0m  0.8741\n",
            "      6        \u001b[36m0.5422\u001b[0m       \u001b[32m0.8484\u001b[0m        \u001b[35m0.4276\u001b[0m  0.8558\n",
            "      7        \u001b[36m0.5164\u001b[0m       \u001b[32m0.8564\u001b[0m        \u001b[35m0.4063\u001b[0m  0.8606\n",
            "      8        \u001b[36m0.4938\u001b[0m       0.8541        \u001b[35m0.4034\u001b[0m  0.8619\n",
            "      9        \u001b[36m0.4728\u001b[0m       \u001b[32m0.8586\u001b[0m        \u001b[35m0.3931\u001b[0m  0.8671\n",
            "     10        \u001b[36m0.4579\u001b[0m       \u001b[32m0.8650\u001b[0m        \u001b[35m0.3792\u001b[0m  0.8666\n",
            "     11        \u001b[36m0.4508\u001b[0m       0.8624        \u001b[35m0.3756\u001b[0m  0.8358\n",
            "     12        \u001b[36m0.4380\u001b[0m       \u001b[32m0.8715\u001b[0m        \u001b[35m0.3602\u001b[0m  0.8295\n",
            "     13        \u001b[36m0.4349\u001b[0m       0.8686        0.3631  0.8414\n",
            "     14        \u001b[36m0.4190\u001b[0m       \u001b[32m0.8736\u001b[0m        \u001b[35m0.3536\u001b[0m  0.8426\n",
            "     15        \u001b[36m0.4140\u001b[0m       0.8710        0.3586  0.8481\n",
            "     16        \u001b[36m0.4046\u001b[0m       0.8722        \u001b[35m0.3535\u001b[0m  0.8430\n",
            "     17        \u001b[36m0.3998\u001b[0m       0.8721        0.3567  0.8383\n",
            "     18        \u001b[36m0.3926\u001b[0m       0.8719        0.3544  0.8426\n",
            "     19        \u001b[36m0.3889\u001b[0m       \u001b[32m0.8771\u001b[0m        \u001b[35m0.3369\u001b[0m  0.8365\n",
            "     20        \u001b[36m0.3824\u001b[0m       \u001b[32m0.8779\u001b[0m        0.3385  0.8471\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=  17.6s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.5680\u001b[0m       \u001b[32m0.6729\u001b[0m        \u001b[35m0.8284\u001b[0m  0.8610\n",
            "      2        \u001b[36m0.8449\u001b[0m       \u001b[32m0.7518\u001b[0m        \u001b[35m0.6468\u001b[0m  0.8972\n",
            "      3        \u001b[36m0.7017\u001b[0m       \u001b[32m0.8104\u001b[0m        \u001b[35m0.5288\u001b[0m  0.8649\n",
            "      4        \u001b[36m0.6169\u001b[0m       \u001b[32m0.8237\u001b[0m        \u001b[35m0.4906\u001b[0m  0.8368\n",
            "      5        \u001b[36m0.5706\u001b[0m       \u001b[32m0.8397\u001b[0m        \u001b[35m0.4494\u001b[0m  0.8334\n",
            "      6        \u001b[36m0.5315\u001b[0m       \u001b[32m0.8460\u001b[0m        \u001b[35m0.4272\u001b[0m  0.8321\n",
            "      7        \u001b[36m0.5076\u001b[0m       0.8454        \u001b[35m0.4234\u001b[0m  0.8279\n",
            "      8        \u001b[36m0.4885\u001b[0m       \u001b[32m0.8598\u001b[0m        \u001b[35m0.3930\u001b[0m  0.8206\n",
            "      9        \u001b[36m0.4729\u001b[0m       0.8525        0.4015  0.8447\n",
            "     10        \u001b[36m0.4556\u001b[0m       \u001b[32m0.8599\u001b[0m        \u001b[35m0.3836\u001b[0m  0.8349\n",
            "     11        \u001b[36m0.4468\u001b[0m       \u001b[32m0.8615\u001b[0m        \u001b[35m0.3759\u001b[0m  0.8270\n",
            "     12        \u001b[36m0.4355\u001b[0m       \u001b[32m0.8659\u001b[0m        \u001b[35m0.3716\u001b[0m  0.8239\n",
            "     13        \u001b[36m0.4284\u001b[0m       \u001b[32m0.8700\u001b[0m        \u001b[35m0.3547\u001b[0m  0.8191\n",
            "     14        \u001b[36m0.4138\u001b[0m       \u001b[32m0.8719\u001b[0m        0.3597  0.8323\n",
            "     15        \u001b[36m0.4086\u001b[0m       \u001b[32m0.8746\u001b[0m        \u001b[35m0.3480\u001b[0m  0.8612\n",
            "     16        \u001b[36m0.4011\u001b[0m       0.8695        0.3562  0.8949\n",
            "     17        \u001b[36m0.3955\u001b[0m       \u001b[32m0.8752\u001b[0m        \u001b[35m0.3457\u001b[0m  0.8521\n",
            "     18        \u001b[36m0.3880\u001b[0m       \u001b[32m0.8780\u001b[0m        \u001b[35m0.3422\u001b[0m  0.8380\n",
            "     19        \u001b[36m0.3871\u001b[0m       \u001b[32m0.8788\u001b[0m        \u001b[35m0.3416\u001b[0m  0.8411\n",
            "     20        \u001b[36m0.3808\u001b[0m       \u001b[32m0.8789\u001b[0m        0.3418  0.8317\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=  17.4s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.6085\u001b[0m       \u001b[32m0.6381\u001b[0m        \u001b[35m0.8825\u001b[0m  0.8352\n",
            "      2        \u001b[36m0.8655\u001b[0m       \u001b[32m0.7381\u001b[0m        \u001b[35m0.6611\u001b[0m  0.8321\n",
            "      3        \u001b[36m0.7095\u001b[0m       \u001b[32m0.7833\u001b[0m        \u001b[35m0.5780\u001b[0m  0.8351\n",
            "      4        \u001b[36m0.6181\u001b[0m       \u001b[32m0.8194\u001b[0m        \u001b[35m0.4983\u001b[0m  0.8309\n",
            "      5        \u001b[36m0.5703\u001b[0m       \u001b[32m0.8271\u001b[0m        \u001b[35m0.4739\u001b[0m  0.8429\n",
            "      6        \u001b[36m0.5363\u001b[0m       \u001b[32m0.8349\u001b[0m        \u001b[35m0.4568\u001b[0m  0.8525\n",
            "      7        \u001b[36m0.5144\u001b[0m       \u001b[32m0.8383\u001b[0m        \u001b[35m0.4355\u001b[0m  0.8543\n",
            "      8        \u001b[36m0.4889\u001b[0m       \u001b[32m0.8495\u001b[0m        \u001b[35m0.4196\u001b[0m  0.8895\n",
            "      9        \u001b[36m0.4787\u001b[0m       \u001b[32m0.8510\u001b[0m        \u001b[35m0.4098\u001b[0m  0.8806\n",
            "     10        \u001b[36m0.4579\u001b[0m       0.8502        \u001b[35m0.4000\u001b[0m  0.8712\n",
            "     11        \u001b[36m0.4545\u001b[0m       \u001b[32m0.8528\u001b[0m        0.4028  0.8367\n",
            "     12        \u001b[36m0.4425\u001b[0m       \u001b[32m0.8600\u001b[0m        \u001b[35m0.3842\u001b[0m  0.8211\n",
            "     13        \u001b[36m0.4330\u001b[0m       \u001b[32m0.8638\u001b[0m        \u001b[35m0.3822\u001b[0m  0.8313\n",
            "     14        0.4330       0.8619        0.3875  0.8401\n",
            "     15        \u001b[36m0.4213\u001b[0m       \u001b[32m0.8662\u001b[0m        \u001b[35m0.3707\u001b[0m  0.8340\n",
            "     16        \u001b[36m0.4105\u001b[0m       \u001b[32m0.8712\u001b[0m        \u001b[35m0.3610\u001b[0m  0.8358\n",
            "     17        \u001b[36m0.4084\u001b[0m       0.8649        0.3653  0.8331\n",
            "     18        \u001b[36m0.3994\u001b[0m       \u001b[32m0.8734\u001b[0m        \u001b[35m0.3566\u001b[0m  0.8303\n",
            "     19        \u001b[36m0.3951\u001b[0m       0.8721        0.3587  0.8245\n",
            "     20        \u001b[36m0.3933\u001b[0m       \u001b[32m0.8755\u001b[0m        \u001b[35m0.3523\u001b[0m  0.8267\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=  17.4s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.6097\u001b[0m       \u001b[32m0.6475\u001b[0m        \u001b[35m0.8738\u001b[0m  0.8466\n",
            "      2        \u001b[36m0.8710\u001b[0m       \u001b[32m0.7556\u001b[0m        \u001b[35m0.6502\u001b[0m  0.8619\n",
            "      3        \u001b[36m0.7251\u001b[0m       \u001b[32m0.8025\u001b[0m        \u001b[35m0.5554\u001b[0m  0.8488\n",
            "      4        \u001b[36m0.6387\u001b[0m       \u001b[32m0.8276\u001b[0m        \u001b[35m0.4946\u001b[0m  0.8567\n",
            "      5        \u001b[36m0.5796\u001b[0m       \u001b[32m0.8311\u001b[0m        \u001b[35m0.4652\u001b[0m  0.8290\n",
            "      6        \u001b[36m0.5477\u001b[0m       \u001b[32m0.8394\u001b[0m        \u001b[35m0.4512\u001b[0m  0.8310\n",
            "      7        \u001b[36m0.5153\u001b[0m       \u001b[32m0.8495\u001b[0m        \u001b[35m0.4139\u001b[0m  0.8391\n",
            "      8        \u001b[36m0.4996\u001b[0m       \u001b[32m0.8541\u001b[0m        \u001b[35m0.4050\u001b[0m  0.8327\n",
            "      9        \u001b[36m0.4818\u001b[0m       \u001b[32m0.8568\u001b[0m        \u001b[35m0.3963\u001b[0m  0.8362\n",
            "     10        \u001b[36m0.4743\u001b[0m       \u001b[32m0.8609\u001b[0m        \u001b[35m0.3808\u001b[0m  0.8359\n",
            "     11        \u001b[36m0.4545\u001b[0m       \u001b[32m0.8628\u001b[0m        0.3809  0.8384\n",
            "     12        \u001b[36m0.4506\u001b[0m       \u001b[32m0.8648\u001b[0m        \u001b[35m0.3751\u001b[0m  0.8332\n",
            "     13        \u001b[36m0.4381\u001b[0m       \u001b[32m0.8710\u001b[0m        \u001b[35m0.3672\u001b[0m  0.8494\n",
            "     14        \u001b[36m0.4274\u001b[0m       \u001b[32m0.8731\u001b[0m        \u001b[35m0.3601\u001b[0m  0.8474\n",
            "     15        \u001b[36m0.4228\u001b[0m       \u001b[32m0.8758\u001b[0m        \u001b[35m0.3535\u001b[0m  0.8450\n",
            "     16        \u001b[36m0.4166\u001b[0m       0.8684        0.3591  0.8596\n",
            "     17        \u001b[36m0.4099\u001b[0m       \u001b[32m0.8762\u001b[0m        \u001b[35m0.3435\u001b[0m  0.8492\n",
            "     18        \u001b[36m0.4060\u001b[0m       0.8746        0.3469  0.8517\n",
            "     19        \u001b[36m0.3965\u001b[0m       0.8750        0.3463  0.8356\n",
            "     20        \u001b[36m0.3934\u001b[0m       0.8731        0.3482  0.8415\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=  17.4s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.5855\u001b[0m       \u001b[32m0.6697\u001b[0m        \u001b[35m0.8368\u001b[0m  0.8297\n",
            "      2        \u001b[36m0.8515\u001b[0m       \u001b[32m0.7440\u001b[0m        \u001b[35m0.6458\u001b[0m  0.8278\n",
            "      3        \u001b[36m0.7051\u001b[0m       \u001b[32m0.8117\u001b[0m        \u001b[35m0.5396\u001b[0m  0.8374\n",
            "      4        \u001b[36m0.6272\u001b[0m       \u001b[32m0.8317\u001b[0m        \u001b[35m0.4821\u001b[0m  0.8562\n",
            "      5        \u001b[36m0.5773\u001b[0m       \u001b[32m0.8325\u001b[0m        \u001b[35m0.4643\u001b[0m  0.8484\n",
            "      6        \u001b[36m0.5409\u001b[0m       \u001b[32m0.8430\u001b[0m        \u001b[35m0.4300\u001b[0m  0.8465\n",
            "      7        \u001b[36m0.5075\u001b[0m       \u001b[32m0.8542\u001b[0m        \u001b[35m0.4172\u001b[0m  0.8495\n",
            "      8        \u001b[36m0.4899\u001b[0m       0.8506        \u001b[35m0.4109\u001b[0m  0.8341\n",
            "      9        \u001b[36m0.4752\u001b[0m       0.8481        0.4121  0.8515\n",
            "     10        \u001b[36m0.4722\u001b[0m       \u001b[32m0.8572\u001b[0m        \u001b[35m0.3891\u001b[0m  0.8622\n",
            "     11        \u001b[36m0.4544\u001b[0m       \u001b[32m0.8639\u001b[0m        \u001b[35m0.3763\u001b[0m  0.8604\n",
            "     12        \u001b[36m0.4406\u001b[0m       \u001b[32m0.8645\u001b[0m        \u001b[35m0.3741\u001b[0m  0.8297\n",
            "     13        \u001b[36m0.4283\u001b[0m       0.8644        \u001b[35m0.3704\u001b[0m  0.8478\n",
            "     14        0.4320       0.8630        0.3710  0.8414\n",
            "     15        \u001b[36m0.4215\u001b[0m       \u001b[32m0.8698\u001b[0m        \u001b[35m0.3571\u001b[0m  0.8413\n",
            "     16        \u001b[36m0.4156\u001b[0m       \u001b[32m0.8714\u001b[0m        0.3605  0.8443\n",
            "     17        \u001b[36m0.4078\u001b[0m       \u001b[32m0.8725\u001b[0m        \u001b[35m0.3550\u001b[0m  0.8391\n",
            "     18        \u001b[36m0.3990\u001b[0m       0.8720        \u001b[35m0.3528\u001b[0m  0.8249\n",
            "     19        \u001b[36m0.3972\u001b[0m       \u001b[32m0.8780\u001b[0m        \u001b[35m0.3427\u001b[0m  0.8731\n",
            "     20        \u001b[36m0.3965\u001b[0m       \u001b[32m0.8829\u001b[0m        \u001b[35m0.3374\u001b[0m  0.8544\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=  17.5s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.2019\u001b[0m       \u001b[32m0.4461\u001b[0m        \u001b[35m1.7513\u001b[0m  0.8381\n",
            "      2        \u001b[36m1.4770\u001b[0m       \u001b[32m0.5717\u001b[0m        \u001b[35m1.0638\u001b[0m  0.8588\n",
            "      3        \u001b[36m1.1362\u001b[0m       \u001b[32m0.6499\u001b[0m        \u001b[35m0.8927\u001b[0m  0.8753\n",
            "      4        \u001b[36m0.9944\u001b[0m       \u001b[32m0.6755\u001b[0m        \u001b[35m0.8039\u001b[0m  0.8876\n",
            "      5        \u001b[36m0.9014\u001b[0m       \u001b[32m0.7134\u001b[0m        \u001b[35m0.7372\u001b[0m  0.8413\n",
            "      6        \u001b[36m0.8391\u001b[0m       \u001b[32m0.7406\u001b[0m        \u001b[35m0.6852\u001b[0m  0.8383\n",
            "      7        \u001b[36m0.7881\u001b[0m       \u001b[32m0.7590\u001b[0m        \u001b[35m0.6426\u001b[0m  0.8391\n",
            "      8        \u001b[36m0.7436\u001b[0m       \u001b[32m0.7679\u001b[0m        \u001b[35m0.6176\u001b[0m  0.8383\n",
            "      9        \u001b[36m0.7138\u001b[0m       \u001b[32m0.7750\u001b[0m        \u001b[35m0.5882\u001b[0m  0.8361\n",
            "     10        \u001b[36m0.6821\u001b[0m       \u001b[32m0.7762\u001b[0m        \u001b[35m0.5639\u001b[0m  0.8375\n",
            "     11        \u001b[36m0.6622\u001b[0m       \u001b[32m0.7950\u001b[0m        \u001b[35m0.5432\u001b[0m  0.8527\n",
            "     12        \u001b[36m0.6345\u001b[0m       0.7943        \u001b[35m0.5221\u001b[0m  0.8597\n",
            "     13        \u001b[36m0.6183\u001b[0m       \u001b[32m0.8135\u001b[0m        \u001b[35m0.5046\u001b[0m  0.8501\n",
            "     14        \u001b[36m0.5977\u001b[0m       \u001b[32m0.8204\u001b[0m        \u001b[35m0.4915\u001b[0m  0.8511\n",
            "     15        \u001b[36m0.5801\u001b[0m       \u001b[32m0.8219\u001b[0m        \u001b[35m0.4803\u001b[0m  0.8512\n",
            "     16        \u001b[36m0.5675\u001b[0m       \u001b[32m0.8315\u001b[0m        \u001b[35m0.4656\u001b[0m  0.8564\n",
            "     17        \u001b[36m0.5540\u001b[0m       \u001b[32m0.8326\u001b[0m        \u001b[35m0.4509\u001b[0m  0.8819\n",
            "     18        \u001b[36m0.5431\u001b[0m       \u001b[32m0.8364\u001b[0m        \u001b[35m0.4434\u001b[0m  0.9163\n",
            "     19        \u001b[36m0.5333\u001b[0m       \u001b[32m0.8415\u001b[0m        \u001b[35m0.4332\u001b[0m  0.8946\n",
            "     20        \u001b[36m0.5247\u001b[0m       \u001b[32m0.8440\u001b[0m        \u001b[35m0.4256\u001b[0m  0.8559\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=  17.7s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.1827\u001b[0m       \u001b[32m0.4285\u001b[0m        \u001b[35m1.7329\u001b[0m  0.8481\n",
            "      2        \u001b[36m1.4579\u001b[0m       \u001b[32m0.5671\u001b[0m        \u001b[35m1.0808\u001b[0m  0.8439\n",
            "      3        \u001b[36m1.1276\u001b[0m       \u001b[32m0.6341\u001b[0m        \u001b[35m0.8671\u001b[0m  0.8461\n",
            "      4        \u001b[36m0.9687\u001b[0m       \u001b[32m0.6900\u001b[0m        \u001b[35m0.7614\u001b[0m  0.8646\n",
            "      5        \u001b[36m0.8818\u001b[0m       \u001b[32m0.7069\u001b[0m        \u001b[35m0.7106\u001b[0m  0.8506\n",
            "      6        \u001b[36m0.8211\u001b[0m       \u001b[32m0.7511\u001b[0m        \u001b[35m0.6605\u001b[0m  0.8532\n",
            "      7        \u001b[36m0.7778\u001b[0m       \u001b[32m0.7649\u001b[0m        \u001b[35m0.6254\u001b[0m  0.8558\n",
            "      8        \u001b[36m0.7372\u001b[0m       \u001b[32m0.7809\u001b[0m        \u001b[35m0.5857\u001b[0m  0.8498\n",
            "      9        \u001b[36m0.7027\u001b[0m       \u001b[32m0.7821\u001b[0m        \u001b[35m0.5609\u001b[0m  0.8627\n",
            "     10        \u001b[36m0.6746\u001b[0m       \u001b[32m0.8019\u001b[0m        \u001b[35m0.5307\u001b[0m  0.8710\n",
            "     11        \u001b[36m0.6479\u001b[0m       \u001b[32m0.8239\u001b[0m        \u001b[35m0.5096\u001b[0m  0.8553\n",
            "     12        \u001b[36m0.6297\u001b[0m       \u001b[32m0.8291\u001b[0m        \u001b[35m0.4948\u001b[0m  0.8606\n",
            "     13        \u001b[36m0.6075\u001b[0m       \u001b[32m0.8323\u001b[0m        \u001b[35m0.4776\u001b[0m  0.8691\n",
            "     14        \u001b[36m0.5875\u001b[0m       \u001b[32m0.8345\u001b[0m        \u001b[35m0.4640\u001b[0m  0.8708\n",
            "     15        \u001b[36m0.5793\u001b[0m       \u001b[32m0.8374\u001b[0m        \u001b[35m0.4594\u001b[0m  0.8662\n",
            "     16        \u001b[36m0.5638\u001b[0m       \u001b[32m0.8396\u001b[0m        \u001b[35m0.4411\u001b[0m  0.8676\n",
            "     17        \u001b[36m0.5475\u001b[0m       \u001b[32m0.8458\u001b[0m        \u001b[35m0.4315\u001b[0m  0.8678\n",
            "     18        \u001b[36m0.5339\u001b[0m       \u001b[32m0.8510\u001b[0m        \u001b[35m0.4256\u001b[0m  0.8590\n",
            "     19        \u001b[36m0.5214\u001b[0m       0.8490        \u001b[35m0.4205\u001b[0m  0.8544\n",
            "     20        \u001b[36m0.5179\u001b[0m       0.8506        \u001b[35m0.4153\u001b[0m  0.8233\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=  17.7s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.1776\u001b[0m       \u001b[32m0.5374\u001b[0m        \u001b[35m1.6470\u001b[0m  0.8489\n",
            "      2        \u001b[36m1.4185\u001b[0m       \u001b[32m0.5916\u001b[0m        \u001b[35m1.0119\u001b[0m  0.8502\n",
            "      3        \u001b[36m1.1016\u001b[0m       \u001b[32m0.6577\u001b[0m        \u001b[35m0.8657\u001b[0m  0.8596\n",
            "      4        \u001b[36m0.9664\u001b[0m       \u001b[32m0.7119\u001b[0m        \u001b[35m0.7733\u001b[0m  0.8573\n",
            "      5        \u001b[36m0.8815\u001b[0m       \u001b[32m0.7391\u001b[0m        \u001b[35m0.7074\u001b[0m  0.8896\n",
            "      6        \u001b[36m0.8162\u001b[0m       \u001b[32m0.7645\u001b[0m        \u001b[35m0.6583\u001b[0m  0.8517\n",
            "      7        \u001b[36m0.7658\u001b[0m       \u001b[32m0.7742\u001b[0m        \u001b[35m0.6161\u001b[0m  0.8460\n",
            "      8        \u001b[36m0.7291\u001b[0m       \u001b[32m0.7867\u001b[0m        \u001b[35m0.5875\u001b[0m  0.8434\n",
            "      9        \u001b[36m0.6962\u001b[0m       \u001b[32m0.7900\u001b[0m        \u001b[35m0.5539\u001b[0m  0.8377\n",
            "     10        \u001b[36m0.6675\u001b[0m       \u001b[32m0.8149\u001b[0m        \u001b[35m0.5348\u001b[0m  0.8638\n",
            "     11        \u001b[36m0.6430\u001b[0m       \u001b[32m0.8157\u001b[0m        \u001b[35m0.5086\u001b[0m  0.8368\n",
            "     12        \u001b[36m0.6211\u001b[0m       \u001b[32m0.8207\u001b[0m        \u001b[35m0.4916\u001b[0m  0.8416\n",
            "     13        \u001b[36m0.6040\u001b[0m       \u001b[32m0.8304\u001b[0m        \u001b[35m0.4768\u001b[0m  0.8421\n",
            "     14        \u001b[36m0.5872\u001b[0m       \u001b[32m0.8385\u001b[0m        \u001b[35m0.4648\u001b[0m  0.8359\n",
            "     15        \u001b[36m0.5740\u001b[0m       \u001b[32m0.8405\u001b[0m        \u001b[35m0.4536\u001b[0m  0.8506\n",
            "     16        \u001b[36m0.5548\u001b[0m       \u001b[32m0.8456\u001b[0m        \u001b[35m0.4399\u001b[0m  0.8492\n",
            "     17        \u001b[36m0.5456\u001b[0m       \u001b[32m0.8466\u001b[0m        \u001b[35m0.4368\u001b[0m  0.8632\n",
            "     18        \u001b[36m0.5366\u001b[0m       \u001b[32m0.8479\u001b[0m        \u001b[35m0.4257\u001b[0m  0.8722\n",
            "     19        \u001b[36m0.5226\u001b[0m       \u001b[32m0.8522\u001b[0m        \u001b[35m0.4196\u001b[0m  0.8620\n",
            "     20        \u001b[36m0.5156\u001b[0m       \u001b[32m0.8540\u001b[0m        \u001b[35m0.4139\u001b[0m  0.8492\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=  17.6s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.1501\u001b[0m       \u001b[32m0.4644\u001b[0m        \u001b[35m1.6005\u001b[0m  0.8461\n",
            "      2        \u001b[36m1.4055\u001b[0m       \u001b[32m0.5675\u001b[0m        \u001b[35m1.0248\u001b[0m  0.8590\n",
            "      3        \u001b[36m1.1112\u001b[0m       \u001b[32m0.6258\u001b[0m        \u001b[35m0.8687\u001b[0m  0.8420\n",
            "      4        \u001b[36m0.9674\u001b[0m       \u001b[32m0.6934\u001b[0m        \u001b[35m0.7631\u001b[0m  0.8326\n",
            "      5        \u001b[36m0.8637\u001b[0m       \u001b[32m0.7281\u001b[0m        \u001b[35m0.6998\u001b[0m  0.8372\n",
            "      6        \u001b[36m0.7992\u001b[0m       \u001b[32m0.7526\u001b[0m        \u001b[35m0.6625\u001b[0m  0.8445\n",
            "      7        \u001b[36m0.7557\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.6178\u001b[0m  0.8580\n",
            "      8        \u001b[36m0.7161\u001b[0m       \u001b[32m0.7768\u001b[0m        \u001b[35m0.5866\u001b[0m  0.8488\n",
            "      9        \u001b[36m0.6831\u001b[0m       \u001b[32m0.7856\u001b[0m        \u001b[35m0.5598\u001b[0m  0.8413\n",
            "     10        \u001b[36m0.6574\u001b[0m       \u001b[32m0.7987\u001b[0m        \u001b[35m0.5339\u001b[0m  0.8365\n",
            "     11        \u001b[36m0.6320\u001b[0m       \u001b[32m0.8107\u001b[0m        \u001b[35m0.5168\u001b[0m  0.8699\n",
            "     12        \u001b[36m0.6069\u001b[0m       \u001b[32m0.8135\u001b[0m        \u001b[35m0.5006\u001b[0m  0.8782\n",
            "     13        \u001b[36m0.5934\u001b[0m       \u001b[32m0.8206\u001b[0m        \u001b[35m0.4881\u001b[0m  0.8442\n",
            "     14        \u001b[36m0.5809\u001b[0m       \u001b[32m0.8217\u001b[0m        \u001b[35m0.4794\u001b[0m  0.8265\n",
            "     15        \u001b[36m0.5639\u001b[0m       \u001b[32m0.8280\u001b[0m        \u001b[35m0.4651\u001b[0m  0.8492\n",
            "     16        \u001b[36m0.5482\u001b[0m       \u001b[32m0.8287\u001b[0m        \u001b[35m0.4646\u001b[0m  0.8416\n",
            "     17        \u001b[36m0.5452\u001b[0m       \u001b[32m0.8324\u001b[0m        \u001b[35m0.4573\u001b[0m  0.8243\n",
            "     18        \u001b[36m0.5333\u001b[0m       \u001b[32m0.8403\u001b[0m        \u001b[35m0.4375\u001b[0m  0.8303\n",
            "     19        \u001b[36m0.5192\u001b[0m       \u001b[32m0.8436\u001b[0m        \u001b[35m0.4310\u001b[0m  0.8250\n",
            "     20        \u001b[36m0.5114\u001b[0m       0.8415        \u001b[35m0.4292\u001b[0m  0.8459\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=  17.4s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.1401\u001b[0m       \u001b[32m0.4450\u001b[0m        \u001b[35m1.5490\u001b[0m  0.8415\n",
            "      2        \u001b[36m1.3926\u001b[0m       \u001b[32m0.5681\u001b[0m        \u001b[35m1.0672\u001b[0m  0.8405\n",
            "      3        \u001b[36m1.1360\u001b[0m       \u001b[32m0.6450\u001b[0m        \u001b[35m0.9020\u001b[0m  0.8439\n",
            "      4        \u001b[36m0.9995\u001b[0m       \u001b[32m0.6663\u001b[0m        \u001b[35m0.7856\u001b[0m  0.8702\n",
            "      5        \u001b[36m0.9070\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.7173\u001b[0m  0.8684\n",
            "      6        \u001b[36m0.8354\u001b[0m       \u001b[32m0.7560\u001b[0m        \u001b[35m0.6687\u001b[0m  0.8374\n",
            "      7        \u001b[36m0.7910\u001b[0m       \u001b[32m0.7730\u001b[0m        \u001b[35m0.6341\u001b[0m  0.8473\n",
            "      8        \u001b[36m0.7496\u001b[0m       \u001b[32m0.7964\u001b[0m        \u001b[35m0.5998\u001b[0m  0.8508\n",
            "      9        \u001b[36m0.7166\u001b[0m       0.7859        \u001b[35m0.5668\u001b[0m  0.8365\n",
            "     10        \u001b[36m0.6898\u001b[0m       \u001b[32m0.8044\u001b[0m        \u001b[35m0.5389\u001b[0m  0.8359\n",
            "     11        \u001b[36m0.6603\u001b[0m       \u001b[32m0.8177\u001b[0m        \u001b[35m0.5206\u001b[0m  0.8624\n",
            "     12        \u001b[36m0.6319\u001b[0m       \u001b[32m0.8223\u001b[0m        \u001b[35m0.4972\u001b[0m  0.8568\n",
            "     13        \u001b[36m0.6169\u001b[0m       \u001b[32m0.8234\u001b[0m        \u001b[35m0.4896\u001b[0m  0.8431\n",
            "     14        \u001b[36m0.5977\u001b[0m       \u001b[32m0.8385\u001b[0m        \u001b[35m0.4679\u001b[0m  0.8609\n",
            "     15        \u001b[36m0.5787\u001b[0m       0.8374        \u001b[35m0.4529\u001b[0m  0.8450\n",
            "     16        \u001b[36m0.5673\u001b[0m       \u001b[32m0.8446\u001b[0m        \u001b[35m0.4427\u001b[0m  0.8536\n",
            "     17        \u001b[36m0.5517\u001b[0m       0.8440        \u001b[35m0.4361\u001b[0m  0.8558\n",
            "     18        \u001b[36m0.5420\u001b[0m       \u001b[32m0.8504\u001b[0m        \u001b[35m0.4271\u001b[0m  0.8770\n",
            "     19        \u001b[36m0.5292\u001b[0m       0.8504        \u001b[35m0.4205\u001b[0m  0.8531\n",
            "     20        \u001b[36m0.5253\u001b[0m       \u001b[32m0.8526\u001b[0m        \u001b[35m0.4136\u001b[0m  0.8652\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=  17.6s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.1500\u001b[0m       \u001b[32m0.4436\u001b[0m        \u001b[35m1.6048\u001b[0m  0.8455\n",
            "      2        \u001b[36m1.4158\u001b[0m       \u001b[32m0.5771\u001b[0m        \u001b[35m1.0587\u001b[0m  0.8526\n",
            "      3        \u001b[36m1.1178\u001b[0m       \u001b[32m0.6375\u001b[0m        \u001b[35m0.8787\u001b[0m  0.8430\n",
            "      4        \u001b[36m0.9780\u001b[0m       \u001b[32m0.6934\u001b[0m        \u001b[35m0.7747\u001b[0m  0.8409\n",
            "      5        \u001b[36m0.8826\u001b[0m       \u001b[32m0.7080\u001b[0m        \u001b[35m0.7150\u001b[0m  0.8365\n",
            "      6        \u001b[36m0.8302\u001b[0m       \u001b[32m0.7405\u001b[0m        \u001b[35m0.6793\u001b[0m  0.8395\n",
            "      7        \u001b[36m0.7840\u001b[0m       \u001b[32m0.7644\u001b[0m        \u001b[35m0.6334\u001b[0m  0.8464\n",
            "      8        \u001b[36m0.7451\u001b[0m       \u001b[32m0.7905\u001b[0m        \u001b[35m0.6045\u001b[0m  0.8392\n",
            "      9        \u001b[36m0.7170\u001b[0m       0.7890        \u001b[35m0.5725\u001b[0m  0.8382\n",
            "     10        \u001b[36m0.6858\u001b[0m       \u001b[32m0.7930\u001b[0m        \u001b[35m0.5508\u001b[0m  0.8382\n",
            "     11        \u001b[36m0.6604\u001b[0m       \u001b[32m0.7975\u001b[0m        \u001b[35m0.5306\u001b[0m  0.8653\n",
            "     12        \u001b[36m0.6427\u001b[0m       \u001b[32m0.8150\u001b[0m        \u001b[35m0.5137\u001b[0m  0.8817\n",
            "     13        \u001b[36m0.6244\u001b[0m       \u001b[32m0.8167\u001b[0m        \u001b[35m0.4989\u001b[0m  0.9196\n",
            "     14        \u001b[36m0.6076\u001b[0m       \u001b[32m0.8251\u001b[0m        \u001b[35m0.4848\u001b[0m  0.8504\n",
            "     15        \u001b[36m0.5921\u001b[0m       0.8234        \u001b[35m0.4729\u001b[0m  0.8412\n",
            "     16        \u001b[36m0.5755\u001b[0m       \u001b[32m0.8384\u001b[0m        \u001b[35m0.4578\u001b[0m  0.8381\n",
            "     17        \u001b[36m0.5629\u001b[0m       \u001b[32m0.8426\u001b[0m        \u001b[35m0.4523\u001b[0m  0.8392\n",
            "     18        \u001b[36m0.5479\u001b[0m       0.8396        0.4535  0.8428\n",
            "     19        \u001b[36m0.5399\u001b[0m       \u001b[32m0.8455\u001b[0m        \u001b[35m0.4336\u001b[0m  0.8607\n",
            "     20        \u001b[36m0.5335\u001b[0m       \u001b[32m0.8472\u001b[0m        0.4338  0.8484\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=  17.6s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.7029\u001b[0m       \u001b[32m0.6024\u001b[0m        \u001b[35m0.9667\u001b[0m  0.8254\n",
            "      2        \u001b[36m0.9586\u001b[0m       \u001b[32m0.7290\u001b[0m        \u001b[35m0.7057\u001b[0m  0.8668\n",
            "      3        \u001b[36m0.7808\u001b[0m       \u001b[32m0.7700\u001b[0m        \u001b[35m0.6071\u001b[0m  0.8361\n",
            "      4        \u001b[36m0.6951\u001b[0m       \u001b[32m0.7884\u001b[0m        \u001b[35m0.5517\u001b[0m  0.8373\n",
            "      5        \u001b[36m0.6371\u001b[0m       \u001b[32m0.8085\u001b[0m        \u001b[35m0.5133\u001b[0m  0.8689\n",
            "      6        \u001b[36m0.6046\u001b[0m       \u001b[32m0.8200\u001b[0m        \u001b[35m0.4880\u001b[0m  0.8833\n",
            "      7        \u001b[36m0.5732\u001b[0m       \u001b[32m0.8265\u001b[0m        \u001b[35m0.4608\u001b[0m  0.8532\n",
            "      8        \u001b[36m0.5465\u001b[0m       \u001b[32m0.8359\u001b[0m        \u001b[35m0.4484\u001b[0m  0.8272\n",
            "      9        \u001b[36m0.5298\u001b[0m       \u001b[32m0.8375\u001b[0m        \u001b[35m0.4398\u001b[0m  0.8301\n",
            "     10        \u001b[36m0.5187\u001b[0m       \u001b[32m0.8435\u001b[0m        \u001b[35m0.4186\u001b[0m  0.8486\n",
            "     11        \u001b[36m0.5060\u001b[0m       \u001b[32m0.8458\u001b[0m        \u001b[35m0.4098\u001b[0m  0.8444\n",
            "     12        \u001b[36m0.4927\u001b[0m       \u001b[32m0.8528\u001b[0m        \u001b[35m0.3994\u001b[0m  0.8421\n",
            "     13        \u001b[36m0.4796\u001b[0m       0.8498        \u001b[35m0.3974\u001b[0m  0.8509\n",
            "     14        0.4810       \u001b[32m0.8559\u001b[0m        \u001b[35m0.3881\u001b[0m  0.8480\n",
            "     15        \u001b[36m0.4680\u001b[0m       0.8559        0.3917  0.8302\n",
            "     16        \u001b[36m0.4597\u001b[0m       0.8531        0.3888  0.8453\n",
            "     17        \u001b[36m0.4518\u001b[0m       \u001b[32m0.8561\u001b[0m        \u001b[35m0.3880\u001b[0m  0.8742\n",
            "     18        \u001b[36m0.4442\u001b[0m       \u001b[32m0.8591\u001b[0m        \u001b[35m0.3744\u001b[0m  0.8601\n",
            "     19        \u001b[36m0.4403\u001b[0m       \u001b[32m0.8639\u001b[0m        \u001b[35m0.3680\u001b[0m  0.8725\n",
            "     20        \u001b[36m0.4330\u001b[0m       0.8625        0.3684  0.8599\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=  17.6s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.6795\u001b[0m       \u001b[32m0.6121\u001b[0m        \u001b[35m0.9033\u001b[0m  0.8549\n",
            "      2        \u001b[36m0.9228\u001b[0m       \u001b[32m0.7441\u001b[0m        \u001b[35m0.6841\u001b[0m  0.8325\n",
            "      3        \u001b[36m0.7817\u001b[0m       \u001b[32m0.7835\u001b[0m        \u001b[35m0.5956\u001b[0m  0.8228\n",
            "      4        \u001b[36m0.7010\u001b[0m       \u001b[32m0.7961\u001b[0m        \u001b[35m0.5431\u001b[0m  0.8219\n",
            "      5        \u001b[36m0.6465\u001b[0m       \u001b[32m0.8174\u001b[0m        \u001b[35m0.5014\u001b[0m  0.8331\n",
            "      6        \u001b[36m0.6052\u001b[0m       \u001b[32m0.8260\u001b[0m        \u001b[35m0.4661\u001b[0m  0.8240\n",
            "      7        \u001b[36m0.5771\u001b[0m       \u001b[32m0.8373\u001b[0m        \u001b[35m0.4475\u001b[0m  0.8214\n",
            "      8        \u001b[36m0.5594\u001b[0m       \u001b[32m0.8460\u001b[0m        \u001b[35m0.4337\u001b[0m  0.8431\n",
            "      9        \u001b[36m0.5413\u001b[0m       \u001b[32m0.8490\u001b[0m        \u001b[35m0.4212\u001b[0m  0.8370\n",
            "     10        \u001b[36m0.5255\u001b[0m       \u001b[32m0.8566\u001b[0m        \u001b[35m0.4067\u001b[0m  0.8414\n",
            "     11        \u001b[36m0.5064\u001b[0m       0.8552        \u001b[35m0.3988\u001b[0m  0.8558\n",
            "     12        \u001b[36m0.4951\u001b[0m       0.8552        \u001b[35m0.3930\u001b[0m  0.8629\n",
            "     13        \u001b[36m0.4830\u001b[0m       \u001b[32m0.8600\u001b[0m        \u001b[35m0.3801\u001b[0m  0.8754\n",
            "     14        \u001b[36m0.4709\u001b[0m       0.8559        0.3896  0.8832\n",
            "     15        \u001b[36m0.4671\u001b[0m       \u001b[32m0.8658\u001b[0m        \u001b[35m0.3749\u001b[0m  0.8468\n",
            "     16        \u001b[36m0.4606\u001b[0m       0.8655        \u001b[35m0.3703\u001b[0m  0.8340\n",
            "     17        \u001b[36m0.4482\u001b[0m       \u001b[32m0.8660\u001b[0m        0.3783  0.8343\n",
            "     18        \u001b[36m0.4444\u001b[0m       \u001b[32m0.8668\u001b[0m        \u001b[35m0.3679\u001b[0m  0.8414\n",
            "     19        \u001b[36m0.4389\u001b[0m       \u001b[32m0.8694\u001b[0m        \u001b[35m0.3626\u001b[0m  0.8352\n",
            "     20        \u001b[36m0.4316\u001b[0m       \u001b[32m0.8738\u001b[0m        \u001b[35m0.3555\u001b[0m  0.8412\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=  17.4s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.6978\u001b[0m       \u001b[32m0.6224\u001b[0m        \u001b[35m0.9237\u001b[0m  0.8435\n",
            "      2        \u001b[36m0.9371\u001b[0m       \u001b[32m0.7191\u001b[0m        \u001b[35m0.6877\u001b[0m  0.8413\n",
            "      3        \u001b[36m0.7814\u001b[0m       \u001b[32m0.7967\u001b[0m        \u001b[35m0.5989\u001b[0m  0.8682\n",
            "      4        \u001b[36m0.6926\u001b[0m       \u001b[32m0.8070\u001b[0m        \u001b[35m0.5315\u001b[0m  0.8808\n",
            "      5        \u001b[36m0.6375\u001b[0m       \u001b[32m0.8230\u001b[0m        \u001b[35m0.4920\u001b[0m  0.9191\n",
            "      6        \u001b[36m0.5978\u001b[0m       \u001b[32m0.8337\u001b[0m        \u001b[35m0.4712\u001b[0m  0.8597\n",
            "      7        \u001b[36m0.5740\u001b[0m       \u001b[32m0.8449\u001b[0m        \u001b[35m0.4372\u001b[0m  0.8884\n",
            "      8        \u001b[36m0.5492\u001b[0m       \u001b[32m0.8486\u001b[0m        \u001b[35m0.4168\u001b[0m  0.8496\n",
            "      9        \u001b[36m0.5387\u001b[0m       \u001b[32m0.8494\u001b[0m        0.4245  0.8500\n",
            "     10        \u001b[36m0.5165\u001b[0m       \u001b[32m0.8522\u001b[0m        \u001b[35m0.4148\u001b[0m  0.8363\n",
            "     11        \u001b[36m0.5044\u001b[0m       \u001b[32m0.8559\u001b[0m        \u001b[35m0.3974\u001b[0m  0.8417\n",
            "     12        \u001b[36m0.4913\u001b[0m       \u001b[32m0.8582\u001b[0m        \u001b[35m0.3952\u001b[0m  0.8394\n",
            "     13        \u001b[36m0.4806\u001b[0m       \u001b[32m0.8646\u001b[0m        \u001b[35m0.3865\u001b[0m  0.8661\n",
            "     14        \u001b[36m0.4723\u001b[0m       \u001b[32m0.8681\u001b[0m        \u001b[35m0.3732\u001b[0m  0.8499\n",
            "     15        \u001b[36m0.4592\u001b[0m       0.8630        \u001b[35m0.3702\u001b[0m  0.8468\n",
            "     16        \u001b[36m0.4555\u001b[0m       0.8661        0.3719  0.8845\n",
            "     17        \u001b[36m0.4515\u001b[0m       0.8648        \u001b[35m0.3680\u001b[0m  0.8723\n",
            "     18        \u001b[36m0.4407\u001b[0m       0.8668        \u001b[35m0.3652\u001b[0m  0.8737\n",
            "     19        \u001b[36m0.4363\u001b[0m       0.8674        \u001b[35m0.3620\u001b[0m  0.8760\n",
            "     20        \u001b[36m0.4319\u001b[0m       \u001b[32m0.8749\u001b[0m        \u001b[35m0.3545\u001b[0m  0.8715\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=  17.9s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.6546\u001b[0m       \u001b[32m0.6355\u001b[0m        \u001b[35m0.9300\u001b[0m  0.8883\n",
            "      2        \u001b[36m0.9547\u001b[0m       \u001b[32m0.7264\u001b[0m        \u001b[35m0.7045\u001b[0m  0.8730\n",
            "      3        \u001b[36m0.7850\u001b[0m       \u001b[32m0.7695\u001b[0m        \u001b[35m0.6151\u001b[0m  0.8526\n",
            "      4        \u001b[36m0.6994\u001b[0m       \u001b[32m0.7871\u001b[0m        \u001b[35m0.5508\u001b[0m  0.8570\n",
            "      5        \u001b[36m0.6372\u001b[0m       \u001b[32m0.8090\u001b[0m        \u001b[35m0.5109\u001b[0m  0.8667\n",
            "      6        \u001b[36m0.5975\u001b[0m       \u001b[32m0.8174\u001b[0m        \u001b[35m0.4881\u001b[0m  0.8648\n",
            "      7        \u001b[36m0.5760\u001b[0m       \u001b[32m0.8294\u001b[0m        \u001b[35m0.4622\u001b[0m  0.8672\n",
            "      8        \u001b[36m0.5488\u001b[0m       0.8220        0.4641  0.8677\n",
            "      9        \u001b[36m0.5315\u001b[0m       \u001b[32m0.8424\u001b[0m        \u001b[35m0.4331\u001b[0m  0.8529\n",
            "     10        \u001b[36m0.5260\u001b[0m       \u001b[32m0.8429\u001b[0m        \u001b[35m0.4210\u001b[0m  0.8476\n",
            "     11        \u001b[36m0.5033\u001b[0m       \u001b[32m0.8466\u001b[0m        \u001b[35m0.4151\u001b[0m  0.8372\n",
            "     12        \u001b[36m0.4992\u001b[0m       0.8420        0.4212  0.8524\n",
            "     13        \u001b[36m0.4913\u001b[0m       \u001b[32m0.8502\u001b[0m        \u001b[35m0.4041\u001b[0m  0.8644\n",
            "     14        \u001b[36m0.4822\u001b[0m       \u001b[32m0.8510\u001b[0m        \u001b[35m0.4001\u001b[0m  0.8684\n",
            "     15        \u001b[36m0.4656\u001b[0m       \u001b[32m0.8572\u001b[0m        \u001b[35m0.3889\u001b[0m  0.8528\n",
            "     16        0.4663       0.8521        0.3955  0.8346\n",
            "     17        \u001b[36m0.4557\u001b[0m       \u001b[32m0.8601\u001b[0m        0.3915  0.8249\n",
            "     18        \u001b[36m0.4511\u001b[0m       \u001b[32m0.8619\u001b[0m        \u001b[35m0.3768\u001b[0m  0.8343\n",
            "     19        \u001b[36m0.4461\u001b[0m       0.8615        0.3775  0.8414\n",
            "     20        \u001b[36m0.4396\u001b[0m       \u001b[32m0.8648\u001b[0m        \u001b[35m0.3737\u001b[0m  0.8318\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=  17.7s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.7031\u001b[0m       \u001b[32m0.5901\u001b[0m        \u001b[35m0.9470\u001b[0m  0.8451\n",
            "      2        \u001b[36m0.9554\u001b[0m       \u001b[32m0.7204\u001b[0m        \u001b[35m0.6993\u001b[0m  0.8579\n",
            "      3        \u001b[36m0.8002\u001b[0m       \u001b[32m0.7681\u001b[0m        \u001b[35m0.6141\u001b[0m  0.8505\n",
            "      4        \u001b[36m0.7101\u001b[0m       \u001b[32m0.7871\u001b[0m        \u001b[35m0.5511\u001b[0m  0.8328\n",
            "      5        \u001b[36m0.6541\u001b[0m       \u001b[32m0.8094\u001b[0m        \u001b[35m0.4981\u001b[0m  0.8490\n",
            "      6        \u001b[36m0.6137\u001b[0m       \u001b[32m0.8360\u001b[0m        \u001b[35m0.4729\u001b[0m  0.8593\n",
            "      7        \u001b[36m0.5759\u001b[0m       \u001b[32m0.8414\u001b[0m        \u001b[35m0.4454\u001b[0m  0.8634\n",
            "      8        \u001b[36m0.5560\u001b[0m       \u001b[32m0.8468\u001b[0m        \u001b[35m0.4305\u001b[0m  0.8575\n",
            "      9        \u001b[36m0.5395\u001b[0m       \u001b[32m0.8501\u001b[0m        \u001b[35m0.4237\u001b[0m  0.8403\n",
            "     10        \u001b[36m0.5232\u001b[0m       0.8500        \u001b[35m0.4165\u001b[0m  0.8361\n",
            "     11        \u001b[36m0.5044\u001b[0m       \u001b[32m0.8571\u001b[0m        \u001b[35m0.3922\u001b[0m  0.8478\n",
            "     12        \u001b[36m0.4926\u001b[0m       \u001b[32m0.8611\u001b[0m        \u001b[35m0.3876\u001b[0m  0.8338\n",
            "     13        \u001b[36m0.4852\u001b[0m       0.8574        0.3955  0.8341\n",
            "     14        \u001b[36m0.4736\u001b[0m       0.8480        0.4098  0.8331\n",
            "     15        \u001b[36m0.4726\u001b[0m       \u001b[32m0.8632\u001b[0m        \u001b[35m0.3797\u001b[0m  0.8656\n",
            "     16        \u001b[36m0.4672\u001b[0m       0.8616        0.3873  0.8541\n",
            "     17        \u001b[36m0.4628\u001b[0m       \u001b[32m0.8640\u001b[0m        \u001b[35m0.3760\u001b[0m  0.8546\n",
            "     18        \u001b[36m0.4479\u001b[0m       0.8599        0.3835  0.8526\n",
            "     19        \u001b[36m0.4427\u001b[0m       \u001b[32m0.8674\u001b[0m        \u001b[35m0.3631\u001b[0m  0.8482\n",
            "     20        \u001b[36m0.4398\u001b[0m       \u001b[32m0.8716\u001b[0m        \u001b[35m0.3622\u001b[0m  0.8570\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=  17.6s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.7059\u001b[0m       \u001b[32m0.6326\u001b[0m        \u001b[35m0.8991\u001b[0m  0.8912\n",
            "      2        \u001b[36m0.9177\u001b[0m       \u001b[32m0.7269\u001b[0m        \u001b[35m0.6926\u001b[0m  0.8613\n",
            "      3        \u001b[36m0.7707\u001b[0m       \u001b[32m0.7749\u001b[0m        \u001b[35m0.6045\u001b[0m  0.8316\n",
            "      4        \u001b[36m0.6914\u001b[0m       \u001b[32m0.8024\u001b[0m        \u001b[35m0.5238\u001b[0m  0.8297\n",
            "      5        \u001b[36m0.6361\u001b[0m       \u001b[32m0.8271\u001b[0m        \u001b[35m0.4916\u001b[0m  0.8485\n",
            "      6        \u001b[36m0.5925\u001b[0m       \u001b[32m0.8334\u001b[0m        \u001b[35m0.4664\u001b[0m  0.8322\n",
            "      7        \u001b[36m0.5697\u001b[0m       \u001b[32m0.8449\u001b[0m        \u001b[35m0.4463\u001b[0m  0.8356\n",
            "      8        \u001b[36m0.5498\u001b[0m       0.8440        \u001b[35m0.4260\u001b[0m  0.8456\n",
            "      9        \u001b[36m0.5279\u001b[0m       \u001b[32m0.8465\u001b[0m        \u001b[35m0.4178\u001b[0m  0.8503\n",
            "     10        \u001b[36m0.5159\u001b[0m       \u001b[32m0.8491\u001b[0m        \u001b[35m0.4157\u001b[0m  0.8371\n",
            "     11        \u001b[36m0.5044\u001b[0m       \u001b[32m0.8558\u001b[0m        \u001b[35m0.3994\u001b[0m  0.8490\n",
            "     12        \u001b[36m0.4863\u001b[0m       0.8451        0.4152  0.8446\n",
            "     13        0.4870       0.8538        \u001b[35m0.3913\u001b[0m  0.8559\n",
            "     14        \u001b[36m0.4776\u001b[0m       \u001b[32m0.8631\u001b[0m        \u001b[35m0.3834\u001b[0m  0.8692\n",
            "     15        \u001b[36m0.4696\u001b[0m       0.8600        0.3868  0.8581\n",
            "     16        \u001b[36m0.4596\u001b[0m       \u001b[32m0.8646\u001b[0m        \u001b[35m0.3763\u001b[0m  0.8528\n",
            "     17        \u001b[36m0.4543\u001b[0m       0.8641        \u001b[35m0.3701\u001b[0m  0.8352\n",
            "     18        \u001b[36m0.4487\u001b[0m       \u001b[32m0.8665\u001b[0m        0.3723  0.8349\n",
            "     19        0.4499       0.8642        0.3742  0.8298\n",
            "     20        \u001b[36m0.4386\u001b[0m       \u001b[32m0.8691\u001b[0m        \u001b[35m0.3624\u001b[0m  0.8453\n",
            "[CV] END lr=0.01, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=  17.5s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.2847\u001b[0m       \u001b[32m0.7404\u001b[0m        \u001b[35m0.7021\u001b[0m  0.8601\n",
            "      2        \u001b[36m0.7075\u001b[0m       \u001b[32m0.7920\u001b[0m        \u001b[35m0.5488\u001b[0m  0.8332\n",
            "      3        \u001b[36m0.5972\u001b[0m       \u001b[32m0.8241\u001b[0m        \u001b[35m0.4729\u001b[0m  0.8413\n",
            "      4        \u001b[36m0.5484\u001b[0m       \u001b[32m0.8343\u001b[0m        \u001b[35m0.4407\u001b[0m  0.8566\n",
            "      5        \u001b[36m0.5104\u001b[0m       \u001b[32m0.8397\u001b[0m        \u001b[35m0.4359\u001b[0m  0.8420\n",
            "      6        \u001b[36m0.4915\u001b[0m       0.8381        0.4379  0.8384\n",
            "      7        \u001b[36m0.4725\u001b[0m       \u001b[32m0.8469\u001b[0m        \u001b[35m0.4074\u001b[0m  0.8748\n",
            "      8        \u001b[36m0.4558\u001b[0m       0.8390        0.4205  0.8778\n",
            "      9        \u001b[36m0.4464\u001b[0m       \u001b[32m0.8550\u001b[0m        \u001b[35m0.3859\u001b[0m  0.8706\n",
            "     10        \u001b[36m0.4305\u001b[0m       \u001b[32m0.8630\u001b[0m        \u001b[35m0.3748\u001b[0m  0.8409\n",
            "[CV] END lr=0.05, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=   9.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.2564\u001b[0m       \u001b[32m0.7455\u001b[0m        \u001b[35m0.6718\u001b[0m  0.8565\n",
            "      2        \u001b[36m0.7122\u001b[0m       \u001b[32m0.8119\u001b[0m        \u001b[35m0.5326\u001b[0m  0.8361\n",
            "      3        \u001b[36m0.6017\u001b[0m       \u001b[32m0.8344\u001b[0m        \u001b[35m0.4537\u001b[0m  0.8514\n",
            "      4        \u001b[36m0.5573\u001b[0m       \u001b[32m0.8377\u001b[0m        \u001b[35m0.4372\u001b[0m  0.8458\n",
            "      5        \u001b[36m0.5196\u001b[0m       \u001b[32m0.8434\u001b[0m        \u001b[35m0.4314\u001b[0m  0.8564\n",
            "      6        \u001b[36m0.4977\u001b[0m       \u001b[32m0.8596\u001b[0m        \u001b[35m0.3934\u001b[0m  0.8533\n",
            "      7        \u001b[36m0.4767\u001b[0m       \u001b[32m0.8598\u001b[0m        \u001b[35m0.3827\u001b[0m  0.8620\n",
            "      8        \u001b[36m0.4602\u001b[0m       0.8584        0.3891  0.8459\n",
            "      9        \u001b[36m0.4493\u001b[0m       \u001b[32m0.8679\u001b[0m        \u001b[35m0.3648\u001b[0m  0.8352\n",
            "     10        \u001b[36m0.4315\u001b[0m       0.8574        0.3770  0.8448\n",
            "[CV] END lr=0.05, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=   9.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.2544\u001b[0m       \u001b[32m0.7585\u001b[0m        \u001b[35m0.6879\u001b[0m  0.8597\n",
            "      2        \u001b[36m0.7095\u001b[0m       \u001b[32m0.8170\u001b[0m        \u001b[35m0.5179\u001b[0m  0.8558\n",
            "      3        \u001b[36m0.5986\u001b[0m       \u001b[32m0.8323\u001b[0m        \u001b[35m0.4672\u001b[0m  0.8318\n",
            "      4        \u001b[36m0.5399\u001b[0m       \u001b[32m0.8430\u001b[0m        \u001b[35m0.4252\u001b[0m  0.8455\n",
            "      5        \u001b[36m0.5156\u001b[0m       \u001b[32m0.8531\u001b[0m        \u001b[35m0.4097\u001b[0m  0.8324\n",
            "      6        \u001b[36m0.4879\u001b[0m       \u001b[32m0.8580\u001b[0m        \u001b[35m0.3935\u001b[0m  0.8557\n",
            "      7        \u001b[36m0.4692\u001b[0m       0.8514        0.3989  0.8330\n",
            "      8        \u001b[36m0.4559\u001b[0m       0.8572        \u001b[35m0.3802\u001b[0m  0.8304\n",
            "      9        \u001b[36m0.4424\u001b[0m       \u001b[32m0.8670\u001b[0m        \u001b[35m0.3726\u001b[0m  0.8329\n",
            "     10        \u001b[36m0.4368\u001b[0m       0.8635        0.3753  0.8334\n",
            "[CV] END lr=0.05, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=   8.9s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.3187\u001b[0m       \u001b[32m0.7114\u001b[0m        \u001b[35m0.7263\u001b[0m  0.8275\n",
            "      2        \u001b[36m0.7404\u001b[0m       \u001b[32m0.7792\u001b[0m        \u001b[35m0.5828\u001b[0m  0.8273\n",
            "      3        \u001b[36m0.6251\u001b[0m       \u001b[32m0.7976\u001b[0m        \u001b[35m0.5292\u001b[0m  0.8466\n",
            "      4        \u001b[36m0.5678\u001b[0m       \u001b[32m0.8205\u001b[0m        \u001b[35m0.4735\u001b[0m  0.8796\n",
            "      5        \u001b[36m0.5286\u001b[0m       \u001b[32m0.8391\u001b[0m        \u001b[35m0.4361\u001b[0m  0.9186\n",
            "      6        \u001b[36m0.5071\u001b[0m       \u001b[32m0.8413\u001b[0m        \u001b[35m0.4241\u001b[0m  0.8471\n",
            "      7        \u001b[36m0.4830\u001b[0m       \u001b[32m0.8424\u001b[0m        \u001b[35m0.4193\u001b[0m  0.8452\n",
            "      8        \u001b[36m0.4743\u001b[0m       \u001b[32m0.8494\u001b[0m        \u001b[35m0.4017\u001b[0m  0.8813\n",
            "      9        \u001b[36m0.4581\u001b[0m       \u001b[32m0.8549\u001b[0m        \u001b[35m0.3940\u001b[0m  0.8806\n",
            "     10        \u001b[36m0.4510\u001b[0m       \u001b[32m0.8578\u001b[0m        \u001b[35m0.3860\u001b[0m  0.8727\n",
            "[CV] END lr=0.05, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=   9.1s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.2951\u001b[0m       \u001b[32m0.7526\u001b[0m        \u001b[35m0.6861\u001b[0m  0.8581\n",
            "      2        \u001b[36m0.7403\u001b[0m       \u001b[32m0.7983\u001b[0m        \u001b[35m0.5533\u001b[0m  0.8541\n",
            "      3        \u001b[36m0.6174\u001b[0m       \u001b[32m0.8251\u001b[0m        \u001b[35m0.4837\u001b[0m  0.8404\n",
            "      4        \u001b[36m0.5657\u001b[0m       \u001b[32m0.8396\u001b[0m        \u001b[35m0.4361\u001b[0m  0.8540\n",
            "      5        \u001b[36m0.5277\u001b[0m       \u001b[32m0.8499\u001b[0m        \u001b[35m0.4099\u001b[0m  0.8311\n",
            "      6        \u001b[36m0.5045\u001b[0m       \u001b[32m0.8525\u001b[0m        \u001b[35m0.4030\u001b[0m  0.8328\n",
            "      7        \u001b[36m0.4822\u001b[0m       \u001b[32m0.8616\u001b[0m        \u001b[35m0.3885\u001b[0m  0.8509\n",
            "      8        \u001b[36m0.4709\u001b[0m       \u001b[32m0.8619\u001b[0m        \u001b[35m0.3790\u001b[0m  0.8883\n",
            "      9        \u001b[36m0.4610\u001b[0m       0.8604        \u001b[35m0.3757\u001b[0m  0.8557\n",
            "     10        \u001b[36m0.4436\u001b[0m       0.8578        0.3808  0.8571\n",
            "[CV] END lr=0.05, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=   9.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.2810\u001b[0m       \u001b[32m0.7250\u001b[0m        \u001b[35m0.7359\u001b[0m  0.8491\n",
            "      2        \u001b[36m0.7257\u001b[0m       \u001b[32m0.7726\u001b[0m        \u001b[35m0.5646\u001b[0m  0.8514\n",
            "      3        \u001b[36m0.6065\u001b[0m       \u001b[32m0.8223\u001b[0m        \u001b[35m0.4834\u001b[0m  0.8493\n",
            "      4        \u001b[36m0.5556\u001b[0m       \u001b[32m0.8406\u001b[0m        \u001b[35m0.4290\u001b[0m  0.8332\n",
            "      5        \u001b[36m0.5197\u001b[0m       \u001b[32m0.8456\u001b[0m        \u001b[35m0.4251\u001b[0m  0.8387\n",
            "      6        \u001b[36m0.4967\u001b[0m       \u001b[32m0.8539\u001b[0m        \u001b[35m0.4056\u001b[0m  0.8245\n",
            "      7        \u001b[36m0.4782\u001b[0m       \u001b[32m0.8621\u001b[0m        \u001b[35m0.3895\u001b[0m  0.8348\n",
            "      8        \u001b[36m0.4655\u001b[0m       0.8521        0.3960  0.8390\n",
            "      9        \u001b[36m0.4539\u001b[0m       \u001b[32m0.8650\u001b[0m        \u001b[35m0.3870\u001b[0m  0.8316\n",
            "     10        \u001b[36m0.4424\u001b[0m       0.8636        \u001b[35m0.3710\u001b[0m  0.8423\n",
            "[CV] END lr=0.05, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=   8.9s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0972\u001b[0m       \u001b[32m0.7840\u001b[0m        \u001b[35m0.6014\u001b[0m  0.8884\n",
            "      2        \u001b[36m0.6648\u001b[0m       \u001b[32m0.7874\u001b[0m        \u001b[35m0.5345\u001b[0m  0.8565\n",
            "      3        \u001b[36m0.6074\u001b[0m       \u001b[32m0.8194\u001b[0m        \u001b[35m0.4984\u001b[0m  0.8637\n",
            "      4        \u001b[36m0.5964\u001b[0m       \u001b[32m0.8260\u001b[0m        \u001b[35m0.4606\u001b[0m  0.8237\n",
            "      5        \u001b[36m0.5721\u001b[0m       0.8256        \u001b[35m0.4557\u001b[0m  0.8264\n",
            "      6        \u001b[36m0.5480\u001b[0m       \u001b[32m0.8334\u001b[0m        \u001b[35m0.4499\u001b[0m  0.8278\n",
            "      7        \u001b[36m0.5358\u001b[0m       0.8296        \u001b[35m0.4313\u001b[0m  0.8358\n",
            "      8        \u001b[36m0.5198\u001b[0m       \u001b[32m0.8444\u001b[0m        \u001b[35m0.4195\u001b[0m  0.8526\n",
            "      9        \u001b[36m0.5096\u001b[0m       \u001b[32m0.8464\u001b[0m        0.4235  0.8353\n",
            "     10        \u001b[36m0.5056\u001b[0m       0.8444        0.4287  0.8434\n",
            "[CV] END lr=0.05, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=   9.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0495\u001b[0m       \u001b[32m0.7899\u001b[0m        \u001b[35m0.5702\u001b[0m  0.8340\n",
            "      2        \u001b[36m0.6696\u001b[0m       \u001b[32m0.8080\u001b[0m        \u001b[35m0.4824\u001b[0m  0.8347\n",
            "      3        \u001b[36m0.6088\u001b[0m       \u001b[32m0.8371\u001b[0m        \u001b[35m0.4501\u001b[0m  0.8530\n",
            "      4        \u001b[36m0.5815\u001b[0m       0.8340        \u001b[35m0.4479\u001b[0m  0.8754\n",
            "      5        \u001b[36m0.5613\u001b[0m       \u001b[32m0.8423\u001b[0m        \u001b[35m0.4357\u001b[0m  0.8791\n",
            "      6        \u001b[36m0.5442\u001b[0m       0.8265        0.4536  0.8616\n",
            "      7        \u001b[36m0.5372\u001b[0m       0.8334        0.4373  0.8287\n",
            "      8        \u001b[36m0.5371\u001b[0m       \u001b[32m0.8476\u001b[0m        \u001b[35m0.4097\u001b[0m  0.8420\n",
            "      9        \u001b[36m0.5116\u001b[0m       \u001b[32m0.8615\u001b[0m        \u001b[35m0.3921\u001b[0m  0.8446\n",
            "     10        \u001b[36m0.4977\u001b[0m       0.8476        0.4256  0.8420\n",
            "[CV] END lr=0.05, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=   9.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0794\u001b[0m       \u001b[32m0.8007\u001b[0m        \u001b[35m0.5503\u001b[0m  0.8414\n",
            "      2        \u001b[36m0.6652\u001b[0m       \u001b[32m0.8161\u001b[0m        \u001b[35m0.5014\u001b[0m  0.8458\n",
            "      3        \u001b[36m0.6094\u001b[0m       0.8104        \u001b[35m0.4998\u001b[0m  0.8230\n",
            "      4        \u001b[36m0.5884\u001b[0m       \u001b[32m0.8427\u001b[0m        \u001b[35m0.4490\u001b[0m  0.8527\n",
            "      5        \u001b[36m0.5656\u001b[0m       \u001b[32m0.8431\u001b[0m        \u001b[35m0.4425\u001b[0m  0.8492\n",
            "      6        \u001b[36m0.5512\u001b[0m       0.8394        0.4459  0.8671\n",
            "      7        \u001b[36m0.5349\u001b[0m       0.8406        \u001b[35m0.4288\u001b[0m  0.8510\n",
            "      8        \u001b[36m0.5191\u001b[0m       \u001b[32m0.8505\u001b[0m        \u001b[35m0.4172\u001b[0m  0.8857\n",
            "      9        \u001b[36m0.5077\u001b[0m       \u001b[32m0.8536\u001b[0m        \u001b[35m0.4121\u001b[0m  0.8559\n",
            "     10        \u001b[36m0.5068\u001b[0m       \u001b[32m0.8576\u001b[0m        \u001b[35m0.3923\u001b[0m  0.8339\n",
            "[CV] END lr=0.05, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=   9.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0751\u001b[0m       \u001b[32m0.7884\u001b[0m        \u001b[35m0.5898\u001b[0m  0.8334\n",
            "      2        \u001b[36m0.6720\u001b[0m       \u001b[32m0.8011\u001b[0m        \u001b[35m0.5259\u001b[0m  0.8440\n",
            "      3        \u001b[36m0.6058\u001b[0m       \u001b[32m0.8149\u001b[0m        \u001b[35m0.4944\u001b[0m  0.8541\n",
            "      4        \u001b[36m0.5771\u001b[0m       \u001b[32m0.8297\u001b[0m        \u001b[35m0.4671\u001b[0m  0.8379\n",
            "      5        \u001b[36m0.5669\u001b[0m       0.8283        \u001b[35m0.4569\u001b[0m  0.8472\n",
            "      6        \u001b[36m0.5513\u001b[0m       \u001b[32m0.8303\u001b[0m        \u001b[35m0.4461\u001b[0m  0.8427\n",
            "      7        \u001b[36m0.5476\u001b[0m       0.8265        0.4686  0.8341\n",
            "      8        \u001b[36m0.5363\u001b[0m       \u001b[32m0.8330\u001b[0m        \u001b[35m0.4456\u001b[0m  0.8347\n",
            "      9        \u001b[36m0.5362\u001b[0m       \u001b[32m0.8407\u001b[0m        \u001b[35m0.4283\u001b[0m  0.8307\n",
            "     10        \u001b[36m0.5339\u001b[0m       0.8389        0.4306  0.8602\n",
            "[CV] END lr=0.05, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=   8.9s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0807\u001b[0m       \u001b[32m0.7811\u001b[0m        \u001b[35m0.5991\u001b[0m  0.8845\n",
            "      2        \u001b[36m0.6604\u001b[0m       \u001b[32m0.8186\u001b[0m        \u001b[35m0.4896\u001b[0m  0.8431\n",
            "      3        \u001b[36m0.6061\u001b[0m       \u001b[32m0.8366\u001b[0m        \u001b[35m0.4555\u001b[0m  0.8334\n",
            "      4        \u001b[36m0.5804\u001b[0m       \u001b[32m0.8414\u001b[0m        \u001b[35m0.4436\u001b[0m  0.8426\n",
            "      5        \u001b[36m0.5681\u001b[0m       0.8194        0.4710  0.8323\n",
            "      6        \u001b[36m0.5612\u001b[0m       0.8319        \u001b[35m0.4418\u001b[0m  0.8293\n",
            "      7        \u001b[36m0.5488\u001b[0m       0.8291        0.4603  0.8323\n",
            "      8        \u001b[36m0.5462\u001b[0m       \u001b[32m0.8468\u001b[0m        \u001b[35m0.4255\u001b[0m  0.8302\n",
            "      9        \u001b[36m0.5290\u001b[0m       0.8465        \u001b[35m0.4254\u001b[0m  0.8480\n",
            "     10        0.5297       0.8240        0.4653  0.8325\n",
            "[CV] END lr=0.05, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=   9.1s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0852\u001b[0m       \u001b[32m0.7798\u001b[0m        \u001b[35m0.6200\u001b[0m  0.8416\n",
            "      2        \u001b[36m0.6628\u001b[0m       \u001b[32m0.8166\u001b[0m        \u001b[35m0.4816\u001b[0m  0.8499\n",
            "      3        \u001b[36m0.6019\u001b[0m       \u001b[32m0.8394\u001b[0m        \u001b[35m0.4540\u001b[0m  0.8751\n",
            "      4        \u001b[36m0.5876\u001b[0m       0.8329        \u001b[35m0.4503\u001b[0m  0.8608\n",
            "      5        \u001b[36m0.5643\u001b[0m       0.8296        0.4539  0.8717\n",
            "      6        \u001b[36m0.5512\u001b[0m       \u001b[32m0.8474\u001b[0m        \u001b[35m0.4274\u001b[0m  0.8357\n",
            "      7        \u001b[36m0.5497\u001b[0m       0.8462        0.4427  0.8407\n",
            "      8        \u001b[36m0.5439\u001b[0m       0.8442        \u001b[35m0.4250\u001b[0m  0.8275\n",
            "      9        0.5462       0.8353        0.4468  0.8362\n",
            "     10        \u001b[36m0.5366\u001b[0m       0.8431        0.4261  0.8249\n",
            "[CV] END lr=0.05, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=   9.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.3837\u001b[0m       \u001b[32m0.6815\u001b[0m        \u001b[35m0.7421\u001b[0m  0.8197\n",
            "      2        \u001b[36m0.8013\u001b[0m       \u001b[32m0.7679\u001b[0m        \u001b[35m0.5880\u001b[0m  0.8384\n",
            "      3        \u001b[36m0.6881\u001b[0m       \u001b[32m0.7867\u001b[0m        \u001b[35m0.5327\u001b[0m  0.8314\n",
            "      4        \u001b[36m0.6247\u001b[0m       \u001b[32m0.8205\u001b[0m        \u001b[35m0.4891\u001b[0m  0.8539\n",
            "      5        \u001b[36m0.5913\u001b[0m       \u001b[32m0.8216\u001b[0m        \u001b[35m0.4726\u001b[0m  0.8600\n",
            "      6        \u001b[36m0.5610\u001b[0m       \u001b[32m0.8275\u001b[0m        \u001b[35m0.4580\u001b[0m  0.8662\n",
            "      7        \u001b[36m0.5425\u001b[0m       \u001b[32m0.8409\u001b[0m        \u001b[35m0.4269\u001b[0m  0.8506\n",
            "      8        \u001b[36m0.5200\u001b[0m       \u001b[32m0.8429\u001b[0m        \u001b[35m0.4111\u001b[0m  0.8652\n",
            "      9        \u001b[36m0.4967\u001b[0m       \u001b[32m0.8511\u001b[0m        \u001b[35m0.4045\u001b[0m  0.8522\n",
            "     10        \u001b[36m0.4868\u001b[0m       0.8504        0.4101  0.8306\n",
            "[CV] END lr=0.05, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=   9.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.3795\u001b[0m       \u001b[32m0.6870\u001b[0m        \u001b[35m0.7478\u001b[0m  0.8282\n",
            "      2        \u001b[36m0.8060\u001b[0m       \u001b[32m0.7843\u001b[0m        \u001b[35m0.5776\u001b[0m  0.8409\n",
            "      3        \u001b[36m0.6803\u001b[0m       \u001b[32m0.8135\u001b[0m        \u001b[35m0.5057\u001b[0m  0.8295\n",
            "      4        \u001b[36m0.6251\u001b[0m       \u001b[32m0.8216\u001b[0m        \u001b[35m0.4846\u001b[0m  0.8398\n",
            "      5        \u001b[36m0.5886\u001b[0m       \u001b[32m0.8365\u001b[0m        \u001b[35m0.4541\u001b[0m  0.8363\n",
            "      6        \u001b[36m0.5641\u001b[0m       \u001b[32m0.8394\u001b[0m        \u001b[35m0.4337\u001b[0m  0.8343\n",
            "      7        \u001b[36m0.5313\u001b[0m       \u001b[32m0.8542\u001b[0m        \u001b[35m0.4034\u001b[0m  0.8676\n",
            "      8        \u001b[36m0.5174\u001b[0m       \u001b[32m0.8552\u001b[0m        \u001b[35m0.4030\u001b[0m  0.8706\n",
            "      9        \u001b[36m0.5059\u001b[0m       \u001b[32m0.8609\u001b[0m        \u001b[35m0.3828\u001b[0m  0.8399\n",
            "     10        \u001b[36m0.4959\u001b[0m       0.8516        0.3978  0.8575\n",
            "[CV] END lr=0.05, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=   9.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.3798\u001b[0m       \u001b[32m0.7051\u001b[0m        \u001b[35m0.7396\u001b[0m  0.8746\n",
            "      2        \u001b[36m0.8045\u001b[0m       \u001b[32m0.7695\u001b[0m        \u001b[35m0.6023\u001b[0m  0.8656\n",
            "      3        \u001b[36m0.6851\u001b[0m       \u001b[32m0.8085\u001b[0m        \u001b[35m0.5138\u001b[0m  0.8341\n",
            "      4        \u001b[36m0.6319\u001b[0m       \u001b[32m0.8236\u001b[0m        \u001b[35m0.4834\u001b[0m  0.8322\n",
            "      5        \u001b[36m0.5889\u001b[0m       \u001b[32m0.8330\u001b[0m        \u001b[35m0.4609\u001b[0m  0.8394\n",
            "      6        \u001b[36m0.5574\u001b[0m       \u001b[32m0.8488\u001b[0m        \u001b[35m0.4259\u001b[0m  0.8246\n",
            "      7        \u001b[36m0.5345\u001b[0m       \u001b[32m0.8492\u001b[0m        \u001b[35m0.4213\u001b[0m  0.8431\n",
            "      8        \u001b[36m0.5210\u001b[0m       \u001b[32m0.8535\u001b[0m        \u001b[35m0.4103\u001b[0m  0.8434\n",
            "      9        \u001b[36m0.5078\u001b[0m       0.8516        \u001b[35m0.4011\u001b[0m  0.8549\n",
            "     10        \u001b[36m0.4894\u001b[0m       \u001b[32m0.8614\u001b[0m        \u001b[35m0.3932\u001b[0m  0.8608\n",
            "[CV] END lr=0.05, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=   9.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.3654\u001b[0m       \u001b[32m0.7240\u001b[0m        \u001b[35m0.7416\u001b[0m  0.8554\n",
            "      2        \u001b[36m0.8028\u001b[0m       \u001b[32m0.7666\u001b[0m        \u001b[35m0.5984\u001b[0m  0.8526\n",
            "      3        \u001b[36m0.6849\u001b[0m       \u001b[32m0.7971\u001b[0m        \u001b[35m0.5274\u001b[0m  0.8554\n",
            "      4        \u001b[36m0.6286\u001b[0m       \u001b[32m0.8176\u001b[0m        \u001b[35m0.4854\u001b[0m  0.8705\n",
            "      5        \u001b[36m0.5909\u001b[0m       \u001b[32m0.8227\u001b[0m        \u001b[35m0.4776\u001b[0m  0.8547\n",
            "      6        \u001b[36m0.5648\u001b[0m       \u001b[32m0.8301\u001b[0m        \u001b[35m0.4481\u001b[0m  0.8411\n",
            "      7        \u001b[36m0.5451\u001b[0m       \u001b[32m0.8420\u001b[0m        \u001b[35m0.4253\u001b[0m  0.8437\n",
            "      8        \u001b[36m0.5257\u001b[0m       \u001b[32m0.8459\u001b[0m        0.4274  0.8417\n",
            "      9        \u001b[36m0.5066\u001b[0m       \u001b[32m0.8461\u001b[0m        \u001b[35m0.4122\u001b[0m  0.8379\n",
            "     10        \u001b[36m0.5019\u001b[0m       0.8461        \u001b[35m0.4090\u001b[0m  0.8339\n",
            "[CV] END lr=0.05, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=   9.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.3869\u001b[0m       \u001b[32m0.6830\u001b[0m        \u001b[35m0.7939\u001b[0m  0.8549\n",
            "      2        \u001b[36m0.8273\u001b[0m       \u001b[32m0.7575\u001b[0m        \u001b[35m0.6264\u001b[0m  0.8491\n",
            "      3        \u001b[36m0.7067\u001b[0m       \u001b[32m0.8045\u001b[0m        \u001b[35m0.5269\u001b[0m  0.8434\n",
            "      4        \u001b[36m0.6400\u001b[0m       \u001b[32m0.8050\u001b[0m        \u001b[35m0.5059\u001b[0m  0.8382\n",
            "      5        \u001b[36m0.6006\u001b[0m       \u001b[32m0.8400\u001b[0m        \u001b[35m0.4562\u001b[0m  0.8314\n",
            "      6        \u001b[36m0.5722\u001b[0m       0.8246        0.4577  0.8480\n",
            "      7        \u001b[36m0.5481\u001b[0m       0.8399        \u001b[35m0.4375\u001b[0m  0.8477\n",
            "      8        \u001b[36m0.5310\u001b[0m       \u001b[32m0.8481\u001b[0m        \u001b[35m0.4185\u001b[0m  0.8595\n",
            "      9        \u001b[36m0.5188\u001b[0m       \u001b[32m0.8526\u001b[0m        \u001b[35m0.4030\u001b[0m  0.8598\n",
            "     10        \u001b[36m0.5029\u001b[0m       \u001b[32m0.8588\u001b[0m        \u001b[35m0.3833\u001b[0m  0.8370\n",
            "[CV] END lr=0.05, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=   9.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.4091\u001b[0m       \u001b[32m0.7175\u001b[0m        \u001b[35m0.7384\u001b[0m  0.8654\n",
            "      2        \u001b[36m0.8182\u001b[0m       \u001b[32m0.7762\u001b[0m        \u001b[35m0.5899\u001b[0m  0.8595\n",
            "      3        \u001b[36m0.6898\u001b[0m       \u001b[32m0.8174\u001b[0m        \u001b[35m0.5136\u001b[0m  0.8520\n",
            "      4        \u001b[36m0.6321\u001b[0m       0.8150        \u001b[35m0.4925\u001b[0m  0.8624\n",
            "      5        \u001b[36m0.5839\u001b[0m       \u001b[32m0.8323\u001b[0m        \u001b[35m0.4644\u001b[0m  0.8581\n",
            "      6        \u001b[36m0.5607\u001b[0m       \u001b[32m0.8425\u001b[0m        \u001b[35m0.4335\u001b[0m  0.8482\n",
            "      7        \u001b[36m0.5417\u001b[0m       \u001b[32m0.8476\u001b[0m        \u001b[35m0.4177\u001b[0m  0.8451\n",
            "      8        \u001b[36m0.5236\u001b[0m       \u001b[32m0.8486\u001b[0m        \u001b[35m0.4100\u001b[0m  0.8478\n",
            "      9        \u001b[36m0.5100\u001b[0m       0.8486        0.4132  0.8556\n",
            "     10        \u001b[36m0.5031\u001b[0m       0.8459        \u001b[35m0.4072\u001b[0m  0.8630\n",
            "[CV] END lr=0.05, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=   9.1s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.2014\u001b[0m       \u001b[32m0.7339\u001b[0m        \u001b[35m0.6737\u001b[0m  0.8612\n",
            "      2        \u001b[36m0.7725\u001b[0m       \u001b[32m0.7768\u001b[0m        \u001b[35m0.5558\u001b[0m  0.8596\n",
            "      3        \u001b[36m0.7294\u001b[0m       \u001b[32m0.7883\u001b[0m        \u001b[35m0.5464\u001b[0m  0.8392\n",
            "      4        \u001b[36m0.7008\u001b[0m       \u001b[32m0.7929\u001b[0m        \u001b[35m0.5093\u001b[0m  0.8482\n",
            "      5        \u001b[36m0.6873\u001b[0m       \u001b[32m0.8111\u001b[0m        0.5129  0.8621\n",
            "      6        \u001b[36m0.6688\u001b[0m       0.8070        \u001b[35m0.5024\u001b[0m  0.8972\n",
            "      7        \u001b[36m0.6538\u001b[0m       \u001b[32m0.8196\u001b[0m        \u001b[35m0.4893\u001b[0m  0.8637\n",
            "      8        \u001b[36m0.6446\u001b[0m       0.8194        \u001b[35m0.4795\u001b[0m  0.8515\n",
            "      9        \u001b[36m0.6355\u001b[0m       \u001b[32m0.8201\u001b[0m        0.4850  0.8524\n",
            "     10        \u001b[36m0.6263\u001b[0m       \u001b[32m0.8295\u001b[0m        \u001b[35m0.4584\u001b[0m  0.8340\n",
            "[CV] END lr=0.05, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=   9.1s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1739\u001b[0m       \u001b[32m0.7532\u001b[0m        \u001b[35m0.6423\u001b[0m  0.8448\n",
            "      2        \u001b[36m0.7722\u001b[0m       \u001b[32m0.7869\u001b[0m        \u001b[35m0.5692\u001b[0m  0.8602\n",
            "      3        \u001b[36m0.7267\u001b[0m       \u001b[32m0.8060\u001b[0m        \u001b[35m0.5275\u001b[0m  0.8472\n",
            "      4        \u001b[36m0.7108\u001b[0m       0.7915        0.5461  0.8863\n",
            "      5        \u001b[36m0.6832\u001b[0m       \u001b[32m0.8167\u001b[0m        \u001b[35m0.5170\u001b[0m  0.8608\n",
            "      6        \u001b[36m0.6632\u001b[0m       \u001b[32m0.8246\u001b[0m        \u001b[35m0.5076\u001b[0m  0.8294\n",
            "      7        \u001b[36m0.6522\u001b[0m       \u001b[32m0.8293\u001b[0m        \u001b[35m0.4817\u001b[0m  0.8267\n",
            "      8        \u001b[36m0.6322\u001b[0m       \u001b[32m0.8355\u001b[0m        0.4843  0.8242\n",
            "      9        0.6408       0.8270        0.4879  0.8405\n",
            "     10        \u001b[36m0.6122\u001b[0m       \u001b[32m0.8433\u001b[0m        \u001b[35m0.4641\u001b[0m  0.8350\n",
            "[CV] END lr=0.05, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=   9.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1732\u001b[0m       \u001b[32m0.7219\u001b[0m        \u001b[35m0.6522\u001b[0m  0.8215\n",
            "      2        \u001b[36m0.7671\u001b[0m       \u001b[32m0.7840\u001b[0m        \u001b[35m0.5851\u001b[0m  0.8432\n",
            "      3        \u001b[36m0.7167\u001b[0m       \u001b[32m0.8034\u001b[0m        \u001b[35m0.5185\u001b[0m  0.8370\n",
            "      4        \u001b[36m0.6975\u001b[0m       \u001b[32m0.8067\u001b[0m        \u001b[35m0.5158\u001b[0m  0.8354\n",
            "      5        \u001b[36m0.6840\u001b[0m       \u001b[32m0.8250\u001b[0m        \u001b[35m0.4969\u001b[0m  0.8378\n",
            "      6        \u001b[36m0.6596\u001b[0m       \u001b[32m0.8255\u001b[0m        0.4999  0.8728\n",
            "      7        \u001b[36m0.6428\u001b[0m       \u001b[32m0.8266\u001b[0m        \u001b[35m0.4898\u001b[0m  0.8504\n",
            "      8        \u001b[36m0.6373\u001b[0m       0.8246        0.4929  0.8591\n",
            "      9        \u001b[36m0.6265\u001b[0m       0.8199        \u001b[35m0.4788\u001b[0m  0.8538\n",
            "     10        \u001b[36m0.6195\u001b[0m       \u001b[32m0.8439\u001b[0m        \u001b[35m0.4534\u001b[0m  0.8486\n",
            "[CV] END lr=0.05, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=   9.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1865\u001b[0m       \u001b[32m0.7460\u001b[0m        \u001b[35m0.6714\u001b[0m  0.8716\n",
            "      2        \u001b[36m0.7609\u001b[0m       \u001b[32m0.7555\u001b[0m        \u001b[35m0.5753\u001b[0m  0.8556\n",
            "      3        \u001b[36m0.7138\u001b[0m       \u001b[32m0.7825\u001b[0m        \u001b[35m0.5473\u001b[0m  0.8489\n",
            "      4        \u001b[36m0.6912\u001b[0m       \u001b[32m0.8090\u001b[0m        \u001b[35m0.5317\u001b[0m  0.8589\n",
            "      5        \u001b[36m0.6789\u001b[0m       0.7970        0.5415  0.8499\n",
            "      6        0.6827       0.7820        0.5410  0.8470\n",
            "      7        \u001b[36m0.6665\u001b[0m       \u001b[32m0.8135\u001b[0m        \u001b[35m0.5129\u001b[0m  0.8520\n",
            "      8        \u001b[36m0.6644\u001b[0m       0.7984        0.5214  0.8654\n",
            "      9        \u001b[36m0.6541\u001b[0m       \u001b[32m0.8213\u001b[0m        0.5234  0.8562\n",
            "     10        \u001b[36m0.6496\u001b[0m       0.8096        \u001b[35m0.4973\u001b[0m  0.8671\n",
            "[CV] END lr=0.05, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=   9.1s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1703\u001b[0m       \u001b[32m0.7232\u001b[0m        \u001b[35m0.6703\u001b[0m  0.8489\n",
            "      2        \u001b[36m0.7795\u001b[0m       \u001b[32m0.7866\u001b[0m        \u001b[35m0.5581\u001b[0m  0.8564\n",
            "      3        \u001b[36m0.7403\u001b[0m       0.7847        \u001b[35m0.5405\u001b[0m  0.8511\n",
            "      4        \u001b[36m0.7015\u001b[0m       \u001b[32m0.7997\u001b[0m        \u001b[35m0.5332\u001b[0m  0.8593\n",
            "      5        \u001b[36m0.6830\u001b[0m       \u001b[32m0.8147\u001b[0m        \u001b[35m0.5017\u001b[0m  0.8673\n",
            "      6        0.6852       0.7933        0.5171  0.8522\n",
            "      7        \u001b[36m0.6648\u001b[0m       \u001b[32m0.8235\u001b[0m        \u001b[35m0.4851\u001b[0m  0.8384\n",
            "      8        \u001b[36m0.6502\u001b[0m       0.8140        \u001b[35m0.4838\u001b[0m  0.8430\n",
            "      9        0.6555       \u001b[32m0.8269\u001b[0m        0.5013  0.8309\n",
            "     10        \u001b[36m0.6490\u001b[0m       0.8231        0.4984  0.8358\n",
            "[CV] END lr=0.05, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=   9.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1944\u001b[0m       \u001b[32m0.7592\u001b[0m        \u001b[35m0.6492\u001b[0m  0.8573\n",
            "      2        \u001b[36m0.7709\u001b[0m       \u001b[32m0.7871\u001b[0m        \u001b[35m0.5500\u001b[0m  0.8563\n",
            "      3        \u001b[36m0.7170\u001b[0m       \u001b[32m0.7994\u001b[0m        \u001b[35m0.5422\u001b[0m  0.8554\n",
            "      4        \u001b[36m0.6784\u001b[0m       \u001b[32m0.8066\u001b[0m        \u001b[35m0.5061\u001b[0m  0.8549\n",
            "      5        \u001b[36m0.6667\u001b[0m       \u001b[32m0.8161\u001b[0m        0.5066  0.8479\n",
            "      6        \u001b[36m0.6639\u001b[0m       \u001b[32m0.8185\u001b[0m        0.5131  0.8405\n",
            "      7        \u001b[36m0.6471\u001b[0m       \u001b[32m0.8303\u001b[0m        \u001b[35m0.4819\u001b[0m  0.8474\n",
            "      8        0.6480       \u001b[32m0.8305\u001b[0m        0.4869  0.8332\n",
            "      9        \u001b[36m0.6399\u001b[0m       0.8237        0.5043  0.8522\n",
            "     10        0.6481       0.8261        0.4828  0.8487\n",
            "[CV] END lr=0.05, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=   9.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.2660\u001b[0m       \u001b[32m0.7330\u001b[0m        \u001b[35m0.7154\u001b[0m  0.8616\n",
            "      2        \u001b[36m0.7188\u001b[0m       \u001b[32m0.8004\u001b[0m        \u001b[35m0.5489\u001b[0m  0.8505\n",
            "      3        \u001b[36m0.6045\u001b[0m       \u001b[32m0.8195\u001b[0m        \u001b[35m0.4901\u001b[0m  0.8634\n",
            "      4        \u001b[36m0.5456\u001b[0m       \u001b[32m0.8355\u001b[0m        \u001b[35m0.4384\u001b[0m  0.8657\n",
            "      5        \u001b[36m0.5202\u001b[0m       \u001b[32m0.8451\u001b[0m        \u001b[35m0.4164\u001b[0m  0.8641\n",
            "      6        \u001b[36m0.4924\u001b[0m       0.8400        0.4270  0.8568\n",
            "      7        \u001b[36m0.4671\u001b[0m       \u001b[32m0.8469\u001b[0m        \u001b[35m0.4018\u001b[0m  0.8787\n",
            "      8        \u001b[36m0.4610\u001b[0m       \u001b[32m0.8611\u001b[0m        \u001b[35m0.3829\u001b[0m  0.8769\n",
            "      9        \u001b[36m0.4431\u001b[0m       0.8564        0.3910  0.8724\n",
            "     10        \u001b[36m0.4332\u001b[0m       0.8598        \u001b[35m0.3789\u001b[0m  0.8505\n",
            "     11        \u001b[36m0.4249\u001b[0m       0.8601        \u001b[35m0.3747\u001b[0m  0.8451\n",
            "     12        \u001b[36m0.4142\u001b[0m       \u001b[32m0.8649\u001b[0m        \u001b[35m0.3670\u001b[0m  0.8440\n",
            "     13        \u001b[36m0.4074\u001b[0m       0.8648        \u001b[35m0.3632\u001b[0m  0.8318\n",
            "     14        \u001b[36m0.3995\u001b[0m       \u001b[32m0.8691\u001b[0m        \u001b[35m0.3511\u001b[0m  0.8328\n",
            "     15        \u001b[36m0.3968\u001b[0m       \u001b[32m0.8738\u001b[0m        \u001b[35m0.3460\u001b[0m  0.8424\n",
            "     16        \u001b[36m0.3820\u001b[0m       0.8602        0.3682  0.8374\n",
            "     17        \u001b[36m0.3777\u001b[0m       0.8712        0.3570  0.8369\n",
            "     18        \u001b[36m0.3729\u001b[0m       0.8725        0.3573  0.8395\n",
            "     19        \u001b[36m0.3695\u001b[0m       \u001b[32m0.8765\u001b[0m        \u001b[35m0.3365\u001b[0m  0.8457\n",
            "     20        \u001b[36m0.3625\u001b[0m       \u001b[32m0.8798\u001b[0m        \u001b[35m0.3345\u001b[0m  0.8584\n",
            "[CV] END lr=0.05, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=  17.6s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.2825\u001b[0m       \u001b[32m0.7234\u001b[0m        \u001b[35m0.6899\u001b[0m  0.8685\n",
            "      2        \u001b[36m0.7262\u001b[0m       \u001b[32m0.7981\u001b[0m        \u001b[35m0.5224\u001b[0m  0.8581\n",
            "      3        \u001b[36m0.6103\u001b[0m       \u001b[32m0.8226\u001b[0m        \u001b[35m0.4839\u001b[0m  0.8351\n",
            "      4        \u001b[36m0.5562\u001b[0m       \u001b[32m0.8377\u001b[0m        \u001b[35m0.4450\u001b[0m  0.8265\n",
            "      5        \u001b[36m0.5228\u001b[0m       \u001b[32m0.8404\u001b[0m        \u001b[35m0.4315\u001b[0m  0.8331\n",
            "      6        \u001b[36m0.4938\u001b[0m       \u001b[32m0.8514\u001b[0m        \u001b[35m0.4012\u001b[0m  0.8311\n",
            "      7        \u001b[36m0.4741\u001b[0m       \u001b[32m0.8598\u001b[0m        \u001b[35m0.3896\u001b[0m  0.8348\n",
            "      8        \u001b[36m0.4572\u001b[0m       0.8488        0.4078  0.8257\n",
            "      9        \u001b[36m0.4456\u001b[0m       \u001b[32m0.8626\u001b[0m        \u001b[35m0.3780\u001b[0m  0.8319\n",
            "     10        \u001b[36m0.4357\u001b[0m       \u001b[32m0.8666\u001b[0m        \u001b[35m0.3624\u001b[0m  0.8177\n",
            "     11        \u001b[36m0.4276\u001b[0m       \u001b[32m0.8682\u001b[0m        0.3638  0.8201\n",
            "     12        \u001b[36m0.4181\u001b[0m       \u001b[32m0.8736\u001b[0m        \u001b[35m0.3518\u001b[0m  0.8348\n",
            "     13        \u001b[36m0.4076\u001b[0m       0.8709        0.3576  0.8412\n",
            "     14        \u001b[36m0.4013\u001b[0m       \u001b[32m0.8771\u001b[0m        \u001b[35m0.3461\u001b[0m  0.9243\n",
            "     15        \u001b[36m0.3914\u001b[0m       \u001b[32m0.8786\u001b[0m        \u001b[35m0.3416\u001b[0m  0.8552\n",
            "     16        \u001b[36m0.3860\u001b[0m       0.8692        0.3504  0.8368\n",
            "     17        \u001b[36m0.3797\u001b[0m       0.8679        0.3555  0.8240\n",
            "     18        \u001b[36m0.3774\u001b[0m       0.8751        0.3450  0.8373\n",
            "     19        \u001b[36m0.3718\u001b[0m       0.8771        0.3417  0.8425\n",
            "     20        \u001b[36m0.3688\u001b[0m       0.8761        0.3417  0.8453\n",
            "[CV] END lr=0.05, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=  17.4s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.2641\u001b[0m       \u001b[32m0.7372\u001b[0m        \u001b[35m0.6772\u001b[0m  0.8314\n",
            "      2        \u001b[36m0.7071\u001b[0m       \u001b[32m0.8087\u001b[0m        \u001b[35m0.5300\u001b[0m  0.8418\n",
            "      3        \u001b[36m0.6042\u001b[0m       \u001b[32m0.8397\u001b[0m        \u001b[35m0.4574\u001b[0m  0.8380\n",
            "      4        \u001b[36m0.5522\u001b[0m       \u001b[32m0.8407\u001b[0m        \u001b[35m0.4468\u001b[0m  0.8218\n",
            "      5        \u001b[36m0.5203\u001b[0m       \u001b[32m0.8532\u001b[0m        \u001b[35m0.4134\u001b[0m  0.8496\n",
            "      6        \u001b[36m0.4906\u001b[0m       \u001b[32m0.8581\u001b[0m        \u001b[35m0.3911\u001b[0m  0.8619\n",
            "      7        \u001b[36m0.4707\u001b[0m       \u001b[32m0.8590\u001b[0m        \u001b[35m0.3866\u001b[0m  0.8906\n",
            "      8        \u001b[36m0.4558\u001b[0m       0.8576        \u001b[35m0.3850\u001b[0m  0.8730\n",
            "      9        \u001b[36m0.4421\u001b[0m       \u001b[32m0.8639\u001b[0m        \u001b[35m0.3769\u001b[0m  0.8411\n",
            "     10        \u001b[36m0.4310\u001b[0m       \u001b[32m0.8689\u001b[0m        \u001b[35m0.3639\u001b[0m  0.8387\n",
            "     11        \u001b[36m0.4252\u001b[0m       \u001b[32m0.8738\u001b[0m        \u001b[35m0.3533\u001b[0m  0.8485\n",
            "     12        \u001b[36m0.4154\u001b[0m       0.8642        0.3727  0.8601\n",
            "     13        \u001b[36m0.4075\u001b[0m       0.8678        0.3607  0.8441\n",
            "     14        \u001b[36m0.4002\u001b[0m       \u001b[32m0.8749\u001b[0m        \u001b[35m0.3495\u001b[0m  0.8607\n",
            "     15        \u001b[36m0.3932\u001b[0m       \u001b[32m0.8764\u001b[0m        \u001b[35m0.3453\u001b[0m  0.8624\n",
            "     16        \u001b[36m0.3845\u001b[0m       0.8714        0.3501  0.8562\n",
            "     17        \u001b[36m0.3807\u001b[0m       0.8741        \u001b[35m0.3435\u001b[0m  0.8547\n",
            "     18        \u001b[36m0.3734\u001b[0m       \u001b[32m0.8785\u001b[0m        \u001b[35m0.3416\u001b[0m  0.8550\n",
            "     19        \u001b[36m0.3731\u001b[0m       0.8772        \u001b[35m0.3355\u001b[0m  0.8522\n",
            "     20        \u001b[36m0.3644\u001b[0m       0.8699        0.3530  0.8690\n",
            "[CV] END lr=0.05, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=  17.6s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.2782\u001b[0m       \u001b[32m0.7348\u001b[0m        \u001b[35m0.7056\u001b[0m  0.8742\n",
            "      2        \u001b[36m0.7415\u001b[0m       \u001b[32m0.7711\u001b[0m        \u001b[35m0.6003\u001b[0m  0.8485\n",
            "      3        \u001b[36m0.6215\u001b[0m       \u001b[32m0.8075\u001b[0m        \u001b[35m0.4965\u001b[0m  0.8517\n",
            "      4        \u001b[36m0.5707\u001b[0m       \u001b[32m0.8297\u001b[0m        \u001b[35m0.4586\u001b[0m  0.8312\n",
            "      5        \u001b[36m0.5307\u001b[0m       \u001b[32m0.8389\u001b[0m        \u001b[35m0.4441\u001b[0m  0.8505\n",
            "      6        \u001b[36m0.5059\u001b[0m       \u001b[32m0.8425\u001b[0m        \u001b[35m0.4281\u001b[0m  0.8598\n",
            "      7        \u001b[36m0.4847\u001b[0m       \u001b[32m0.8492\u001b[0m        \u001b[35m0.4052\u001b[0m  0.8507\n",
            "      8        \u001b[36m0.4709\u001b[0m       0.8464        0.4074  0.8414\n",
            "      9        \u001b[36m0.4617\u001b[0m       \u001b[32m0.8582\u001b[0m        \u001b[35m0.3857\u001b[0m  0.8630\n",
            "     10        \u001b[36m0.4497\u001b[0m       0.8501        0.4030  0.8443\n",
            "     11        \u001b[36m0.4394\u001b[0m       0.8449        0.4102  0.8363\n",
            "     12        \u001b[36m0.4316\u001b[0m       \u001b[32m0.8650\u001b[0m        \u001b[35m0.3748\u001b[0m  0.8500\n",
            "     13        \u001b[36m0.4244\u001b[0m       0.8639        0.3795  0.8720\n",
            "     14        \u001b[36m0.4193\u001b[0m       0.8579        0.3835  0.8370\n",
            "     15        \u001b[36m0.4138\u001b[0m       0.8641        0.3786  0.8724\n",
            "     16        \u001b[36m0.4095\u001b[0m       \u001b[32m0.8732\u001b[0m        \u001b[35m0.3526\u001b[0m  0.8413\n",
            "     17        \u001b[36m0.4069\u001b[0m       0.8591        0.3777  0.8525\n",
            "     18        \u001b[36m0.3976\u001b[0m       0.8688        0.3641  0.8394\n",
            "     19        \u001b[36m0.3947\u001b[0m       0.8652        0.3679  0.8372\n",
            "     20        \u001b[36m0.3926\u001b[0m       0.8668        0.3611  0.8356\n",
            "[CV] END lr=0.05, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=  17.6s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.2866\u001b[0m       \u001b[32m0.7330\u001b[0m        \u001b[35m0.6966\u001b[0m  0.8557\n",
            "      2        \u001b[36m0.7363\u001b[0m       \u001b[32m0.7920\u001b[0m        \u001b[35m0.5426\u001b[0m  0.8346\n",
            "      3        \u001b[36m0.6200\u001b[0m       \u001b[32m0.8147\u001b[0m        \u001b[35m0.4996\u001b[0m  0.8436\n",
            "      4        \u001b[36m0.5593\u001b[0m       \u001b[32m0.8430\u001b[0m        \u001b[35m0.4371\u001b[0m  0.8547\n",
            "      5        \u001b[36m0.5292\u001b[0m       \u001b[32m0.8460\u001b[0m        \u001b[35m0.4283\u001b[0m  0.8576\n",
            "      6        \u001b[36m0.5073\u001b[0m       \u001b[32m0.8516\u001b[0m        \u001b[35m0.4079\u001b[0m  0.8418\n",
            "      7        \u001b[36m0.4887\u001b[0m       \u001b[32m0.8559\u001b[0m        \u001b[35m0.3998\u001b[0m  0.8633\n",
            "      8        \u001b[36m0.4695\u001b[0m       \u001b[32m0.8581\u001b[0m        \u001b[35m0.3918\u001b[0m  0.8767\n",
            "      9        \u001b[36m0.4611\u001b[0m       \u001b[32m0.8599\u001b[0m        \u001b[35m0.3806\u001b[0m  0.8649\n",
            "     10        \u001b[36m0.4449\u001b[0m       \u001b[32m0.8686\u001b[0m        \u001b[35m0.3644\u001b[0m  0.8523\n",
            "     11        \u001b[36m0.4370\u001b[0m       0.8538        0.3996  0.8355\n",
            "     12        \u001b[36m0.4305\u001b[0m       0.8602        0.3857  0.8379\n",
            "     13        \u001b[36m0.4265\u001b[0m       \u001b[32m0.8712\u001b[0m        \u001b[35m0.3577\u001b[0m  0.8342\n",
            "     14        \u001b[36m0.4115\u001b[0m       0.8655        0.3644  0.8441\n",
            "     15        0.4117       0.8704        0.3600  0.8412\n",
            "     16        \u001b[36m0.4078\u001b[0m       \u001b[32m0.8760\u001b[0m        \u001b[35m0.3475\u001b[0m  0.8238\n",
            "     17        \u001b[36m0.4000\u001b[0m       0.8746        0.3525  0.8486\n",
            "     18        \u001b[36m0.3999\u001b[0m       \u001b[32m0.8791\u001b[0m        \u001b[35m0.3447\u001b[0m  0.8450\n",
            "     19        \u001b[36m0.3950\u001b[0m       0.8738        0.3478  0.8238\n",
            "     20        \u001b[36m0.3903\u001b[0m       0.8739        0.3518  0.8320\n",
            "[CV] END lr=0.05, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=  17.5s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.3004\u001b[0m       \u001b[32m0.7315\u001b[0m        \u001b[35m0.6910\u001b[0m  0.8520\n",
            "      2        \u001b[36m0.7253\u001b[0m       \u001b[32m0.8083\u001b[0m        \u001b[35m0.5356\u001b[0m  0.8633\n",
            "      3        \u001b[36m0.6122\u001b[0m       \u001b[32m0.8180\u001b[0m        \u001b[35m0.4847\u001b[0m  0.8738\n",
            "      4        \u001b[36m0.5565\u001b[0m       \u001b[32m0.8441\u001b[0m        \u001b[35m0.4347\u001b[0m  0.8637\n",
            "      5        \u001b[36m0.5200\u001b[0m       \u001b[32m0.8445\u001b[0m        \u001b[35m0.4251\u001b[0m  0.8492\n",
            "      6        \u001b[36m0.4954\u001b[0m       \u001b[32m0.8560\u001b[0m        \u001b[35m0.4045\u001b[0m  0.8522\n",
            "      7        \u001b[36m0.4822\u001b[0m       0.8488        0.4084  0.8589\n",
            "      8        \u001b[36m0.4664\u001b[0m       \u001b[32m0.8564\u001b[0m        \u001b[35m0.3943\u001b[0m  0.8434\n",
            "      9        \u001b[36m0.4566\u001b[0m       \u001b[32m0.8576\u001b[0m        \u001b[35m0.3880\u001b[0m  0.8413\n",
            "     10        \u001b[36m0.4452\u001b[0m       \u001b[32m0.8642\u001b[0m        \u001b[35m0.3695\u001b[0m  0.8575\n",
            "     11        \u001b[36m0.4370\u001b[0m       \u001b[32m0.8708\u001b[0m        \u001b[35m0.3625\u001b[0m  0.8569\n",
            "     12        \u001b[36m0.4274\u001b[0m       0.8652        0.3740  0.8412\n",
            "     13        \u001b[36m0.4209\u001b[0m       0.8700        \u001b[35m0.3573\u001b[0m  0.8474\n",
            "     14        \u001b[36m0.4146\u001b[0m       0.8682        0.3595  0.8427\n",
            "     15        \u001b[36m0.4140\u001b[0m       0.8705        \u001b[35m0.3551\u001b[0m  0.8449\n",
            "     16        \u001b[36m0.4019\u001b[0m       \u001b[32m0.8720\u001b[0m        \u001b[35m0.3490\u001b[0m  0.8637\n",
            "     17        \u001b[36m0.3999\u001b[0m       0.8705        0.3525  0.8538\n",
            "     18        \u001b[36m0.3954\u001b[0m       0.8669        0.3607  0.8423\n",
            "     19        \u001b[36m0.3954\u001b[0m       \u001b[32m0.8736\u001b[0m        \u001b[35m0.3456\u001b[0m  0.8410\n",
            "     20        \u001b[36m0.3888\u001b[0m       \u001b[32m0.8804\u001b[0m        \u001b[35m0.3389\u001b[0m  0.8299\n",
            "[CV] END lr=0.05, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=  17.6s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0583\u001b[0m       \u001b[32m0.7725\u001b[0m        \u001b[35m0.5786\u001b[0m  0.8452\n",
            "      2        \u001b[36m0.6653\u001b[0m       \u001b[32m0.7886\u001b[0m        \u001b[35m0.5395\u001b[0m  0.8409\n",
            "      3        \u001b[36m0.6148\u001b[0m       \u001b[32m0.8227\u001b[0m        \u001b[35m0.4714\u001b[0m  0.8469\n",
            "      4        \u001b[36m0.5877\u001b[0m       0.8227        0.4715  0.8274\n",
            "      5        \u001b[36m0.5723\u001b[0m       \u001b[32m0.8271\u001b[0m        \u001b[35m0.4647\u001b[0m  0.8413\n",
            "      6        \u001b[36m0.5562\u001b[0m       \u001b[32m0.8364\u001b[0m        \u001b[35m0.4385\u001b[0m  0.8454\n",
            "      7        \u001b[36m0.5455\u001b[0m       \u001b[32m0.8377\u001b[0m        0.4401  0.8503\n",
            "      8        \u001b[36m0.5232\u001b[0m       \u001b[32m0.8384\u001b[0m        \u001b[35m0.4229\u001b[0m  0.8611\n",
            "      9        \u001b[36m0.5147\u001b[0m       0.8370        0.4311  0.8798\n",
            "     10        \u001b[36m0.5060\u001b[0m       \u001b[32m0.8427\u001b[0m        \u001b[35m0.4184\u001b[0m  0.8494\n",
            "     11        \u001b[36m0.4957\u001b[0m       \u001b[32m0.8518\u001b[0m        \u001b[35m0.3991\u001b[0m  0.8539\n",
            "     12        \u001b[36m0.4847\u001b[0m       0.8478        0.4023  0.8419\n",
            "     13        \u001b[36m0.4748\u001b[0m       \u001b[32m0.8541\u001b[0m        \u001b[35m0.3984\u001b[0m  0.8369\n",
            "     14        \u001b[36m0.4638\u001b[0m       0.8499        \u001b[35m0.3935\u001b[0m  0.8405\n",
            "     15        \u001b[36m0.4614\u001b[0m       0.8476        0.3972  0.8472\n",
            "     16        \u001b[36m0.4578\u001b[0m       \u001b[32m0.8596\u001b[0m        \u001b[35m0.3841\u001b[0m  0.8440\n",
            "     17        \u001b[36m0.4533\u001b[0m       0.8492        0.4014  0.8473\n",
            "     18        \u001b[36m0.4496\u001b[0m       0.8541        0.3880  0.8533\n",
            "     19        \u001b[36m0.4439\u001b[0m       0.8580        0.3899  0.8426\n",
            "     20        \u001b[36m0.4397\u001b[0m       \u001b[32m0.8609\u001b[0m        0.3870  0.8465\n",
            "[CV] END lr=0.05, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=  17.5s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0954\u001b[0m       \u001b[32m0.7855\u001b[0m        \u001b[35m0.5750\u001b[0m  0.8726\n",
            "      2        \u001b[36m0.6679\u001b[0m       0.7770        \u001b[35m0.5442\u001b[0m  0.8514\n",
            "      3        \u001b[36m0.6073\u001b[0m       \u001b[32m0.8257\u001b[0m        \u001b[35m0.4688\u001b[0m  0.8834\n",
            "      4        \u001b[36m0.5775\u001b[0m       0.8180        0.4784  0.8433\n",
            "      5        \u001b[36m0.5572\u001b[0m       \u001b[32m0.8455\u001b[0m        \u001b[35m0.4346\u001b[0m  0.8357\n",
            "      6        \u001b[36m0.5431\u001b[0m       \u001b[32m0.8470\u001b[0m        \u001b[35m0.4285\u001b[0m  0.8455\n",
            "      7        \u001b[36m0.5231\u001b[0m       0.8465        \u001b[35m0.4264\u001b[0m  0.8325\n",
            "      8        \u001b[36m0.5225\u001b[0m       \u001b[32m0.8514\u001b[0m        \u001b[35m0.4193\u001b[0m  0.8497\n",
            "      9        \u001b[36m0.5111\u001b[0m       0.8506        \u001b[35m0.4185\u001b[0m  0.8457\n",
            "     10        \u001b[36m0.5098\u001b[0m       \u001b[32m0.8534\u001b[0m        \u001b[35m0.4125\u001b[0m  0.8293\n",
            "     11        \u001b[36m0.4883\u001b[0m       0.8440        0.4195  0.8558\n",
            "     12        \u001b[36m0.4824\u001b[0m       \u001b[32m0.8592\u001b[0m        \u001b[35m0.3961\u001b[0m  0.8493\n",
            "     13        \u001b[36m0.4789\u001b[0m       \u001b[32m0.8602\u001b[0m        0.4056  0.8521\n",
            "     14        \u001b[36m0.4668\u001b[0m       0.8511        \u001b[35m0.3953\u001b[0m  0.8413\n",
            "     15        \u001b[36m0.4585\u001b[0m       0.8599        \u001b[35m0.3817\u001b[0m  0.8516\n",
            "     16        \u001b[36m0.4585\u001b[0m       0.8595        0.3915  0.8666\n",
            "     17        \u001b[36m0.4502\u001b[0m       \u001b[32m0.8664\u001b[0m        \u001b[35m0.3757\u001b[0m  0.8676\n",
            "     18        \u001b[36m0.4490\u001b[0m       0.8650        0.3791  0.8428\n",
            "     19        \u001b[36m0.4444\u001b[0m       0.8640        0.3920  0.8258\n",
            "     20        \u001b[36m0.4296\u001b[0m       0.8662        \u001b[35m0.3745\u001b[0m  0.8290\n",
            "[CV] END lr=0.05, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=  17.6s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0904\u001b[0m       \u001b[32m0.7725\u001b[0m        \u001b[35m0.5881\u001b[0m  0.8705\n",
            "      2        \u001b[36m0.6603\u001b[0m       \u001b[32m0.8160\u001b[0m        \u001b[35m0.5022\u001b[0m  0.8363\n",
            "      3        \u001b[36m0.5981\u001b[0m       \u001b[32m0.8334\u001b[0m        \u001b[35m0.4654\u001b[0m  0.8330\n",
            "      4        \u001b[36m0.5750\u001b[0m       \u001b[32m0.8420\u001b[0m        \u001b[35m0.4445\u001b[0m  0.8280\n",
            "      5        \u001b[36m0.5535\u001b[0m       0.8203        0.4720  0.8232\n",
            "      6        \u001b[36m0.5393\u001b[0m       \u001b[32m0.8525\u001b[0m        \u001b[35m0.4153\u001b[0m  0.8351\n",
            "      7        \u001b[36m0.5312\u001b[0m       0.8481        \u001b[35m0.4145\u001b[0m  0.8528\n",
            "      8        \u001b[36m0.5147\u001b[0m       \u001b[32m0.8538\u001b[0m        \u001b[35m0.4076\u001b[0m  0.8564\n",
            "      9        \u001b[36m0.4971\u001b[0m       \u001b[32m0.8574\u001b[0m        \u001b[35m0.3977\u001b[0m  0.8655\n",
            "     10        \u001b[36m0.4920\u001b[0m       0.8561        0.4100  0.8928\n",
            "     11        0.4942       0.8549        \u001b[35m0.3937\u001b[0m  0.8422\n",
            "     12        \u001b[36m0.4853\u001b[0m       0.8562        0.3963  0.8528\n",
            "     13        \u001b[36m0.4723\u001b[0m       0.8558        \u001b[35m0.3787\u001b[0m  0.8487\n",
            "     14        \u001b[36m0.4568\u001b[0m       \u001b[32m0.8576\u001b[0m        0.3946  0.8585\n",
            "     15        \u001b[36m0.4568\u001b[0m       \u001b[32m0.8688\u001b[0m        \u001b[35m0.3711\u001b[0m  0.8427\n",
            "     16        \u001b[36m0.4533\u001b[0m       0.8632        0.3755  0.8454\n",
            "     17        \u001b[36m0.4491\u001b[0m       0.8615        0.3810  0.8512\n",
            "     18        \u001b[36m0.4429\u001b[0m       0.8574        0.3788  0.8471\n",
            "     19        \u001b[36m0.4400\u001b[0m       0.8650        0.3901  0.8334\n",
            "     20        \u001b[36m0.4381\u001b[0m       0.8604        0.3845  0.8448\n",
            "[CV] END lr=0.05, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=  17.5s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0805\u001b[0m       \u001b[32m0.7709\u001b[0m        \u001b[35m0.5904\u001b[0m  0.8403\n",
            "      2        \u001b[36m0.6800\u001b[0m       \u001b[32m0.7967\u001b[0m        \u001b[35m0.5292\u001b[0m  0.8550\n",
            "      3        \u001b[36m0.6066\u001b[0m       \u001b[32m0.8257\u001b[0m        \u001b[35m0.4695\u001b[0m  0.8659\n",
            "      4        \u001b[36m0.5868\u001b[0m       0.8241        \u001b[35m0.4660\u001b[0m  0.8474\n",
            "      5        \u001b[36m0.5806\u001b[0m       0.8213        0.4743  0.8645\n",
            "      6        \u001b[36m0.5503\u001b[0m       \u001b[32m0.8314\u001b[0m        \u001b[35m0.4498\u001b[0m  0.8496\n",
            "      7        0.5601       0.8295        0.4584  0.8545\n",
            "      8        \u001b[36m0.5437\u001b[0m       0.8294        0.4540  0.8394\n",
            "      9        0.5466       0.8256        0.4625  0.8428\n",
            "     10        \u001b[36m0.5380\u001b[0m       0.8293        \u001b[35m0.4450\u001b[0m  0.8313\n",
            "     11        0.5403       \u001b[32m0.8356\u001b[0m        \u001b[35m0.4399\u001b[0m  0.8350\n",
            "     12        \u001b[36m0.5370\u001b[0m       \u001b[32m0.8429\u001b[0m        \u001b[35m0.4329\u001b[0m  0.8271\n",
            "     13        \u001b[36m0.5310\u001b[0m       0.8383        \u001b[35m0.4263\u001b[0m  0.8300\n",
            "     14        \u001b[36m0.5167\u001b[0m       0.8417        0.4518  0.8379\n",
            "     15        0.5316       0.8354        0.4375  0.8254\n",
            "     16        0.5302       0.8405        0.4492  0.8531\n",
            "     17        0.5405       0.8171        0.4653  0.8464\n",
            "     18        0.5320       \u001b[32m0.8451\u001b[0m        \u001b[35m0.4194\u001b[0m  0.8655\n",
            "     19        0.5321       0.8329        0.4393  0.8515\n",
            "     20        0.5286       0.8433        0.4210  0.8441\n",
            "[CV] END lr=0.05, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=  17.5s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0696\u001b[0m       \u001b[32m0.7937\u001b[0m        \u001b[35m0.5742\u001b[0m  0.8387\n",
            "      2        \u001b[36m0.6571\u001b[0m       \u001b[32m0.8120\u001b[0m        \u001b[35m0.5075\u001b[0m  0.8427\n",
            "      3        \u001b[36m0.6124\u001b[0m       \u001b[32m0.8177\u001b[0m        \u001b[35m0.4936\u001b[0m  0.8376\n",
            "      4        \u001b[36m0.5802\u001b[0m       \u001b[32m0.8193\u001b[0m        \u001b[35m0.4721\u001b[0m  0.8575\n",
            "      5        \u001b[36m0.5656\u001b[0m       \u001b[32m0.8336\u001b[0m        \u001b[35m0.4557\u001b[0m  0.8685\n",
            "      6        \u001b[36m0.5615\u001b[0m       \u001b[32m0.8393\u001b[0m        \u001b[35m0.4398\u001b[0m  0.8912\n",
            "      7        \u001b[36m0.5573\u001b[0m       \u001b[32m0.8444\u001b[0m        \u001b[35m0.4327\u001b[0m  0.8572\n",
            "      8        \u001b[36m0.5505\u001b[0m       0.8413        0.4511  0.8668\n",
            "      9        \u001b[36m0.5350\u001b[0m       \u001b[32m0.8451\u001b[0m        0.4389  0.8550\n",
            "     10        0.5495       0.8360        0.4433  0.8401\n",
            "     11        0.5370       \u001b[32m0.8460\u001b[0m        \u001b[35m0.4154\u001b[0m  0.8672\n",
            "     12        \u001b[36m0.5289\u001b[0m       \u001b[32m0.8495\u001b[0m        \u001b[35m0.4097\u001b[0m  0.8747\n",
            "     13        0.5343       \u001b[32m0.8496\u001b[0m        0.4236  0.8525\n",
            "     14        0.5382       0.8441        0.4307  0.8477\n",
            "     15        \u001b[36m0.5278\u001b[0m       \u001b[32m0.8538\u001b[0m        \u001b[35m0.4076\u001b[0m  0.8464\n",
            "     16        0.5372       0.8407        0.4335  0.8608\n",
            "     17        \u001b[36m0.5195\u001b[0m       0.8508        0.4205  0.8454\n",
            "     18        0.5348       0.8459        0.4198  0.8471\n",
            "     19        0.5316       0.8510        0.4108  0.8461\n",
            "     20        0.5298       0.8416        0.4283  0.8581\n",
            "[CV] END lr=0.05, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=  17.7s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0945\u001b[0m       \u001b[32m0.7881\u001b[0m        \u001b[35m0.5531\u001b[0m  0.8384\n",
            "      2        \u001b[36m0.6597\u001b[0m       \u001b[32m0.8065\u001b[0m        \u001b[35m0.5191\u001b[0m  0.8464\n",
            "      3        \u001b[36m0.6061\u001b[0m       \u001b[32m0.8320\u001b[0m        \u001b[35m0.4916\u001b[0m  0.8618\n",
            "      4        \u001b[36m0.5875\u001b[0m       0.8195        \u001b[35m0.4794\u001b[0m  0.8775\n",
            "      5        \u001b[36m0.5641\u001b[0m       \u001b[32m0.8365\u001b[0m        \u001b[35m0.4470\u001b[0m  0.8490\n",
            "      6        \u001b[36m0.5508\u001b[0m       \u001b[32m0.8499\u001b[0m        \u001b[35m0.4182\u001b[0m  0.8361\n",
            "      7        \u001b[36m0.5408\u001b[0m       0.8458        0.4236  0.8322\n",
            "      8        0.5500       0.8399        0.4379  0.8465\n",
            "      9        \u001b[36m0.5307\u001b[0m       \u001b[32m0.8512\u001b[0m        \u001b[35m0.4048\u001b[0m  0.8361\n",
            "     10        0.5320       0.8407        0.4266  0.8318\n",
            "     11        \u001b[36m0.5296\u001b[0m       \u001b[32m0.8532\u001b[0m        \u001b[35m0.4032\u001b[0m  0.8436\n",
            "     12        \u001b[36m0.5281\u001b[0m       0.8498        0.4059  0.8374\n",
            "     13        \u001b[36m0.5265\u001b[0m       0.8502        0.4171  0.8226\n",
            "     14        0.5280       0.8458        0.4096  0.8400\n",
            "     15        \u001b[36m0.5228\u001b[0m       0.8479        0.4282  0.8333\n",
            "     16        \u001b[36m0.5184\u001b[0m       \u001b[32m0.8588\u001b[0m        \u001b[35m0.4007\u001b[0m  0.8446\n",
            "     17        \u001b[36m0.5075\u001b[0m       0.8472        0.4040  0.8619\n",
            "     18        0.5193       0.8420        0.4273  0.8620\n",
            "     19        \u001b[36m0.5050\u001b[0m       0.8464        0.4301  0.8538\n",
            "     20        0.5267       0.8518        0.4084  0.8436\n",
            "[CV] END lr=0.05, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=  17.5s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.3986\u001b[0m       \u001b[32m0.7130\u001b[0m        \u001b[35m0.7422\u001b[0m  0.8551\n",
            "      2        \u001b[36m0.8122\u001b[0m       \u001b[32m0.7484\u001b[0m        \u001b[35m0.6178\u001b[0m  0.8549\n",
            "      3        \u001b[36m0.7064\u001b[0m       \u001b[32m0.7957\u001b[0m        \u001b[35m0.5555\u001b[0m  0.8424\n",
            "      4        \u001b[36m0.6402\u001b[0m       \u001b[32m0.7981\u001b[0m        \u001b[35m0.5064\u001b[0m  0.8307\n",
            "      5        \u001b[36m0.6063\u001b[0m       \u001b[32m0.8134\u001b[0m        \u001b[35m0.4829\u001b[0m  0.8325\n",
            "      6        \u001b[36m0.5739\u001b[0m       \u001b[32m0.8254\u001b[0m        \u001b[35m0.4651\u001b[0m  0.8396\n",
            "      7        \u001b[36m0.5512\u001b[0m       \u001b[32m0.8354\u001b[0m        \u001b[35m0.4402\u001b[0m  0.8422\n",
            "      8        \u001b[36m0.5354\u001b[0m       \u001b[32m0.8407\u001b[0m        \u001b[35m0.4329\u001b[0m  0.8396\n",
            "      9        \u001b[36m0.5136\u001b[0m       \u001b[32m0.8429\u001b[0m        \u001b[35m0.4109\u001b[0m  0.8670\n",
            "     10        \u001b[36m0.4948\u001b[0m       0.8407        0.4237  0.8642\n",
            "     11        \u001b[36m0.4905\u001b[0m       \u001b[32m0.8474\u001b[0m        \u001b[35m0.3991\u001b[0m  0.8551\n",
            "     12        \u001b[36m0.4788\u001b[0m       \u001b[32m0.8568\u001b[0m        \u001b[35m0.3981\u001b[0m  0.8729\n",
            "     13        \u001b[36m0.4687\u001b[0m       0.8522        \u001b[35m0.3967\u001b[0m  0.8635\n",
            "     14        \u001b[36m0.4589\u001b[0m       \u001b[32m0.8619\u001b[0m        \u001b[35m0.3771\u001b[0m  0.8668\n",
            "     15        \u001b[36m0.4478\u001b[0m       0.8616        \u001b[35m0.3759\u001b[0m  0.8757\n",
            "     16        0.4490       \u001b[32m0.8624\u001b[0m        0.3778  0.8527\n",
            "     17        \u001b[36m0.4398\u001b[0m       0.8594        0.3759  0.8412\n",
            "     18        \u001b[36m0.4334\u001b[0m       0.8614        0.3759  0.8372\n",
            "     19        \u001b[36m0.4272\u001b[0m       \u001b[32m0.8678\u001b[0m        \u001b[35m0.3532\u001b[0m  0.8345\n",
            "     20        \u001b[36m0.4226\u001b[0m       0.8668        0.3656  0.8369\n",
            "[CV] END lr=0.05, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=  17.6s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.4034\u001b[0m       \u001b[32m0.6809\u001b[0m        \u001b[35m0.7335\u001b[0m  0.8409\n",
            "      2        \u001b[36m0.8027\u001b[0m       \u001b[32m0.7698\u001b[0m        \u001b[35m0.5935\u001b[0m  0.8578\n",
            "      3        \u001b[36m0.6908\u001b[0m       \u001b[32m0.8120\u001b[0m        \u001b[35m0.5111\u001b[0m  0.8674\n",
            "      4        \u001b[36m0.6343\u001b[0m       \u001b[32m0.8290\u001b[0m        \u001b[35m0.4648\u001b[0m  0.8523\n",
            "      5        \u001b[36m0.5900\u001b[0m       \u001b[32m0.8413\u001b[0m        \u001b[35m0.4413\u001b[0m  0.8598\n",
            "      6        \u001b[36m0.5650\u001b[0m       0.8407        \u001b[35m0.4273\u001b[0m  0.8493\n",
            "      7        \u001b[36m0.5426\u001b[0m       \u001b[32m0.8518\u001b[0m        \u001b[35m0.4063\u001b[0m  0.8546\n",
            "      8        \u001b[36m0.5269\u001b[0m       0.8504        0.4071  0.8527\n",
            "      9        \u001b[36m0.5057\u001b[0m       \u001b[32m0.8574\u001b[0m        \u001b[35m0.3903\u001b[0m  0.8468\n",
            "     10        \u001b[36m0.4861\u001b[0m       \u001b[32m0.8579\u001b[0m        \u001b[35m0.3884\u001b[0m  0.8493\n",
            "     11        \u001b[36m0.4819\u001b[0m       \u001b[32m0.8592\u001b[0m        0.3895  0.8427\n",
            "     12        \u001b[36m0.4729\u001b[0m       \u001b[32m0.8604\u001b[0m        \u001b[35m0.3739\u001b[0m  0.8482\n",
            "     13        \u001b[36m0.4623\u001b[0m       0.8581        0.3836  0.8515\n",
            "     14        \u001b[36m0.4557\u001b[0m       \u001b[32m0.8680\u001b[0m        \u001b[35m0.3656\u001b[0m  0.8560\n",
            "     15        \u001b[36m0.4478\u001b[0m       \u001b[32m0.8681\u001b[0m        0.3720  0.8731\n",
            "     16        \u001b[36m0.4433\u001b[0m       0.8671        0.3671  0.8802\n",
            "     17        \u001b[36m0.4354\u001b[0m       \u001b[32m0.8705\u001b[0m        \u001b[35m0.3559\u001b[0m  0.8716\n",
            "     18        \u001b[36m0.4285\u001b[0m       \u001b[32m0.8725\u001b[0m        \u001b[35m0.3551\u001b[0m  0.8540\n",
            "     19        \u001b[36m0.4261\u001b[0m       \u001b[32m0.8758\u001b[0m        \u001b[35m0.3481\u001b[0m  0.8579\n",
            "     20        \u001b[36m0.4232\u001b[0m       \u001b[32m0.8766\u001b[0m        \u001b[35m0.3441\u001b[0m  0.8565\n",
            "[CV] END lr=0.05, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=  17.7s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.4085\u001b[0m       \u001b[32m0.6840\u001b[0m        \u001b[35m0.7523\u001b[0m  0.8433\n",
            "      2        \u001b[36m0.8114\u001b[0m       \u001b[32m0.7891\u001b[0m        \u001b[35m0.5883\u001b[0m  0.8583\n",
            "      3        \u001b[36m0.6959\u001b[0m       \u001b[32m0.8201\u001b[0m        \u001b[35m0.5196\u001b[0m  0.8576\n",
            "      4        \u001b[36m0.6287\u001b[0m       \u001b[32m0.8296\u001b[0m        \u001b[35m0.4871\u001b[0m  0.8390\n",
            "      5        \u001b[36m0.5931\u001b[0m       \u001b[32m0.8404\u001b[0m        \u001b[35m0.4468\u001b[0m  0.8348\n",
            "      6        \u001b[36m0.5593\u001b[0m       \u001b[32m0.8439\u001b[0m        \u001b[35m0.4380\u001b[0m  0.8399\n",
            "      7        \u001b[36m0.5391\u001b[0m       0.8436        \u001b[35m0.4258\u001b[0m  0.8508\n",
            "      8        \u001b[36m0.5210\u001b[0m       \u001b[32m0.8494\u001b[0m        \u001b[35m0.4145\u001b[0m  0.8632\n",
            "      9        \u001b[36m0.5014\u001b[0m       \u001b[32m0.8595\u001b[0m        \u001b[35m0.3944\u001b[0m  0.8359\n",
            "     10        \u001b[36m0.4848\u001b[0m       0.8531        \u001b[35m0.3913\u001b[0m  0.8546\n",
            "     11        \u001b[36m0.4811\u001b[0m       \u001b[32m0.8598\u001b[0m        0.3938  0.8580\n",
            "     12        \u001b[36m0.4661\u001b[0m       \u001b[32m0.8629\u001b[0m        \u001b[35m0.3802\u001b[0m  0.8648\n",
            "     13        \u001b[36m0.4587\u001b[0m       0.8590        0.3869  0.8491\n",
            "     14        \u001b[36m0.4576\u001b[0m       \u001b[32m0.8672\u001b[0m        \u001b[35m0.3683\u001b[0m  0.8530\n",
            "     15        \u001b[36m0.4480\u001b[0m       0.8651        \u001b[35m0.3666\u001b[0m  0.8445\n",
            "     16        \u001b[36m0.4419\u001b[0m       \u001b[32m0.8690\u001b[0m        \u001b[35m0.3526\u001b[0m  0.8440\n",
            "     17        \u001b[36m0.4368\u001b[0m       \u001b[32m0.8696\u001b[0m        0.3593  0.8517\n",
            "     18        \u001b[36m0.4297\u001b[0m       \u001b[32m0.8701\u001b[0m        0.3584  0.8453\n",
            "     19        \u001b[36m0.4261\u001b[0m       0.8610        0.3721  0.8427\n",
            "     20        \u001b[36m0.4184\u001b[0m       \u001b[32m0.8731\u001b[0m        \u001b[35m0.3484\u001b[0m  0.8549\n",
            "[CV] END lr=0.05, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=  17.6s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.4301\u001b[0m       \u001b[32m0.6813\u001b[0m        \u001b[35m0.7709\u001b[0m  0.8461\n",
            "      2        \u001b[36m0.8182\u001b[0m       \u001b[32m0.7540\u001b[0m        \u001b[35m0.6203\u001b[0m  0.8371\n",
            "      3        \u001b[36m0.6997\u001b[0m       \u001b[32m0.7666\u001b[0m        \u001b[35m0.5608\u001b[0m  0.8332\n",
            "      4        \u001b[36m0.6316\u001b[0m       \u001b[32m0.8187\u001b[0m        \u001b[35m0.4850\u001b[0m  0.8545\n",
            "      5        \u001b[36m0.6004\u001b[0m       \u001b[32m0.8249\u001b[0m        \u001b[35m0.4636\u001b[0m  0.8681\n",
            "      6        \u001b[36m0.5656\u001b[0m       \u001b[32m0.8304\u001b[0m        \u001b[35m0.4437\u001b[0m  0.8570\n",
            "      7        \u001b[36m0.5516\u001b[0m       \u001b[32m0.8414\u001b[0m        \u001b[35m0.4238\u001b[0m  0.8531\n",
            "      8        \u001b[36m0.5251\u001b[0m       0.8375        0.4375  0.8366\n",
            "      9        \u001b[36m0.5100\u001b[0m       \u001b[32m0.8471\u001b[0m        \u001b[35m0.4165\u001b[0m  0.8346\n",
            "     10        \u001b[36m0.5005\u001b[0m       \u001b[32m0.8495\u001b[0m        \u001b[35m0.4013\u001b[0m  0.8279\n",
            "     11        \u001b[36m0.4901\u001b[0m       \u001b[32m0.8502\u001b[0m        \u001b[35m0.3983\u001b[0m  0.8582\n",
            "     12        \u001b[36m0.4812\u001b[0m       \u001b[32m0.8531\u001b[0m        \u001b[35m0.3924\u001b[0m  0.8415\n",
            "     13        \u001b[36m0.4747\u001b[0m       \u001b[32m0.8572\u001b[0m        \u001b[35m0.3841\u001b[0m  0.8434\n",
            "     14        \u001b[36m0.4672\u001b[0m       0.8501        0.3937  0.8442\n",
            "     15        \u001b[36m0.4610\u001b[0m       0.8571        0.3901  0.8396\n",
            "     16        \u001b[36m0.4582\u001b[0m       0.8542        0.3924  0.8380\n",
            "     17        \u001b[36m0.4482\u001b[0m       \u001b[32m0.8672\u001b[0m        \u001b[35m0.3761\u001b[0m  0.8403\n",
            "     18        \u001b[36m0.4458\u001b[0m       0.8631        0.3782  0.8684\n",
            "     19        \u001b[36m0.4370\u001b[0m       0.8575        0.3821  0.8813\n",
            "     20        \u001b[36m0.4367\u001b[0m       0.8589        \u001b[35m0.3758\u001b[0m  0.8506\n",
            "[CV] END lr=0.05, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=  17.5s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.3538\u001b[0m       \u001b[32m0.6905\u001b[0m        \u001b[35m0.7331\u001b[0m  0.8524\n",
            "      2        \u001b[36m0.8029\u001b[0m       \u001b[32m0.7778\u001b[0m        \u001b[35m0.5939\u001b[0m  0.8363\n",
            "      3        \u001b[36m0.6927\u001b[0m       \u001b[32m0.8193\u001b[0m        \u001b[35m0.5168\u001b[0m  0.8493\n",
            "      4        \u001b[36m0.6378\u001b[0m       \u001b[32m0.8246\u001b[0m        \u001b[35m0.4784\u001b[0m  0.8462\n",
            "      5        \u001b[36m0.5926\u001b[0m       \u001b[32m0.8356\u001b[0m        \u001b[35m0.4513\u001b[0m  0.8570\n",
            "      6        \u001b[36m0.5689\u001b[0m       \u001b[32m0.8391\u001b[0m        \u001b[35m0.4372\u001b[0m  0.8836\n",
            "      7        \u001b[36m0.5491\u001b[0m       \u001b[32m0.8502\u001b[0m        \u001b[35m0.4168\u001b[0m  0.8471\n",
            "      8        \u001b[36m0.5317\u001b[0m       \u001b[32m0.8546\u001b[0m        \u001b[35m0.4038\u001b[0m  0.8463\n",
            "      9        \u001b[36m0.5094\u001b[0m       0.8515        \u001b[35m0.4014\u001b[0m  0.8507\n",
            "     10        \u001b[36m0.5008\u001b[0m       \u001b[32m0.8556\u001b[0m        0.4027  0.8466\n",
            "     11        \u001b[36m0.4912\u001b[0m       \u001b[32m0.8611\u001b[0m        \u001b[35m0.3805\u001b[0m  0.8570\n",
            "     12        \u001b[36m0.4861\u001b[0m       \u001b[32m0.8628\u001b[0m        0.3851  0.8587\n",
            "     13        \u001b[36m0.4702\u001b[0m       \u001b[32m0.8664\u001b[0m        \u001b[35m0.3743\u001b[0m  0.8917\n",
            "     14        0.4712       0.8625        \u001b[35m0.3683\u001b[0m  0.8430\n",
            "     15        \u001b[36m0.4616\u001b[0m       \u001b[32m0.8698\u001b[0m        \u001b[35m0.3646\u001b[0m  0.8461\n",
            "     16        \u001b[36m0.4596\u001b[0m       0.8671        0.3709  0.8385\n",
            "     17        \u001b[36m0.4525\u001b[0m       0.8608        0.3781  0.8437\n",
            "     18        \u001b[36m0.4472\u001b[0m       0.8662        \u001b[35m0.3624\u001b[0m  0.8438\n",
            "     19        \u001b[36m0.4434\u001b[0m       \u001b[32m0.8701\u001b[0m        0.3669  0.8549\n",
            "     20        \u001b[36m0.4394\u001b[0m       \u001b[32m0.8719\u001b[0m        \u001b[35m0.3568\u001b[0m  0.8341\n",
            "[CV] END lr=0.05, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=  17.6s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.4203\u001b[0m       \u001b[32m0.6935\u001b[0m        \u001b[35m0.7841\u001b[0m  0.8532\n",
            "      2        \u001b[36m0.8189\u001b[0m       \u001b[32m0.7594\u001b[0m        \u001b[35m0.6089\u001b[0m  0.8489\n",
            "      3        \u001b[36m0.6947\u001b[0m       \u001b[32m0.8141\u001b[0m        \u001b[35m0.5184\u001b[0m  0.8317\n",
            "      4        \u001b[36m0.6302\u001b[0m       \u001b[32m0.8319\u001b[0m        \u001b[35m0.4644\u001b[0m  0.8412\n",
            "      5        \u001b[36m0.5884\u001b[0m       \u001b[32m0.8333\u001b[0m        0.4649  0.8820\n",
            "      6        \u001b[36m0.5562\u001b[0m       \u001b[32m0.8397\u001b[0m        \u001b[35m0.4389\u001b[0m  0.8964\n",
            "      7        \u001b[36m0.5334\u001b[0m       0.8397        0.4399  0.8467\n",
            "      8        \u001b[36m0.5272\u001b[0m       \u001b[32m0.8478\u001b[0m        \u001b[35m0.4159\u001b[0m  0.8460\n",
            "      9        \u001b[36m0.5123\u001b[0m       \u001b[32m0.8551\u001b[0m        \u001b[35m0.4135\u001b[0m  0.8446\n",
            "     10        \u001b[36m0.4981\u001b[0m       \u001b[32m0.8602\u001b[0m        \u001b[35m0.3873\u001b[0m  0.8437\n",
            "     11        \u001b[36m0.4870\u001b[0m       0.8525        0.4116  0.8651\n",
            "     12        \u001b[36m0.4765\u001b[0m       \u001b[32m0.8629\u001b[0m        \u001b[35m0.3835\u001b[0m  0.8569\n",
            "     13        \u001b[36m0.4728\u001b[0m       \u001b[32m0.8654\u001b[0m        \u001b[35m0.3736\u001b[0m  0.8333\n",
            "     14        \u001b[36m0.4646\u001b[0m       0.8636        \u001b[35m0.3727\u001b[0m  0.8413\n",
            "     15        \u001b[36m0.4606\u001b[0m       \u001b[32m0.8658\u001b[0m        \u001b[35m0.3697\u001b[0m  0.8434\n",
            "     16        \u001b[36m0.4585\u001b[0m       \u001b[32m0.8668\u001b[0m        0.3730  0.8425\n",
            "     17        \u001b[36m0.4506\u001b[0m       \u001b[32m0.8689\u001b[0m        0.3698  0.8350\n",
            "     18        \u001b[36m0.4465\u001b[0m       0.8675        \u001b[35m0.3604\u001b[0m  0.8645\n",
            "     19        \u001b[36m0.4411\u001b[0m       0.8660        0.3659  0.8489\n",
            "     20        \u001b[36m0.4395\u001b[0m       0.8642        0.3688  0.8503\n",
            "[CV] END lr=0.05, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=  17.6s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1709\u001b[0m       \u001b[32m0.7312\u001b[0m        \u001b[35m0.6484\u001b[0m  0.8503\n",
            "      2        \u001b[36m0.7754\u001b[0m       \u001b[32m0.7766\u001b[0m        \u001b[35m0.5736\u001b[0m  0.8443\n",
            "      3        \u001b[36m0.7323\u001b[0m       \u001b[32m0.7905\u001b[0m        \u001b[35m0.5496\u001b[0m  0.8342\n",
            "      4        \u001b[36m0.7002\u001b[0m       \u001b[32m0.7989\u001b[0m        \u001b[35m0.5278\u001b[0m  0.8561\n",
            "      5        \u001b[36m0.6833\u001b[0m       \u001b[32m0.7990\u001b[0m        0.5389  0.8365\n",
            "      6        \u001b[36m0.6756\u001b[0m       0.7924        0.5286  0.8388\n",
            "      7        \u001b[36m0.6574\u001b[0m       \u001b[32m0.8163\u001b[0m        \u001b[35m0.5079\u001b[0m  0.8394\n",
            "      8        \u001b[36m0.6357\u001b[0m       0.8011        0.5086  0.8482\n",
            "      9        \u001b[36m0.6237\u001b[0m       \u001b[32m0.8234\u001b[0m        \u001b[35m0.4953\u001b[0m  0.8391\n",
            "     10        \u001b[36m0.6171\u001b[0m       0.8199        \u001b[35m0.4682\u001b[0m  0.8387\n",
            "     11        \u001b[36m0.6073\u001b[0m       \u001b[32m0.8303\u001b[0m        \u001b[35m0.4675\u001b[0m  0.8336\n",
            "     12        \u001b[36m0.5947\u001b[0m       0.8293        0.4701  0.8455\n",
            "     13        0.5969       0.8265        0.4734  0.8532\n",
            "     14        \u001b[36m0.5946\u001b[0m       \u001b[32m0.8319\u001b[0m        0.4769  0.8537\n",
            "     15        \u001b[36m0.5812\u001b[0m       \u001b[32m0.8357\u001b[0m        \u001b[35m0.4653\u001b[0m  0.8442\n",
            "     16        \u001b[36m0.5809\u001b[0m       \u001b[32m0.8393\u001b[0m        \u001b[35m0.4491\u001b[0m  0.8423\n",
            "     17        \u001b[36m0.5758\u001b[0m       0.8316        0.4498  0.8537\n",
            "     18        0.5828       \u001b[32m0.8409\u001b[0m        \u001b[35m0.4471\u001b[0m  0.8385\n",
            "     19        \u001b[36m0.5679\u001b[0m       0.8331        0.4545  0.8333\n",
            "     20        0.5712       0.8237        0.4552  0.8561\n",
            "[CV] END lr=0.05, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=  17.5s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1810\u001b[0m       \u001b[32m0.7630\u001b[0m        \u001b[35m0.6305\u001b[0m  0.8324\n",
            "      2        \u001b[36m0.7790\u001b[0m       \u001b[32m0.7937\u001b[0m        \u001b[35m0.5524\u001b[0m  0.8318\n",
            "      3        \u001b[36m0.7338\u001b[0m       0.7711        \u001b[35m0.5407\u001b[0m  0.8362\n",
            "      4        \u001b[36m0.6964\u001b[0m       \u001b[32m0.8204\u001b[0m        \u001b[35m0.5159\u001b[0m  0.8437\n",
            "      5        \u001b[36m0.6770\u001b[0m       0.8074        \u001b[35m0.5050\u001b[0m  0.8539\n",
            "      6        \u001b[36m0.6636\u001b[0m       0.8131        0.5115  0.8466\n",
            "      7        \u001b[36m0.6483\u001b[0m       0.8029        \u001b[35m0.4879\u001b[0m  0.8545\n",
            "      8        \u001b[36m0.6358\u001b[0m       \u001b[32m0.8280\u001b[0m        0.4949  0.8474\n",
            "      9        0.6396       0.8243        \u001b[35m0.4856\u001b[0m  0.8611\n",
            "     10        \u001b[36m0.6163\u001b[0m       \u001b[32m0.8401\u001b[0m        \u001b[35m0.4622\u001b[0m  0.8532\n",
            "     11        \u001b[36m0.6040\u001b[0m       0.8206        0.4704  0.8442\n",
            "     12        0.6080       0.8359        \u001b[35m0.4527\u001b[0m  0.8527\n",
            "     13        \u001b[36m0.5895\u001b[0m       \u001b[32m0.8404\u001b[0m        \u001b[35m0.4479\u001b[0m  0.8427\n",
            "     14        \u001b[36m0.5825\u001b[0m       0.8241        0.4638  0.8512\n",
            "     15        0.5834       0.8361        0.4614  0.8449\n",
            "     16        \u001b[36m0.5705\u001b[0m       \u001b[32m0.8449\u001b[0m        \u001b[35m0.4312\u001b[0m  0.8545\n",
            "     17        \u001b[36m0.5678\u001b[0m       \u001b[32m0.8529\u001b[0m        \u001b[35m0.4305\u001b[0m  0.8428\n",
            "     18        \u001b[36m0.5524\u001b[0m       0.8480        0.4317  0.8323\n",
            "     19        0.5701       0.8459        \u001b[35m0.4245\u001b[0m  0.8517\n",
            "     20        0.5586       0.8494        0.4302  0.8455\n",
            "[CV] END lr=0.05, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=  17.5s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1841\u001b[0m       \u001b[32m0.7506\u001b[0m        \u001b[35m0.6436\u001b[0m  0.8738\n",
            "      2        \u001b[36m0.7665\u001b[0m       \u001b[32m0.7849\u001b[0m        \u001b[35m0.5627\u001b[0m  0.8751\n",
            "      3        \u001b[36m0.7148\u001b[0m       \u001b[32m0.8024\u001b[0m        \u001b[35m0.5430\u001b[0m  0.8440\n",
            "      4        \u001b[36m0.6878\u001b[0m       0.7750        \u001b[35m0.5197\u001b[0m  0.8333\n",
            "      5        \u001b[36m0.6802\u001b[0m       \u001b[32m0.8149\u001b[0m        \u001b[35m0.5038\u001b[0m  0.8433\n",
            "      6        \u001b[36m0.6562\u001b[0m       \u001b[32m0.8253\u001b[0m        \u001b[35m0.5032\u001b[0m  0.8526\n",
            "      7        \u001b[36m0.6499\u001b[0m       0.8179        \u001b[35m0.4774\u001b[0m  0.8401\n",
            "      8        \u001b[36m0.6370\u001b[0m       \u001b[32m0.8299\u001b[0m        \u001b[35m0.4710\u001b[0m  0.8432\n",
            "      9        0.6373       \u001b[32m0.8305\u001b[0m        0.4759  0.8398\n",
            "     10        \u001b[36m0.6280\u001b[0m       \u001b[32m0.8360\u001b[0m        0.4881  0.8391\n",
            "     11        \u001b[36m0.6192\u001b[0m       \u001b[32m0.8361\u001b[0m        \u001b[35m0.4708\u001b[0m  0.8241\n",
            "     12        \u001b[36m0.6030\u001b[0m       0.8207        0.4916  0.8473\n",
            "     13        \u001b[36m0.6025\u001b[0m       0.8325        \u001b[35m0.4655\u001b[0m  0.8373\n",
            "     14        \u001b[36m0.5991\u001b[0m       \u001b[32m0.8486\u001b[0m        \u001b[35m0.4461\u001b[0m  0.8593\n",
            "     15        \u001b[36m0.5895\u001b[0m       0.8293        0.4643  0.8952\n",
            "     16        \u001b[36m0.5874\u001b[0m       0.8485        \u001b[35m0.4419\u001b[0m  0.8458\n",
            "     17        \u001b[36m0.5789\u001b[0m       0.8438        0.4441  0.8304\n",
            "     18        \u001b[36m0.5679\u001b[0m       \u001b[32m0.8532\u001b[0m        0.4499  0.8439\n",
            "     19        0.5715       0.8524        \u001b[35m0.4326\u001b[0m  0.8403\n",
            "     20        \u001b[36m0.5660\u001b[0m       0.8364        0.4488  0.8456\n",
            "[CV] END lr=0.05, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=  17.5s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1906\u001b[0m       \u001b[32m0.7438\u001b[0m        \u001b[35m0.6450\u001b[0m  0.8339\n",
            "      2        \u001b[36m0.7734\u001b[0m       \u001b[32m0.7701\u001b[0m        \u001b[35m0.5952\u001b[0m  0.8349\n",
            "      3        \u001b[36m0.7223\u001b[0m       \u001b[32m0.7860\u001b[0m        \u001b[35m0.5422\u001b[0m  0.8231\n",
            "      4        \u001b[36m0.7007\u001b[0m       0.7742        0.5558  0.8300\n",
            "      5        \u001b[36m0.6839\u001b[0m       \u001b[32m0.7943\u001b[0m        \u001b[35m0.5238\u001b[0m  0.8466\n",
            "      6        \u001b[36m0.6712\u001b[0m       \u001b[32m0.8013\u001b[0m        \u001b[35m0.5135\u001b[0m  0.8426\n",
            "      7        \u001b[36m0.6551\u001b[0m       0.7956        \u001b[35m0.5104\u001b[0m  0.8527\n",
            "      8        \u001b[36m0.6518\u001b[0m       \u001b[32m0.8164\u001b[0m        \u001b[35m0.4985\u001b[0m  0.8912\n",
            "      9        \u001b[36m0.6437\u001b[0m       0.8153        0.4990  0.8336\n",
            "     10        \u001b[36m0.6393\u001b[0m       0.8106        0.5186  0.8572\n",
            "     11        0.6477       0.8106        \u001b[35m0.4879\u001b[0m  0.8478\n",
            "     12        0.6447       \u001b[32m0.8201\u001b[0m        0.4989  0.8508\n",
            "     13        0.6482       0.7866        0.5361  0.8490\n",
            "     14        0.6554       \u001b[32m0.8211\u001b[0m        \u001b[35m0.4838\u001b[0m  0.8400\n",
            "     15        0.6548       0.8063        0.4902  0.8367\n",
            "     16        0.6469       0.8187        0.5144  0.8301\n",
            "     17        0.6469       0.8190        0.5157  0.8455\n",
            "     18        0.6471       0.8149        0.4885  0.8336\n",
            "     19        0.6495       \u001b[32m0.8269\u001b[0m        0.4942  0.8314\n",
            "     20        0.6406       0.8174        0.5011  0.8603\n",
            "[CV] END lr=0.05, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=  17.5s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1767\u001b[0m       \u001b[32m0.7215\u001b[0m        \u001b[35m0.6714\u001b[0m  0.8758\n",
            "      2        \u001b[36m0.7742\u001b[0m       \u001b[32m0.7877\u001b[0m        \u001b[35m0.5849\u001b[0m  0.8533\n",
            "      3        \u001b[36m0.7138\u001b[0m       \u001b[32m0.8133\u001b[0m        \u001b[35m0.5458\u001b[0m  0.8567\n",
            "      4        \u001b[36m0.7048\u001b[0m       0.8020        \u001b[35m0.5023\u001b[0m  0.8393\n",
            "      5        \u001b[36m0.6836\u001b[0m       0.8084        0.5077  0.8439\n",
            "      6        \u001b[36m0.6784\u001b[0m       0.8127        \u001b[35m0.4928\u001b[0m  0.8337\n",
            "      7        \u001b[36m0.6455\u001b[0m       0.7934        0.5092  0.8464\n",
            "      8        \u001b[36m0.6452\u001b[0m       0.8064        0.4945  0.8339\n",
            "      9        \u001b[36m0.6330\u001b[0m       \u001b[32m0.8201\u001b[0m        \u001b[35m0.4815\u001b[0m  0.8457\n",
            "     10        0.6517       \u001b[32m0.8363\u001b[0m        \u001b[35m0.4693\u001b[0m  0.8492\n",
            "     11        0.6388       0.8210        0.4812  0.8361\n",
            "     12        0.6403       0.8114        0.4882  0.8403\n",
            "     13        0.6383       \u001b[32m0.8375\u001b[0m        0.4781  0.8743\n",
            "     14        0.6349       0.8279        0.4791  0.8549\n",
            "     15        0.6354       0.8313        0.4788  0.8497\n",
            "     16        0.6477       0.8207        0.5053  0.8543\n",
            "     17        0.6408       0.8045        0.5047  0.8549\n",
            "     18        0.6439       0.8251        0.4811  0.8330\n",
            "     19        0.6396       0.8285        0.5070  0.8323\n",
            "     20        0.6357       0.8351        0.4766  0.8358\n",
            "[CV] END lr=0.05, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=  17.5s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1735\u001b[0m       \u001b[32m0.7640\u001b[0m        \u001b[35m0.6204\u001b[0m  0.8296\n",
            "      2        \u001b[36m0.7649\u001b[0m       \u001b[32m0.7881\u001b[0m        \u001b[35m0.5560\u001b[0m  0.8263\n",
            "      3        \u001b[36m0.7003\u001b[0m       \u001b[32m0.8200\u001b[0m        \u001b[35m0.5205\u001b[0m  0.8252\n",
            "      4        \u001b[36m0.6815\u001b[0m       \u001b[32m0.8246\u001b[0m        \u001b[35m0.4967\u001b[0m  0.8312\n",
            "      5        \u001b[36m0.6671\u001b[0m       0.8236        \u001b[35m0.4866\u001b[0m  0.8371\n",
            "      6        \u001b[36m0.6587\u001b[0m       \u001b[32m0.8304\u001b[0m        \u001b[35m0.4772\u001b[0m  0.8542\n",
            "      7        \u001b[36m0.6457\u001b[0m       0.8299        \u001b[35m0.4666\u001b[0m  0.8586\n",
            "      8        \u001b[36m0.6391\u001b[0m       0.8214        0.4743  0.8546\n",
            "      9        0.6492       \u001b[32m0.8317\u001b[0m        \u001b[35m0.4651\u001b[0m  0.8684\n",
            "     10        \u001b[36m0.6329\u001b[0m       0.8315        0.4828  0.8540\n",
            "     11        \u001b[36m0.6257\u001b[0m       0.8206        0.4994  0.8603\n",
            "     12        0.6301       \u001b[32m0.8363\u001b[0m        \u001b[35m0.4465\u001b[0m  0.8336\n",
            "     13        \u001b[36m0.6192\u001b[0m       \u001b[32m0.8415\u001b[0m        0.4514  0.8518\n",
            "     14        0.6295       0.8311        0.4822  0.8400\n",
            "     15        0.6263       \u001b[32m0.8439\u001b[0m        \u001b[35m0.4402\u001b[0m  0.8301\n",
            "     16        \u001b[36m0.6174\u001b[0m       0.8400        0.4563  0.8416\n",
            "     17        \u001b[36m0.6074\u001b[0m       \u001b[32m0.8484\u001b[0m        \u001b[35m0.4396\u001b[0m  0.8295\n",
            "     18        0.6259       0.8406        \u001b[35m0.4380\u001b[0m  0.8426\n",
            "     19        0.6377       0.8256        0.4701  0.8449\n",
            "     20        0.6292       0.8375        0.4702  0.8418\n",
            "[CV] END lr=0.05, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=  17.4s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0738\u001b[0m       \u001b[32m0.7746\u001b[0m        \u001b[35m0.5790\u001b[0m  0.8446\n",
            "      2        \u001b[36m0.6385\u001b[0m       \u001b[32m0.8089\u001b[0m        \u001b[35m0.5177\u001b[0m  0.8597\n",
            "      3        \u001b[36m0.5702\u001b[0m       \u001b[32m0.8150\u001b[0m        \u001b[35m0.4922\u001b[0m  0.8350\n",
            "      4        \u001b[36m0.5263\u001b[0m       \u001b[32m0.8393\u001b[0m        \u001b[35m0.4290\u001b[0m  0.8644\n",
            "      5        \u001b[36m0.5050\u001b[0m       0.8373        \u001b[35m0.4239\u001b[0m  0.8576\n",
            "      6        \u001b[36m0.4826\u001b[0m       \u001b[32m0.8479\u001b[0m        \u001b[35m0.4168\u001b[0m  0.8492\n",
            "      7        \u001b[36m0.4687\u001b[0m       \u001b[32m0.8544\u001b[0m        \u001b[35m0.3961\u001b[0m  0.8412\n",
            "      8        \u001b[36m0.4552\u001b[0m       \u001b[32m0.8558\u001b[0m        \u001b[35m0.3920\u001b[0m  0.8712\n",
            "      9        \u001b[36m0.4413\u001b[0m       0.8459        0.4195  0.8491\n",
            "     10        \u001b[36m0.4318\u001b[0m       \u001b[32m0.8685\u001b[0m        \u001b[35m0.3646\u001b[0m  0.8361\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=   9.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1106\u001b[0m       \u001b[32m0.7701\u001b[0m        \u001b[35m0.6004\u001b[0m  0.8581\n",
            "      2        \u001b[36m0.6595\u001b[0m       \u001b[32m0.8269\u001b[0m        \u001b[35m0.4725\u001b[0m  0.8434\n",
            "      3        \u001b[36m0.5814\u001b[0m       \u001b[32m0.8305\u001b[0m        \u001b[35m0.4677\u001b[0m  0.8479\n",
            "      4        \u001b[36m0.5391\u001b[0m       \u001b[32m0.8531\u001b[0m        \u001b[35m0.4118\u001b[0m  0.8483\n",
            "      5        \u001b[36m0.5091\u001b[0m       0.8522        \u001b[35m0.4085\u001b[0m  0.8602\n",
            "      6        \u001b[36m0.4876\u001b[0m       0.8516        \u001b[35m0.4082\u001b[0m  0.8518\n",
            "      7        \u001b[36m0.4757\u001b[0m       \u001b[32m0.8644\u001b[0m        \u001b[35m0.3796\u001b[0m  0.8341\n",
            "      8        \u001b[36m0.4593\u001b[0m       \u001b[32m0.8650\u001b[0m        \u001b[35m0.3619\u001b[0m  0.8449\n",
            "      9        \u001b[36m0.4477\u001b[0m       0.8600        0.3756  0.8409\n",
            "     10        \u001b[36m0.4393\u001b[0m       \u001b[32m0.8668\u001b[0m        0.3675  0.8468\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=   9.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0734\u001b[0m       \u001b[32m0.7950\u001b[0m        \u001b[35m0.5555\u001b[0m  0.8372\n",
            "      2        \u001b[36m0.6394\u001b[0m       \u001b[32m0.8244\u001b[0m        \u001b[35m0.4814\u001b[0m  0.8389\n",
            "      3        \u001b[36m0.5690\u001b[0m       \u001b[32m0.8320\u001b[0m        \u001b[35m0.4587\u001b[0m  0.8618\n",
            "      4        \u001b[36m0.5284\u001b[0m       \u001b[32m0.8387\u001b[0m        \u001b[35m0.4437\u001b[0m  0.8486\n",
            "      5        \u001b[36m0.5078\u001b[0m       \u001b[32m0.8480\u001b[0m        \u001b[35m0.4088\u001b[0m  0.8478\n",
            "      6        \u001b[36m0.4810\u001b[0m       \u001b[32m0.8501\u001b[0m        \u001b[35m0.4031\u001b[0m  0.8548\n",
            "      7        \u001b[36m0.4692\u001b[0m       \u001b[32m0.8611\u001b[0m        \u001b[35m0.3810\u001b[0m  0.8618\n",
            "      8        \u001b[36m0.4515\u001b[0m       0.8579        0.3885  0.8549\n",
            "      9        \u001b[36m0.4394\u001b[0m       0.8601        \u001b[35m0.3767\u001b[0m  0.8554\n",
            "     10        \u001b[36m0.4293\u001b[0m       \u001b[32m0.8620\u001b[0m        0.3775  0.8492\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=   9.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0949\u001b[0m       \u001b[32m0.7354\u001b[0m        \u001b[35m0.6673\u001b[0m  0.8531\n",
            "      2        \u001b[36m0.6608\u001b[0m       \u001b[32m0.8137\u001b[0m        \u001b[35m0.5131\u001b[0m  0.8445\n",
            "      3        \u001b[36m0.5796\u001b[0m       \u001b[32m0.8143\u001b[0m        \u001b[35m0.5028\u001b[0m  0.8406\n",
            "      4        \u001b[36m0.5420\u001b[0m       \u001b[32m0.8344\u001b[0m        \u001b[35m0.4481\u001b[0m  0.8400\n",
            "      5        \u001b[36m0.5150\u001b[0m       \u001b[32m0.8386\u001b[0m        \u001b[35m0.4252\u001b[0m  0.8530\n",
            "      6        \u001b[36m0.4977\u001b[0m       \u001b[32m0.8455\u001b[0m        \u001b[35m0.4207\u001b[0m  0.8646\n",
            "      7        \u001b[36m0.4821\u001b[0m       \u001b[32m0.8522\u001b[0m        \u001b[35m0.4031\u001b[0m  0.8414\n",
            "      8        \u001b[36m0.4749\u001b[0m       0.8510        \u001b[35m0.4021\u001b[0m  0.8623\n",
            "      9        \u001b[36m0.4636\u001b[0m       0.8438        0.4090  0.8505\n",
            "     10        \u001b[36m0.4539\u001b[0m       0.8514        \u001b[35m0.3913\u001b[0m  0.8366\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=   9.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0883\u001b[0m       \u001b[32m0.7937\u001b[0m        \u001b[35m0.5931\u001b[0m  0.8559\n",
            "      2        \u001b[36m0.6605\u001b[0m       \u001b[32m0.8054\u001b[0m        \u001b[35m0.5303\u001b[0m  0.8326\n",
            "      3        \u001b[36m0.5863\u001b[0m       \u001b[32m0.8239\u001b[0m        \u001b[35m0.4719\u001b[0m  0.8414\n",
            "      4        \u001b[36m0.5507\u001b[0m       \u001b[32m0.8373\u001b[0m        \u001b[35m0.4445\u001b[0m  0.8591\n",
            "      5        \u001b[36m0.5139\u001b[0m       \u001b[32m0.8461\u001b[0m        \u001b[35m0.4176\u001b[0m  0.8350\n",
            "      6        \u001b[36m0.4969\u001b[0m       \u001b[32m0.8508\u001b[0m        \u001b[35m0.4012\u001b[0m  0.8371\n",
            "      7        \u001b[36m0.4865\u001b[0m       \u001b[32m0.8619\u001b[0m        \u001b[35m0.3894\u001b[0m  0.8399\n",
            "      8        \u001b[36m0.4742\u001b[0m       0.8578        \u001b[35m0.3838\u001b[0m  0.8556\n",
            "      9        \u001b[36m0.4674\u001b[0m       0.8611        \u001b[35m0.3784\u001b[0m  0.8508\n",
            "     10        \u001b[36m0.4576\u001b[0m       \u001b[32m0.8679\u001b[0m        \u001b[35m0.3678\u001b[0m  0.8474\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=   9.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0681\u001b[0m       \u001b[32m0.8024\u001b[0m        \u001b[35m0.5516\u001b[0m  0.8486\n",
            "      2        \u001b[36m0.6455\u001b[0m       \u001b[32m0.8205\u001b[0m        \u001b[35m0.4871\u001b[0m  0.8381\n",
            "      3        \u001b[36m0.5777\u001b[0m       \u001b[32m0.8346\u001b[0m        \u001b[35m0.4510\u001b[0m  0.8531\n",
            "      4        \u001b[36m0.5394\u001b[0m       \u001b[32m0.8371\u001b[0m        0.4608  0.8658\n",
            "      5        \u001b[36m0.5140\u001b[0m       \u001b[32m0.8474\u001b[0m        \u001b[35m0.4215\u001b[0m  0.8425\n",
            "      6        \u001b[36m0.4932\u001b[0m       \u001b[32m0.8579\u001b[0m        \u001b[35m0.3866\u001b[0m  0.8445\n",
            "      7        \u001b[36m0.4824\u001b[0m       0.8574        \u001b[35m0.3853\u001b[0m  0.8433\n",
            "      8        \u001b[36m0.4730\u001b[0m       \u001b[32m0.8580\u001b[0m        \u001b[35m0.3825\u001b[0m  0.8307\n",
            "      9        \u001b[36m0.4613\u001b[0m       \u001b[32m0.8611\u001b[0m        0.3926  0.8276\n",
            "     10        \u001b[36m0.4559\u001b[0m       0.8570        0.4058  0.8381\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=   8.9s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0349\u001b[0m       \u001b[32m0.7498\u001b[0m        \u001b[35m0.6049\u001b[0m  0.8523\n",
            "      2        \u001b[36m0.7913\u001b[0m       0.7339        \u001b[35m0.5954\u001b[0m  0.8286\n",
            "      3        \u001b[36m0.7674\u001b[0m       \u001b[32m0.7580\u001b[0m        0.6062  0.8282\n",
            "      4        \u001b[36m0.7223\u001b[0m       \u001b[32m0.7856\u001b[0m        \u001b[35m0.5719\u001b[0m  0.8222\n",
            "      5        0.7277       \u001b[32m0.7893\u001b[0m        \u001b[35m0.5402\u001b[0m  0.8196\n",
            "      6        \u001b[36m0.7052\u001b[0m       \u001b[32m0.8149\u001b[0m        0.5446  0.8476\n",
            "      7        \u001b[36m0.7021\u001b[0m       0.7690        0.5963  0.8608\n",
            "      8        \u001b[36m0.7001\u001b[0m       \u001b[32m0.8155\u001b[0m        \u001b[35m0.5159\u001b[0m  0.8527\n",
            "      9        \u001b[36m0.6847\u001b[0m       \u001b[32m0.8193\u001b[0m        \u001b[35m0.5147\u001b[0m  0.8321\n",
            "     10        \u001b[36m0.6742\u001b[0m       0.7956        0.5368  0.8427\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=   8.9s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0298\u001b[0m       \u001b[32m0.7358\u001b[0m        \u001b[35m0.6056\u001b[0m  0.8472\n",
            "      2        \u001b[36m0.7907\u001b[0m       \u001b[32m0.7802\u001b[0m        \u001b[35m0.5906\u001b[0m  0.8369\n",
            "      3        \u001b[36m0.7623\u001b[0m       \u001b[32m0.7880\u001b[0m        \u001b[35m0.5590\u001b[0m  0.8529\n",
            "      4        \u001b[36m0.7271\u001b[0m       0.7794        0.5740  0.8529\n",
            "      5        0.7295       0.7874        0.5778  0.8656\n",
            "      6        \u001b[36m0.7231\u001b[0m       0.7800        0.5794  0.8400\n",
            "      7        \u001b[36m0.7073\u001b[0m       \u001b[32m0.8213\u001b[0m        \u001b[35m0.5453\u001b[0m  0.8390\n",
            "      8        \u001b[36m0.6898\u001b[0m       0.8145        \u001b[35m0.5428\u001b[0m  0.8416\n",
            "      9        \u001b[36m0.6851\u001b[0m       0.8059        \u001b[35m0.5263\u001b[0m  0.8487\n",
            "     10        0.6867       0.8101        0.5418  0.8459\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=   9.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0285\u001b[0m       \u001b[32m0.7761\u001b[0m        \u001b[35m0.6052\u001b[0m  0.8677\n",
            "      2        \u001b[36m0.7581\u001b[0m       0.7725        0.6135  0.8451\n",
            "      3        0.7615       0.7756        \u001b[35m0.5995\u001b[0m  0.8550\n",
            "      4        \u001b[36m0.7252\u001b[0m       \u001b[32m0.8064\u001b[0m        \u001b[35m0.5354\u001b[0m  0.8600\n",
            "      5        \u001b[36m0.7135\u001b[0m       \u001b[32m0.8220\u001b[0m        \u001b[35m0.5158\u001b[0m  0.8394\n",
            "      6        \u001b[36m0.7075\u001b[0m       0.7758        0.5768  0.8363\n",
            "      7        0.7169       0.7983        0.5403  0.8198\n",
            "      8        0.7106       0.7939        0.5642  0.8379\n",
            "      9        \u001b[36m0.7015\u001b[0m       0.7936        0.5395  0.8438\n",
            "     10        \u001b[36m0.6843\u001b[0m       0.8084        0.5580  0.8407\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=   8.9s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0353\u001b[0m       \u001b[32m0.7689\u001b[0m        \u001b[35m0.6029\u001b[0m  0.8253\n",
            "      2        \u001b[36m0.7856\u001b[0m       0.7296        0.6236  0.8330\n",
            "      3        \u001b[36m0.7591\u001b[0m       \u001b[32m0.7814\u001b[0m        0.6045  0.8534\n",
            "      4        \u001b[36m0.7297\u001b[0m       \u001b[32m0.7853\u001b[0m        \u001b[35m0.5486\u001b[0m  0.8546\n",
            "      5        \u001b[36m0.7210\u001b[0m       0.7724        0.5610  0.8380\n",
            "      6        \u001b[36m0.7177\u001b[0m       \u001b[32m0.7865\u001b[0m        \u001b[35m0.5390\u001b[0m  0.8303\n",
            "      7        0.7316       0.7771        0.5883  0.8483\n",
            "      8        0.7212       \u001b[32m0.8107\u001b[0m        0.5414  0.8561\n",
            "      9        0.7266       0.7916        0.5601  0.8475\n",
            "     10        0.7323       0.7895        0.5717  0.8304\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=   8.9s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0570\u001b[0m       \u001b[32m0.7772\u001b[0m        \u001b[35m0.6116\u001b[0m  0.8389\n",
            "      2        \u001b[36m0.7869\u001b[0m       \u001b[32m0.7810\u001b[0m        \u001b[35m0.5972\u001b[0m  0.8365\n",
            "      3        \u001b[36m0.7675\u001b[0m       0.7719        \u001b[35m0.5943\u001b[0m  0.8489\n",
            "      4        \u001b[36m0.7647\u001b[0m       0.7789        \u001b[35m0.5670\u001b[0m  0.8523\n",
            "      5        \u001b[36m0.7564\u001b[0m       0.7744        0.5778  0.8422\n",
            "      6        \u001b[36m0.7388\u001b[0m       \u001b[32m0.7859\u001b[0m        0.5687  0.8508\n",
            "      7        \u001b[36m0.7349\u001b[0m       \u001b[32m0.7974\u001b[0m        \u001b[35m0.5531\u001b[0m  0.8605\n",
            "      8        0.7461       \u001b[32m0.8135\u001b[0m        0.5541  0.8651\n",
            "      9        \u001b[36m0.7257\u001b[0m       0.7897        0.5936  0.8765\n",
            "     10        0.7350       0.7815        0.5664  0.8518\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=   9.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0281\u001b[0m       \u001b[32m0.7645\u001b[0m        \u001b[35m0.6203\u001b[0m  0.8441\n",
            "      2        \u001b[36m0.7437\u001b[0m       \u001b[32m0.7751\u001b[0m        \u001b[35m0.5620\u001b[0m  0.8272\n",
            "      3        \u001b[36m0.7421\u001b[0m       0.7642        0.6077  0.8398\n",
            "      4        \u001b[36m0.7420\u001b[0m       \u001b[32m0.8126\u001b[0m        \u001b[35m0.5296\u001b[0m  0.8419\n",
            "      5        \u001b[36m0.7326\u001b[0m       0.8027        0.5595  0.8388\n",
            "      6        0.7453       0.7967        0.5866  0.8360\n",
            "      7        0.7530       0.8056        0.5816  0.8449\n",
            "      8        0.7326       0.8021        \u001b[35m0.5229\u001b[0m  0.8294\n",
            "      9        0.7501       0.8024        0.5375  0.8310\n",
            "     10        0.7432       0.7903        0.5674  0.8573\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=   8.9s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1709\u001b[0m       \u001b[32m0.7558\u001b[0m        \u001b[35m0.6464\u001b[0m  0.8549\n",
            "      2        \u001b[36m0.7360\u001b[0m       \u001b[32m0.7863\u001b[0m        \u001b[35m0.5572\u001b[0m  0.8609\n",
            "      3        \u001b[36m0.6620\u001b[0m       \u001b[32m0.7999\u001b[0m        \u001b[35m0.5142\u001b[0m  0.8589\n",
            "      4        \u001b[36m0.6161\u001b[0m       \u001b[32m0.8210\u001b[0m        \u001b[35m0.4807\u001b[0m  0.8204\n",
            "      5        \u001b[36m0.5955\u001b[0m       \u001b[32m0.8227\u001b[0m        \u001b[35m0.4784\u001b[0m  0.8247\n",
            "      6        \u001b[36m0.5655\u001b[0m       \u001b[32m0.8331\u001b[0m        \u001b[35m0.4478\u001b[0m  0.8341\n",
            "      7        \u001b[36m0.5438\u001b[0m       \u001b[32m0.8360\u001b[0m        \u001b[35m0.4346\u001b[0m  0.8321\n",
            "      8        \u001b[36m0.5354\u001b[0m       \u001b[32m0.8397\u001b[0m        \u001b[35m0.4213\u001b[0m  0.8303\n",
            "      9        \u001b[36m0.5189\u001b[0m       \u001b[32m0.8409\u001b[0m        0.4217  0.8213\n",
            "     10        \u001b[36m0.5093\u001b[0m       \u001b[32m0.8480\u001b[0m        \u001b[35m0.4081\u001b[0m  0.8331\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=   8.9s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1763\u001b[0m       \u001b[32m0.7322\u001b[0m        \u001b[35m0.6760\u001b[0m  0.8349\n",
            "      2        \u001b[36m0.7513\u001b[0m       \u001b[32m0.7836\u001b[0m        \u001b[35m0.5533\u001b[0m  0.8327\n",
            "      3        \u001b[36m0.6675\u001b[0m       \u001b[32m0.8060\u001b[0m        \u001b[35m0.5045\u001b[0m  0.8609\n",
            "      4        \u001b[36m0.6283\u001b[0m       \u001b[32m0.8270\u001b[0m        \u001b[35m0.4809\u001b[0m  0.8485\n",
            "      5        \u001b[36m0.5955\u001b[0m       \u001b[32m0.8283\u001b[0m        \u001b[35m0.4758\u001b[0m  0.8611\n",
            "      6        \u001b[36m0.5757\u001b[0m       \u001b[32m0.8436\u001b[0m        \u001b[35m0.4365\u001b[0m  0.8514\n",
            "      7        \u001b[36m0.5513\u001b[0m       \u001b[32m0.8489\u001b[0m        \u001b[35m0.4301\u001b[0m  0.8449\n",
            "      8        \u001b[36m0.5335\u001b[0m       \u001b[32m0.8511\u001b[0m        \u001b[35m0.3992\u001b[0m  0.8428\n",
            "      9        \u001b[36m0.5310\u001b[0m       \u001b[32m0.8540\u001b[0m        0.4032  0.8372\n",
            "     10        \u001b[36m0.5042\u001b[0m       0.8538        0.4067  0.8313\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=   9.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1964\u001b[0m       \u001b[32m0.7689\u001b[0m        \u001b[35m0.6442\u001b[0m  0.8360\n",
            "      2        \u001b[36m0.7333\u001b[0m       \u001b[32m0.8075\u001b[0m        \u001b[35m0.5129\u001b[0m  0.8436\n",
            "      3        \u001b[36m0.6540\u001b[0m       0.8065        \u001b[35m0.5073\u001b[0m  0.8516\n",
            "      4        \u001b[36m0.6131\u001b[0m       \u001b[32m0.8405\u001b[0m        \u001b[35m0.4440\u001b[0m  0.8310\n",
            "      5        \u001b[36m0.5842\u001b[0m       0.8371        \u001b[35m0.4340\u001b[0m  0.8429\n",
            "      6        \u001b[36m0.5523\u001b[0m       0.8351        0.4414  0.8521\n",
            "      7        \u001b[36m0.5388\u001b[0m       \u001b[32m0.8515\u001b[0m        \u001b[35m0.4022\u001b[0m  0.8599\n",
            "      8        \u001b[36m0.5285\u001b[0m       0.8465        0.4051  0.8724\n",
            "      9        \u001b[36m0.5137\u001b[0m       \u001b[32m0.8541\u001b[0m        \u001b[35m0.3964\u001b[0m  0.8418\n",
            "     10        \u001b[36m0.4956\u001b[0m       \u001b[32m0.8551\u001b[0m        \u001b[35m0.3942\u001b[0m  0.8504\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=   9.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1611\u001b[0m       \u001b[32m0.7586\u001b[0m        \u001b[35m0.6394\u001b[0m  0.8572\n",
            "      2        \u001b[36m0.7345\u001b[0m       \u001b[32m0.7857\u001b[0m        \u001b[35m0.5643\u001b[0m  0.8522\n",
            "      3        \u001b[36m0.6561\u001b[0m       \u001b[32m0.8040\u001b[0m        \u001b[35m0.4997\u001b[0m  0.8312\n",
            "      4        \u001b[36m0.6130\u001b[0m       \u001b[32m0.8206\u001b[0m        \u001b[35m0.4937\u001b[0m  0.8441\n",
            "      5        \u001b[36m0.5827\u001b[0m       \u001b[32m0.8311\u001b[0m        \u001b[35m0.4547\u001b[0m  0.8361\n",
            "      6        \u001b[36m0.5664\u001b[0m       \u001b[32m0.8384\u001b[0m        \u001b[35m0.4286\u001b[0m  0.8288\n",
            "      7        \u001b[36m0.5518\u001b[0m       0.8353        0.4440  0.8303\n",
            "      8        \u001b[36m0.5317\u001b[0m       \u001b[32m0.8423\u001b[0m        \u001b[35m0.4243\u001b[0m  0.8269\n",
            "      9        \u001b[36m0.5250\u001b[0m       \u001b[32m0.8496\u001b[0m        \u001b[35m0.4100\u001b[0m  0.8322\n",
            "     10        \u001b[36m0.5190\u001b[0m       0.8419        0.4275  0.8711\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=   8.9s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1794\u001b[0m       \u001b[32m0.7434\u001b[0m        \u001b[35m0.6887\u001b[0m  0.8513\n",
            "      2        \u001b[36m0.7465\u001b[0m       \u001b[32m0.7694\u001b[0m        \u001b[35m0.5658\u001b[0m  0.8495\n",
            "      3        \u001b[36m0.6680\u001b[0m       \u001b[32m0.8215\u001b[0m        \u001b[35m0.5017\u001b[0m  0.8450\n",
            "      4        \u001b[36m0.6314\u001b[0m       \u001b[32m0.8280\u001b[0m        \u001b[35m0.4761\u001b[0m  0.8425\n",
            "      5        \u001b[36m0.5969\u001b[0m       0.8275        0.4764  0.8372\n",
            "      6        \u001b[36m0.5752\u001b[0m       \u001b[32m0.8441\u001b[0m        \u001b[35m0.4326\u001b[0m  0.8350\n",
            "      7        \u001b[36m0.5602\u001b[0m       0.8431        \u001b[35m0.4255\u001b[0m  0.8359\n",
            "      8        \u001b[36m0.5460\u001b[0m       0.8386        0.4306  0.8370\n",
            "      9        \u001b[36m0.5315\u001b[0m       \u001b[32m0.8479\u001b[0m        \u001b[35m0.4172\u001b[0m  0.8319\n",
            "     10        \u001b[36m0.5261\u001b[0m       \u001b[32m0.8540\u001b[0m        \u001b[35m0.4030\u001b[0m  0.8302\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=   8.9s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1857\u001b[0m       \u001b[32m0.7281\u001b[0m        \u001b[35m0.6647\u001b[0m  0.8328\n",
            "      2        \u001b[36m0.7461\u001b[0m       \u001b[32m0.7970\u001b[0m        \u001b[35m0.5415\u001b[0m  0.8478\n",
            "      3        \u001b[36m0.6617\u001b[0m       \u001b[32m0.8231\u001b[0m        \u001b[35m0.5011\u001b[0m  0.8688\n",
            "      4        \u001b[36m0.6112\u001b[0m       \u001b[32m0.8357\u001b[0m        \u001b[35m0.4541\u001b[0m  0.8466\n",
            "      5        \u001b[36m0.5870\u001b[0m       \u001b[32m0.8413\u001b[0m        \u001b[35m0.4435\u001b[0m  0.8618\n",
            "      6        \u001b[36m0.5686\u001b[0m       \u001b[32m0.8450\u001b[0m        \u001b[35m0.4249\u001b[0m  0.8634\n",
            "      7        \u001b[36m0.5475\u001b[0m       \u001b[32m0.8531\u001b[0m        \u001b[35m0.4215\u001b[0m  0.8825\n",
            "      8        \u001b[36m0.5305\u001b[0m       \u001b[32m0.8535\u001b[0m        \u001b[35m0.4000\u001b[0m  0.8414\n",
            "      9        \u001b[36m0.5300\u001b[0m       0.8468        0.4139  0.8457\n",
            "     10        \u001b[36m0.5223\u001b[0m       \u001b[32m0.8569\u001b[0m        0.4057  0.8422\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=   9.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1842\u001b[0m       \u001b[32m0.6960\u001b[0m        \u001b[35m0.7734\u001b[0m  0.8379\n",
            "      2        \u001b[36m1.0066\u001b[0m       0.6489        \u001b[35m0.7717\u001b[0m  0.8683\n",
            "      3        \u001b[36m0.9819\u001b[0m       \u001b[32m0.7177\u001b[0m        \u001b[35m0.6710\u001b[0m  0.8377\n",
            "      4        \u001b[36m0.9765\u001b[0m       \u001b[32m0.7720\u001b[0m        \u001b[35m0.6541\u001b[0m  0.8512\n",
            "      5        \u001b[36m0.9528\u001b[0m       0.7411        0.6617  0.8668\n",
            "      6        0.9903       0.7718        0.6610  0.8533\n",
            "      7        0.9723       0.7225        0.6995  0.8616\n",
            "      8        0.9855       0.7466        0.6869  0.8561\n",
            "      9        0.9967       0.7272        0.6827  0.8338\n",
            "     10        1.0368       0.7239        0.7225  0.8345\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=   9.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1970\u001b[0m       \u001b[32m0.7149\u001b[0m        \u001b[35m0.6925\u001b[0m  0.8594\n",
            "      2        \u001b[36m0.9868\u001b[0m       \u001b[32m0.7278\u001b[0m        \u001b[35m0.6901\u001b[0m  0.8527\n",
            "      3        0.9997       0.7274        0.6963  0.8464\n",
            "      4        1.0060       \u001b[32m0.7424\u001b[0m        0.7412  0.8545\n",
            "      5        1.0459       0.7179        0.7216  0.8390\n",
            "      6        1.0001       0.7310        \u001b[35m0.6550\u001b[0m  0.8297\n",
            "      7        0.9999       0.7276        0.7103  0.8554\n",
            "      8        0.9949       0.7127        0.7200  0.8487\n",
            "      9        1.0597       0.7206        0.7198  0.8517\n",
            "     10        1.0739       0.7266        0.6936  0.8416\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=   9.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1913\u001b[0m       \u001b[32m0.7130\u001b[0m        \u001b[35m0.7239\u001b[0m  0.8642\n",
            "      2        \u001b[36m0.9782\u001b[0m       0.6785        0.7644  0.8487\n",
            "      3        \u001b[36m0.9577\u001b[0m       \u001b[32m0.7225\u001b[0m        \u001b[35m0.6571\u001b[0m  0.8555\n",
            "      4        \u001b[36m0.9574\u001b[0m       \u001b[32m0.7552\u001b[0m        0.6774  0.8505\n",
            "      5        0.9700       0.7332        \u001b[35m0.6442\u001b[0m  0.8497\n",
            "      6        0.9666       0.7529        0.7027  0.8527\n",
            "      7        0.9837       \u001b[32m0.7610\u001b[0m        0.6752  0.8492\n",
            "      8        0.9917       0.7188        0.6824  0.8493\n",
            "      9        0.9870       0.7452        0.6497  0.8695\n",
            "     10        1.0204       0.7315        0.6595  0.8565\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=   9.1s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1805\u001b[0m       \u001b[32m0.7097\u001b[0m        \u001b[35m0.7047\u001b[0m  0.8534\n",
            "      2        \u001b[36m0.9603\u001b[0m       \u001b[32m0.7177\u001b[0m        0.7121  0.8690\n",
            "      3        \u001b[36m0.9294\u001b[0m       0.7173        \u001b[35m0.6642\u001b[0m  0.8550\n",
            "      4        \u001b[36m0.8997\u001b[0m       \u001b[32m0.7424\u001b[0m        0.6681  0.8627\n",
            "      5        0.9200       0.7219        0.6764  0.8444\n",
            "      6        0.9070       0.7230        0.6670  0.8457\n",
            "      7        0.9246       0.7228        \u001b[35m0.6551\u001b[0m  0.8427\n",
            "      8        0.9383       \u001b[32m0.7505\u001b[0m        0.6690  0.8440\n",
            "      9        0.9064       0.7185        0.6834  0.8341\n",
            "     10        0.9288       0.7500        0.6917  0.8453\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=   9.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1927\u001b[0m       \u001b[32m0.7166\u001b[0m        \u001b[35m0.7425\u001b[0m  0.8430\n",
            "      2        \u001b[36m0.9636\u001b[0m       0.7165        \u001b[35m0.6736\u001b[0m  0.8564\n",
            "      3        \u001b[36m0.9147\u001b[0m       \u001b[32m0.7328\u001b[0m        \u001b[35m0.6494\u001b[0m  0.8231\n",
            "      4        \u001b[36m0.9096\u001b[0m       \u001b[32m0.7631\u001b[0m        0.6619  0.8575\n",
            "      5        0.9282       0.7290        0.6515  0.8490\n",
            "      6        0.9339       0.7259        0.6686  0.8554\n",
            "      7        0.9293       0.7295        \u001b[35m0.6481\u001b[0m  0.8562\n",
            "      8        0.9108       0.7330        0.6542  0.8419\n",
            "      9        \u001b[36m0.9018\u001b[0m       0.7355        \u001b[35m0.6307\u001b[0m  0.8449\n",
            "     10        0.9095       0.7309        0.6390  0.8544\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=   9.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1723\u001b[0m       \u001b[32m0.7275\u001b[0m        \u001b[35m0.6843\u001b[0m  0.8351\n",
            "      2        \u001b[36m0.9485\u001b[0m       \u001b[32m0.7380\u001b[0m        \u001b[35m0.6561\u001b[0m  0.8382\n",
            "      3        \u001b[36m0.9195\u001b[0m       0.7106        0.6990  0.8368\n",
            "      4        \u001b[36m0.9014\u001b[0m       \u001b[32m0.7426\u001b[0m        0.6652  0.8527\n",
            "      5        \u001b[36m0.8858\u001b[0m       \u001b[32m0.7470\u001b[0m        \u001b[35m0.6223\u001b[0m  0.8439\n",
            "      6        0.9115       0.7180        0.6671  0.8377\n",
            "      7        0.8933       0.7289        0.6457  0.8344\n",
            "      8        0.9007       \u001b[32m0.7684\u001b[0m        0.6613  0.8422\n",
            "      9        \u001b[36m0.8850\u001b[0m       \u001b[32m0.7961\u001b[0m        0.6450  0.8686\n",
            "     10        0.9046       0.7701        0.6269  0.8585\n",
            "[CV] END lr=0.1, max_epochs=10, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=   9.0s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1011\u001b[0m       \u001b[32m0.7576\u001b[0m        \u001b[35m0.6512\u001b[0m  0.8560\n",
            "      2        \u001b[36m0.6570\u001b[0m       \u001b[32m0.8167\u001b[0m        \u001b[35m0.5086\u001b[0m  0.8546\n",
            "      3        \u001b[36m0.5778\u001b[0m       \u001b[32m0.8253\u001b[0m        \u001b[35m0.4683\u001b[0m  0.8682\n",
            "      4        \u001b[36m0.5313\u001b[0m       \u001b[32m0.8285\u001b[0m        \u001b[35m0.4432\u001b[0m  0.8692\n",
            "      5        \u001b[36m0.5006\u001b[0m       \u001b[32m0.8461\u001b[0m        \u001b[35m0.4084\u001b[0m  0.8622\n",
            "      6        \u001b[36m0.4818\u001b[0m       \u001b[32m0.8510\u001b[0m        \u001b[35m0.4021\u001b[0m  0.8531\n",
            "      7        \u001b[36m0.4717\u001b[0m       0.8508        0.4110  0.8651\n",
            "      8        \u001b[36m0.4583\u001b[0m       \u001b[32m0.8576\u001b[0m        \u001b[35m0.3913\u001b[0m  0.8673\n",
            "      9        \u001b[36m0.4446\u001b[0m       0.8576        \u001b[35m0.3730\u001b[0m  0.8677\n",
            "     10        \u001b[36m0.4364\u001b[0m       0.8559        0.3947  0.8628\n",
            "     11        \u001b[36m0.4298\u001b[0m       \u001b[32m0.8686\u001b[0m        \u001b[35m0.3658\u001b[0m  0.8444\n",
            "     12        \u001b[36m0.4211\u001b[0m       0.8596        0.3808  0.8703\n",
            "     13        \u001b[36m0.4121\u001b[0m       \u001b[32m0.8711\u001b[0m        \u001b[35m0.3530\u001b[0m  0.8350\n",
            "     14        \u001b[36m0.4027\u001b[0m       0.8699        0.3534  0.8450\n",
            "     15        \u001b[36m0.3984\u001b[0m       0.8668        0.3571  0.8377\n",
            "     16        \u001b[36m0.3951\u001b[0m       0.8704        \u001b[35m0.3520\u001b[0m  0.8306\n",
            "     17        \u001b[36m0.3876\u001b[0m       \u001b[32m0.8728\u001b[0m        0.3549  0.8475\n",
            "     18        \u001b[36m0.3793\u001b[0m       0.8710        \u001b[35m0.3440\u001b[0m  0.8285\n",
            "     19        0.3811       0.8641        0.3620  0.8411\n",
            "     20        \u001b[36m0.3775\u001b[0m       \u001b[32m0.8751\u001b[0m        0.3456  0.8485\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=  17.6s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0998\u001b[0m       \u001b[32m0.7559\u001b[0m        \u001b[35m0.6190\u001b[0m  0.8434\n",
            "      2        \u001b[36m0.6711\u001b[0m       \u001b[32m0.8170\u001b[0m        \u001b[35m0.5169\u001b[0m  0.8566\n",
            "      3        \u001b[36m0.5846\u001b[0m       \u001b[32m0.8394\u001b[0m        \u001b[35m0.4410\u001b[0m  0.8443\n",
            "      4        \u001b[36m0.5468\u001b[0m       \u001b[32m0.8417\u001b[0m        \u001b[35m0.4319\u001b[0m  0.8331\n",
            "      5        \u001b[36m0.5056\u001b[0m       \u001b[32m0.8468\u001b[0m        \u001b[35m0.4153\u001b[0m  0.8443\n",
            "      6        \u001b[36m0.4930\u001b[0m       \u001b[32m0.8531\u001b[0m        \u001b[35m0.3984\u001b[0m  0.8618\n",
            "      7        \u001b[36m0.4713\u001b[0m       \u001b[32m0.8586\u001b[0m        \u001b[35m0.3806\u001b[0m  0.8573\n",
            "      8        \u001b[36m0.4521\u001b[0m       \u001b[32m0.8588\u001b[0m        \u001b[35m0.3791\u001b[0m  0.8511\n",
            "      9        \u001b[36m0.4494\u001b[0m       \u001b[32m0.8652\u001b[0m        0.3822  0.8559\n",
            "     10        \u001b[36m0.4394\u001b[0m       \u001b[32m0.8676\u001b[0m        \u001b[35m0.3637\u001b[0m  0.8257\n",
            "     11        \u001b[36m0.4313\u001b[0m       0.8646        0.3778  0.8323\n",
            "     12        \u001b[36m0.4239\u001b[0m       0.8674        \u001b[35m0.3637\u001b[0m  0.8481\n",
            "     13        \u001b[36m0.4092\u001b[0m       \u001b[32m0.8752\u001b[0m        \u001b[35m0.3443\u001b[0m  0.8429\n",
            "     14        \u001b[36m0.4080\u001b[0m       \u001b[32m0.8766\u001b[0m        0.3464  0.8311\n",
            "     15        \u001b[36m0.4003\u001b[0m       0.8670        0.3642  0.8433\n",
            "     16        \u001b[36m0.3968\u001b[0m       0.8746        0.3500  0.8441\n",
            "     17        \u001b[36m0.3951\u001b[0m       0.8750        0.3491  0.8517\n",
            "     18        \u001b[36m0.3798\u001b[0m       \u001b[32m0.8774\u001b[0m        \u001b[35m0.3427\u001b[0m  0.8343\n",
            "     19        0.3821       \u001b[32m0.8792\u001b[0m        \u001b[35m0.3316\u001b[0m  0.8555\n",
            "     20        \u001b[36m0.3744\u001b[0m       \u001b[32m0.8816\u001b[0m        \u001b[35m0.3312\u001b[0m  0.8484\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=  17.5s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0813\u001b[0m       \u001b[32m0.7759\u001b[0m        \u001b[35m0.5873\u001b[0m  0.8488\n",
            "      2        \u001b[36m0.6459\u001b[0m       \u001b[32m0.8295\u001b[0m        \u001b[35m0.4770\u001b[0m  0.8409\n",
            "      3        \u001b[36m0.5804\u001b[0m       \u001b[32m0.8339\u001b[0m        \u001b[35m0.4441\u001b[0m  0.8446\n",
            "      4        \u001b[36m0.5342\u001b[0m       \u001b[32m0.8481\u001b[0m        \u001b[35m0.4192\u001b[0m  0.8484\n",
            "      5        \u001b[36m0.5109\u001b[0m       \u001b[32m0.8506\u001b[0m        \u001b[35m0.4010\u001b[0m  0.8424\n",
            "      6        \u001b[36m0.4853\u001b[0m       0.8492        0.4071  0.8316\n",
            "      7        \u001b[36m0.4683\u001b[0m       \u001b[32m0.8544\u001b[0m        \u001b[35m0.3945\u001b[0m  0.8519\n",
            "      8        \u001b[36m0.4650\u001b[0m       \u001b[32m0.8592\u001b[0m        \u001b[35m0.3818\u001b[0m  0.8300\n",
            "      9        \u001b[36m0.4471\u001b[0m       \u001b[32m0.8669\u001b[0m        \u001b[35m0.3742\u001b[0m  0.8354\n",
            "     10        \u001b[36m0.4312\u001b[0m       0.8649        \u001b[35m0.3732\u001b[0m  0.8261\n",
            "     11        \u001b[36m0.4298\u001b[0m       \u001b[32m0.8692\u001b[0m        \u001b[35m0.3603\u001b[0m  0.8314\n",
            "     12        \u001b[36m0.4191\u001b[0m       0.8624        0.3765  0.8318\n",
            "     13        \u001b[36m0.4119\u001b[0m       0.8625        0.3731  0.8434\n",
            "     14        \u001b[36m0.4056\u001b[0m       \u001b[32m0.8752\u001b[0m        \u001b[35m0.3469\u001b[0m  0.8344\n",
            "     15        \u001b[36m0.4031\u001b[0m       \u001b[32m0.8759\u001b[0m        0.3475  0.8519\n",
            "     16        \u001b[36m0.3956\u001b[0m       0.8726        0.3496  0.8381\n",
            "     17        \u001b[36m0.3902\u001b[0m       \u001b[32m0.8789\u001b[0m        0.3469  0.8375\n",
            "     18        \u001b[36m0.3861\u001b[0m       0.8771        \u001b[35m0.3426\u001b[0m  0.8596\n",
            "     19        \u001b[36m0.3822\u001b[0m       0.8735        \u001b[35m0.3404\u001b[0m  0.8385\n",
            "     20        \u001b[36m0.3763\u001b[0m       \u001b[32m0.8800\u001b[0m        \u001b[35m0.3302\u001b[0m  0.8474\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=  17.4s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0894\u001b[0m       \u001b[32m0.7746\u001b[0m        \u001b[35m0.6059\u001b[0m  0.8372\n",
            "      2        \u001b[36m0.6478\u001b[0m       \u001b[32m0.8147\u001b[0m        \u001b[35m0.5139\u001b[0m  0.8321\n",
            "      3        \u001b[36m0.5722\u001b[0m       \u001b[32m0.8286\u001b[0m        \u001b[35m0.4678\u001b[0m  0.8272\n",
            "      4        \u001b[36m0.5428\u001b[0m       \u001b[32m0.8315\u001b[0m        \u001b[35m0.4505\u001b[0m  0.8299\n",
            "      5        \u001b[36m0.5145\u001b[0m       \u001b[32m0.8442\u001b[0m        \u001b[35m0.4170\u001b[0m  0.8143\n",
            "      6        \u001b[36m0.4940\u001b[0m       0.8333        0.4459  0.8225\n",
            "      7        \u001b[36m0.4811\u001b[0m       0.8396        0.4367  0.8396\n",
            "      8        \u001b[36m0.4762\u001b[0m       0.8394        0.4355  0.8386\n",
            "      9        \u001b[36m0.4689\u001b[0m       \u001b[32m0.8520\u001b[0m        \u001b[35m0.3951\u001b[0m  0.8440\n",
            "     10        \u001b[36m0.4530\u001b[0m       0.8494        0.4012  0.8660\n",
            "     11        \u001b[36m0.4512\u001b[0m       0.8505        0.3961  0.8574\n",
            "     12        \u001b[36m0.4410\u001b[0m       \u001b[32m0.8580\u001b[0m        \u001b[35m0.3805\u001b[0m  0.8329\n",
            "     13        \u001b[36m0.4387\u001b[0m       0.8570        0.3884  0.8308\n",
            "     14        \u001b[36m0.4379\u001b[0m       0.8568        0.3954  0.8464\n",
            "     15        \u001b[36m0.4364\u001b[0m       \u001b[32m0.8618\u001b[0m        \u001b[35m0.3798\u001b[0m  0.8315\n",
            "     16        \u001b[36m0.4289\u001b[0m       0.8594        0.3869  0.8303\n",
            "     17        0.4293       0.8489        0.4045  0.8340\n",
            "     18        \u001b[36m0.4288\u001b[0m       0.8602        \u001b[35m0.3695\u001b[0m  0.8372\n",
            "     19        \u001b[36m0.4225\u001b[0m       0.8581        0.3794  0.8238\n",
            "     20        0.4260       0.8591        0.3750  0.8340\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=  17.3s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0875\u001b[0m       \u001b[32m0.7849\u001b[0m        \u001b[35m0.5805\u001b[0m  0.8314\n",
            "      2        \u001b[36m0.6553\u001b[0m       \u001b[32m0.8290\u001b[0m        \u001b[35m0.4813\u001b[0m  0.8409\n",
            "      3        \u001b[36m0.5874\u001b[0m       0.8181        0.4871  0.8553\n",
            "      4        \u001b[36m0.5445\u001b[0m       \u001b[32m0.8445\u001b[0m        \u001b[35m0.4285\u001b[0m  0.8445\n",
            "      5        \u001b[36m0.5158\u001b[0m       0.8353        0.4585  0.8425\n",
            "      6        \u001b[36m0.4975\u001b[0m       \u001b[32m0.8496\u001b[0m        \u001b[35m0.4112\u001b[0m  0.8401\n",
            "      7        \u001b[36m0.4814\u001b[0m       0.8475        0.4138  0.8465\n",
            "      8        \u001b[36m0.4693\u001b[0m       \u001b[32m0.8652\u001b[0m        \u001b[35m0.3794\u001b[0m  0.8404\n",
            "      9        \u001b[36m0.4631\u001b[0m       0.8619        \u001b[35m0.3677\u001b[0m  0.8395\n",
            "     10        \u001b[36m0.4565\u001b[0m       0.8611        0.3846  0.8351\n",
            "     11        \u001b[36m0.4488\u001b[0m       \u001b[32m0.8676\u001b[0m        \u001b[35m0.3673\u001b[0m  0.8331\n",
            "     12        \u001b[36m0.4401\u001b[0m       0.8665        \u001b[35m0.3592\u001b[0m  0.8383\n",
            "     13        \u001b[36m0.4401\u001b[0m       \u001b[32m0.8711\u001b[0m        0.3654  0.8337\n",
            "     14        \u001b[36m0.4381\u001b[0m       0.8682        0.3708  0.8425\n",
            "     15        0.4383       0.8578        0.3881  0.8489\n",
            "     16        \u001b[36m0.4291\u001b[0m       0.8608        0.3752  0.8747\n",
            "     17        \u001b[36m0.4280\u001b[0m       \u001b[32m0.8714\u001b[0m        \u001b[35m0.3545\u001b[0m  0.8488\n",
            "     18        \u001b[36m0.4247\u001b[0m       0.8638        0.3644  0.8408\n",
            "     19        \u001b[36m0.4242\u001b[0m       \u001b[32m0.8721\u001b[0m        \u001b[35m0.3533\u001b[0m  0.8332\n",
            "     20        \u001b[36m0.4227\u001b[0m       0.8562        0.3925  0.8497\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=  17.4s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0962\u001b[0m       \u001b[32m0.7760\u001b[0m        \u001b[35m0.5948\u001b[0m  0.8417\n",
            "      2        \u001b[36m0.6544\u001b[0m       \u001b[32m0.7950\u001b[0m        \u001b[35m0.5351\u001b[0m  0.8405\n",
            "      3        \u001b[36m0.5838\u001b[0m       \u001b[32m0.8425\u001b[0m        \u001b[35m0.4445\u001b[0m  0.8293\n",
            "      4        \u001b[36m0.5394\u001b[0m       0.8374        \u001b[35m0.4432\u001b[0m  0.8324\n",
            "      5        \u001b[36m0.5179\u001b[0m       \u001b[32m0.8539\u001b[0m        \u001b[35m0.4074\u001b[0m  0.8299\n",
            "      6        \u001b[36m0.4964\u001b[0m       0.8536        \u001b[35m0.3987\u001b[0m  0.8688\n",
            "      7        \u001b[36m0.4825\u001b[0m       0.8461        0.4091  0.8420\n",
            "      8        \u001b[36m0.4738\u001b[0m       0.8528        0.4022  0.8447\n",
            "      9        \u001b[36m0.4647\u001b[0m       0.8478        0.4025  0.9055\n",
            "     10        \u001b[36m0.4567\u001b[0m       \u001b[32m0.8614\u001b[0m        \u001b[35m0.3896\u001b[0m  0.8536\n",
            "     11        \u001b[36m0.4517\u001b[0m       \u001b[32m0.8646\u001b[0m        \u001b[35m0.3742\u001b[0m  0.8392\n",
            "     12        \u001b[36m0.4465\u001b[0m       \u001b[32m0.8661\u001b[0m        0.3745  0.8301\n",
            "     13        \u001b[36m0.4424\u001b[0m       \u001b[32m0.8684\u001b[0m        \u001b[35m0.3626\u001b[0m  0.8366\n",
            "     14        \u001b[36m0.4411\u001b[0m       \u001b[32m0.8694\u001b[0m        0.3642  0.8459\n",
            "     15        \u001b[36m0.4325\u001b[0m       \u001b[32m0.8719\u001b[0m        \u001b[35m0.3591\u001b[0m  0.8581\n",
            "     16        \u001b[36m0.4297\u001b[0m       0.8678        0.3697  0.8479\n",
            "     17        \u001b[36m0.4258\u001b[0m       0.8690        0.3631  0.8490\n",
            "     18        \u001b[36m0.4228\u001b[0m       \u001b[32m0.8721\u001b[0m        0.3631  0.8289\n",
            "     19        0.4253       0.8701        0.3642  0.8160\n",
            "     20        \u001b[36m0.4195\u001b[0m       \u001b[32m0.8748\u001b[0m        \u001b[35m0.3487\u001b[0m  0.8248\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=  17.4s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0360\u001b[0m       \u001b[32m0.7752\u001b[0m        \u001b[35m0.6231\u001b[0m  0.8648\n",
            "      2        \u001b[36m0.7735\u001b[0m       \u001b[32m0.7770\u001b[0m        \u001b[35m0.6111\u001b[0m  0.8633\n",
            "      3        \u001b[36m0.7526\u001b[0m       \u001b[32m0.8033\u001b[0m        \u001b[35m0.5480\u001b[0m  0.8363\n",
            "      4        \u001b[36m0.7370\u001b[0m       0.7556        0.6419  0.8309\n",
            "      5        \u001b[36m0.7315\u001b[0m       0.7575        0.5615  0.8404\n",
            "      6        \u001b[36m0.7057\u001b[0m       \u001b[32m0.8104\u001b[0m        \u001b[35m0.5301\u001b[0m  0.8338\n",
            "      7        \u001b[36m0.6793\u001b[0m       0.7966        0.5316  0.8157\n",
            "      8        \u001b[36m0.6783\u001b[0m       0.7614        0.5902  0.8317\n",
            "      9        0.7098       \u001b[32m0.8170\u001b[0m        0.5344  0.8371\n",
            "     10        0.6854       \u001b[32m0.8203\u001b[0m        0.5371  0.8324\n",
            "     11        \u001b[36m0.6716\u001b[0m       0.8041        0.5499  0.8217\n",
            "     12        0.6760       0.7899        0.5486  0.8271\n",
            "     13        0.6735       0.8195        \u001b[35m0.5076\u001b[0m  0.8222\n",
            "     14        \u001b[36m0.6693\u001b[0m       0.7934        0.5369  0.8309\n",
            "     15        \u001b[36m0.6679\u001b[0m       0.7996        0.5132  0.8658\n",
            "     16        \u001b[36m0.6473\u001b[0m       \u001b[32m0.8277\u001b[0m        0.5337  0.8431\n",
            "     17        0.6569       0.8209        0.5276  0.8458\n",
            "     18        0.6581       0.8010        0.5412  0.8431\n",
            "     19        0.6652       0.8175        0.5186  0.8452\n",
            "     20        0.6731       0.8077        0.5242  0.8433\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=  17.3s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0481\u001b[0m       \u001b[32m0.7674\u001b[0m        \u001b[35m0.6253\u001b[0m  0.8267\n",
            "      2        \u001b[36m0.7794\u001b[0m       0.7381        \u001b[35m0.6111\u001b[0m  0.8339\n",
            "      3        \u001b[36m0.7586\u001b[0m       \u001b[32m0.7835\u001b[0m        \u001b[35m0.5926\u001b[0m  0.8295\n",
            "      4        \u001b[36m0.7291\u001b[0m       \u001b[32m0.7907\u001b[0m        \u001b[35m0.5893\u001b[0m  0.8445\n",
            "      5        \u001b[36m0.7184\u001b[0m       \u001b[32m0.7944\u001b[0m        \u001b[35m0.5729\u001b[0m  0.8359\n",
            "      6        \u001b[36m0.7112\u001b[0m       \u001b[32m0.8026\u001b[0m        \u001b[35m0.5362\u001b[0m  0.8437\n",
            "      7        \u001b[36m0.7036\u001b[0m       0.7729        0.5445  0.8441\n",
            "      8        \u001b[36m0.6820\u001b[0m       0.8021        \u001b[35m0.5343\u001b[0m  0.8510\n",
            "      9        \u001b[36m0.6771\u001b[0m       \u001b[32m0.8047\u001b[0m        0.5921  0.8377\n",
            "     10        0.6844       0.7859        0.5669  0.8587\n",
            "     11        \u001b[36m0.6751\u001b[0m       0.8045        0.5383  0.8312\n",
            "     12        0.6847       0.7946        0.5685  0.8390\n",
            "     13        0.6912       \u001b[32m0.8133\u001b[0m        \u001b[35m0.5321\u001b[0m  0.8405\n",
            "     14        \u001b[36m0.6706\u001b[0m       0.7983        0.5464  0.8257\n",
            "     15        \u001b[36m0.6675\u001b[0m       0.8105        \u001b[35m0.5116\u001b[0m  0.8162\n",
            "     16        0.6714       0.8010        0.5518  0.8410\n",
            "     17        0.6694       0.7980        0.5489  0.8374\n",
            "     18        \u001b[36m0.6574\u001b[0m       \u001b[32m0.8234\u001b[0m        0.5362  0.8359\n",
            "     19        \u001b[36m0.6465\u001b[0m       \u001b[32m0.8354\u001b[0m        0.5119  0.8253\n",
            "     20        \u001b[36m0.6349\u001b[0m       0.8109        0.5202  0.8458\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=  17.3s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0270\u001b[0m       \u001b[32m0.7579\u001b[0m        \u001b[35m0.6056\u001b[0m  0.8224\n",
            "      2        \u001b[36m0.7852\u001b[0m       \u001b[32m0.8180\u001b[0m        \u001b[35m0.5690\u001b[0m  0.8436\n",
            "      3        \u001b[36m0.7673\u001b[0m       0.7776        0.6110  0.8330\n",
            "      4        \u001b[36m0.7549\u001b[0m       0.7951        \u001b[35m0.5686\u001b[0m  0.8402\n",
            "      5        \u001b[36m0.7378\u001b[0m       0.8081        \u001b[35m0.5494\u001b[0m  0.8331\n",
            "      6        \u001b[36m0.7216\u001b[0m       0.7869        0.5951  0.8362\n",
            "      7        \u001b[36m0.7102\u001b[0m       0.7955        \u001b[35m0.5191\u001b[0m  0.8279\n",
            "      8        \u001b[36m0.6860\u001b[0m       0.7883        0.5434  0.8148\n",
            "      9        \u001b[36m0.6855\u001b[0m       0.8117        \u001b[35m0.4968\u001b[0m  0.8442\n",
            "     10        \u001b[36m0.6832\u001b[0m       \u001b[32m0.8231\u001b[0m        0.5245  0.8319\n",
            "     11        \u001b[36m0.6758\u001b[0m       0.8097        0.5399  0.8253\n",
            "     12        0.7012       0.8170        0.5360  0.8340\n",
            "     13        0.6768       0.8186        0.5320  0.8434\n",
            "     14        0.6891       0.8006        0.5462  0.8396\n",
            "     15        0.6856       0.7974        0.5425  0.8255\n",
            "     16        0.7016       \u001b[32m0.8291\u001b[0m        0.5443  0.8502\n",
            "     17        \u001b[36m0.6720\u001b[0m       0.8096        0.5849  0.8368\n",
            "     18        \u001b[36m0.6593\u001b[0m       \u001b[32m0.8416\u001b[0m        \u001b[35m0.4729\u001b[0m  0.8546\n",
            "     19        \u001b[36m0.6556\u001b[0m       0.8084        0.5269  0.8503\n",
            "     20        0.6655       0.7671        0.5439  0.8332\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=  17.3s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0511\u001b[0m       \u001b[32m0.7650\u001b[0m        \u001b[35m0.6323\u001b[0m  0.8327\n",
            "      2        \u001b[36m0.7815\u001b[0m       0.7375        \u001b[35m0.6027\u001b[0m  0.8218\n",
            "      3        \u001b[36m0.7668\u001b[0m       0.7310        0.6757  0.8399\n",
            "      4        \u001b[36m0.7528\u001b[0m       \u001b[32m0.7867\u001b[0m        \u001b[35m0.5697\u001b[0m  0.8397\n",
            "      5        \u001b[36m0.7382\u001b[0m       \u001b[32m0.7963\u001b[0m        \u001b[35m0.5616\u001b[0m  0.8234\n",
            "      6        \u001b[36m0.7334\u001b[0m       0.7839        0.5858  0.8404\n",
            "      7        0.7381       0.7859        0.5870  0.8211\n",
            "      8        \u001b[36m0.7260\u001b[0m       \u001b[32m0.8033\u001b[0m        \u001b[35m0.5299\u001b[0m  0.8337\n",
            "      9        0.7388       0.7975        0.5397  0.8285\n",
            "     10        0.7490       0.7937        0.5791  0.8520\n",
            "     11        0.7319       0.7919        0.5797  0.8427\n",
            "     12        0.7288       \u001b[32m0.8124\u001b[0m        0.5395  0.8553\n",
            "     13        0.7321       0.7889        0.5762  0.8460\n",
            "     14        0.7478       0.7906        0.5590  0.8491\n",
            "     15        0.7313       0.7906        0.5545  0.8368\n",
            "     16        0.7419       0.7985        0.5567  0.8354\n",
            "     17        0.7717       0.7381        0.6240  0.8554\n",
            "     18        0.7669       0.8011        0.5904  0.8375\n",
            "     19        0.7626       0.8116        0.5865  0.8594\n",
            "     20        0.7723       0.7782        0.5879  0.8417\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=  17.4s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0501\u001b[0m       \u001b[32m0.7810\u001b[0m        \u001b[35m0.5970\u001b[0m  0.8382\n",
            "      2        \u001b[36m0.7847\u001b[0m       0.7662        \u001b[35m0.5869\u001b[0m  0.8227\n",
            "      3        \u001b[36m0.7510\u001b[0m       0.7441        0.6090  0.8503\n",
            "      4        0.7519       \u001b[32m0.7939\u001b[0m        \u001b[35m0.5571\u001b[0m  0.8365\n",
            "      5        0.7918       0.7434        0.5987  0.8550\n",
            "      6        0.7708       0.7368        0.5977  0.8333\n",
            "      7        \u001b[36m0.7466\u001b[0m       \u001b[32m0.8034\u001b[0m        \u001b[35m0.5497\u001b[0m  0.8433\n",
            "      8        0.7571       0.7461        0.6292  0.8531\n",
            "      9        0.7949       0.7321        0.6569  0.8367\n",
            "     10        0.7907       0.7330        0.6310  0.8322\n",
            "     11        0.7839       0.7782        0.5798  0.8461\n",
            "     12        0.7589       0.7579        0.6053  0.8389\n",
            "     13        \u001b[36m0.7458\u001b[0m       0.8006        \u001b[35m0.5442\u001b[0m  0.8351\n",
            "     14        0.7461       \u001b[32m0.8079\u001b[0m        0.5601  0.8622\n",
            "     15        0.7657       0.7579        0.5899  0.8244\n",
            "     16        0.7631       \u001b[32m0.8225\u001b[0m        0.5674  0.8372\n",
            "     17        0.7589       0.7966        0.5765  0.8518\n",
            "     18        0.7475       0.7986        0.5520  0.8325\n",
            "     19        \u001b[36m0.7404\u001b[0m       0.8141        0.5857  0.8515\n",
            "     20        0.7734       0.7505        0.6028  0.8360\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=  17.4s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.0241\u001b[0m       \u001b[32m0.7365\u001b[0m        \u001b[35m0.6168\u001b[0m  0.8424\n",
            "      2        \u001b[36m0.7705\u001b[0m       \u001b[32m0.8004\u001b[0m        \u001b[35m0.5289\u001b[0m  0.8393\n",
            "      3        \u001b[36m0.7636\u001b[0m       0.7970        0.5660  0.8251\n",
            "      4        \u001b[36m0.7384\u001b[0m       0.7875        0.5729  0.8469\n",
            "      5        \u001b[36m0.7343\u001b[0m       0.7943        0.5326  0.8575\n",
            "      6        \u001b[36m0.7340\u001b[0m       0.7905        0.5440  0.8372\n",
            "      7        0.7432       0.7934        0.5678  0.8397\n",
            "      8        0.7524       \u001b[32m0.8254\u001b[0m        0.5402  0.8389\n",
            "      9        0.7572       0.7963        0.5684  0.8323\n",
            "     10        0.7429       0.8071        0.6103  0.8272\n",
            "     11        0.7581       0.8101        0.5503  0.8355\n",
            "     12        0.7728       0.7955        0.6183  0.8291\n",
            "     13        0.7711       0.7873        0.5860  0.8419\n",
            "     14        0.7443       0.8217        0.5498  0.8287\n",
            "     15        0.7769       0.8001        0.5831  0.8401\n",
            "     16        0.7741       0.7856        0.5979  0.8395\n",
            "     17        0.7625       0.8035        0.5885  0.8417\n",
            "     18        0.7612       0.7875        0.5866  0.8517\n",
            "     19        0.7550       0.8084        0.5559  0.8367\n",
            "     20        0.7773       0.7880        0.5921  0.8366\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.5, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=  17.3s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1715\u001b[0m       \u001b[32m0.7446\u001b[0m        \u001b[35m0.6454\u001b[0m  0.8366\n",
            "      2        \u001b[36m0.7476\u001b[0m       \u001b[32m0.7798\u001b[0m        \u001b[35m0.5512\u001b[0m  0.8381\n",
            "      3        \u001b[36m0.6600\u001b[0m       \u001b[32m0.8004\u001b[0m        \u001b[35m0.5067\u001b[0m  0.8280\n",
            "      4        \u001b[36m0.6204\u001b[0m       0.8004        \u001b[35m0.4946\u001b[0m  0.8696\n",
            "      5        \u001b[36m0.5933\u001b[0m       \u001b[32m0.8291\u001b[0m        \u001b[35m0.4600\u001b[0m  0.8693\n",
            "      6        \u001b[36m0.5735\u001b[0m       0.8266        0.4676  0.8492\n",
            "      7        \u001b[36m0.5482\u001b[0m       0.8273        \u001b[35m0.4388\u001b[0m  0.8269\n",
            "      8        \u001b[36m0.5334\u001b[0m       \u001b[32m0.8420\u001b[0m        \u001b[35m0.4121\u001b[0m  0.8393\n",
            "      9        \u001b[36m0.5234\u001b[0m       \u001b[32m0.8472\u001b[0m        0.4157  0.8607\n",
            "     10        \u001b[36m0.5079\u001b[0m       0.8375        0.4245  0.8518\n",
            "     11        \u001b[36m0.4998\u001b[0m       \u001b[32m0.8506\u001b[0m        \u001b[35m0.4044\u001b[0m  0.8379\n",
            "     12        \u001b[36m0.4856\u001b[0m       \u001b[32m0.8515\u001b[0m        \u001b[35m0.3974\u001b[0m  0.8259\n",
            "     13        \u001b[36m0.4798\u001b[0m       0.8486        0.4015  0.8398\n",
            "     14        \u001b[36m0.4757\u001b[0m       0.8502        \u001b[35m0.3960\u001b[0m  0.8236\n",
            "     15        \u001b[36m0.4701\u001b[0m       \u001b[32m0.8560\u001b[0m        \u001b[35m0.3885\u001b[0m  0.8200\n",
            "     16        \u001b[36m0.4644\u001b[0m       0.8542        \u001b[35m0.3813\u001b[0m  0.8171\n",
            "     17        \u001b[36m0.4580\u001b[0m       0.8471        0.4057  0.8370\n",
            "     18        \u001b[36m0.4526\u001b[0m       \u001b[32m0.8599\u001b[0m        \u001b[35m0.3757\u001b[0m  0.8348\n",
            "     19        \u001b[36m0.4511\u001b[0m       0.8551        0.3796  0.8518\n",
            "     20        \u001b[36m0.4479\u001b[0m       \u001b[32m0.8615\u001b[0m        \u001b[35m0.3742\u001b[0m  0.8515\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=  17.4s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1827\u001b[0m       \u001b[32m0.7589\u001b[0m        \u001b[35m0.6398\u001b[0m  0.8329\n",
            "      2        \u001b[36m0.7516\u001b[0m       \u001b[32m0.8030\u001b[0m        \u001b[35m0.5247\u001b[0m  0.8506\n",
            "      3        \u001b[36m0.6682\u001b[0m       \u001b[32m0.8147\u001b[0m        \u001b[35m0.4816\u001b[0m  0.8524\n",
            "      4        \u001b[36m0.6304\u001b[0m       \u001b[32m0.8315\u001b[0m        0.4877  0.8310\n",
            "      5        \u001b[36m0.5903\u001b[0m       \u001b[32m0.8427\u001b[0m        \u001b[35m0.4346\u001b[0m  0.8305\n",
            "      6        \u001b[36m0.5722\u001b[0m       \u001b[32m0.8456\u001b[0m        \u001b[35m0.4187\u001b[0m  0.8396\n",
            "      7        \u001b[36m0.5483\u001b[0m       \u001b[32m0.8498\u001b[0m        0.4249  0.8343\n",
            "      8        \u001b[36m0.5310\u001b[0m       0.8460        \u001b[35m0.4148\u001b[0m  0.8273\n",
            "      9        \u001b[36m0.5152\u001b[0m       \u001b[32m0.8559\u001b[0m        \u001b[35m0.3932\u001b[0m  0.8373\n",
            "     10        \u001b[36m0.5095\u001b[0m       0.8540        0.3936  0.8264\n",
            "     11        \u001b[36m0.5004\u001b[0m       \u001b[32m0.8644\u001b[0m        \u001b[35m0.3753\u001b[0m  0.8432\n",
            "     12        \u001b[36m0.4893\u001b[0m       0.8575        0.3883  0.8498\n",
            "     13        \u001b[36m0.4796\u001b[0m       0.8479        0.4011  0.8372\n",
            "     14        \u001b[36m0.4779\u001b[0m       0.8558        0.3930  0.8411\n",
            "     15        \u001b[36m0.4656\u001b[0m       0.8590        0.3937  0.8710\n",
            "     16        \u001b[36m0.4645\u001b[0m       \u001b[32m0.8681\u001b[0m        \u001b[35m0.3664\u001b[0m  0.8907\n",
            "     17        \u001b[36m0.4591\u001b[0m       0.8648        0.3768  0.8781\n",
            "     18        \u001b[36m0.4529\u001b[0m       \u001b[32m0.8718\u001b[0m        \u001b[35m0.3645\u001b[0m  0.8481\n",
            "     19        \u001b[36m0.4471\u001b[0m       0.8601        0.3790  0.8490\n",
            "     20        0.4485       0.8666        0.3731  0.8635\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=  17.5s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1799\u001b[0m       \u001b[32m0.7385\u001b[0m        \u001b[35m0.6462\u001b[0m  0.8404\n",
            "      2        \u001b[36m0.7405\u001b[0m       \u001b[32m0.8017\u001b[0m        \u001b[35m0.5214\u001b[0m  0.8472\n",
            "      3        \u001b[36m0.6614\u001b[0m       \u001b[32m0.8275\u001b[0m        \u001b[35m0.4911\u001b[0m  0.8504\n",
            "      4        \u001b[36m0.6084\u001b[0m       \u001b[32m0.8334\u001b[0m        \u001b[35m0.4543\u001b[0m  0.8469\n",
            "      5        \u001b[36m0.5803\u001b[0m       \u001b[32m0.8391\u001b[0m        \u001b[35m0.4330\u001b[0m  0.8547\n",
            "      6        \u001b[36m0.5564\u001b[0m       \u001b[32m0.8421\u001b[0m        \u001b[35m0.4316\u001b[0m  0.8501\n",
            "      7        \u001b[36m0.5390\u001b[0m       \u001b[32m0.8492\u001b[0m        \u001b[35m0.4110\u001b[0m  0.8743\n",
            "      8        \u001b[36m0.5275\u001b[0m       0.8427        0.4115  0.8570\n",
            "      9        \u001b[36m0.5137\u001b[0m       0.8481        \u001b[35m0.4081\u001b[0m  0.8542\n",
            "     10        \u001b[36m0.5068\u001b[0m       \u001b[32m0.8590\u001b[0m        \u001b[35m0.3971\u001b[0m  0.8338\n",
            "     11        \u001b[36m0.4931\u001b[0m       \u001b[32m0.8619\u001b[0m        \u001b[35m0.3814\u001b[0m  0.8385\n",
            "     12        \u001b[36m0.4819\u001b[0m       0.8606        0.4016  0.8329\n",
            "     13        \u001b[36m0.4801\u001b[0m       \u001b[32m0.8629\u001b[0m        0.3840  0.8372\n",
            "     14        \u001b[36m0.4688\u001b[0m       \u001b[32m0.8691\u001b[0m        \u001b[35m0.3724\u001b[0m  0.8385\n",
            "     15        0.4705       0.8678        0.3749  0.8387\n",
            "     16        \u001b[36m0.4562\u001b[0m       0.8645        0.3848  0.8278\n",
            "     17        0.4582       0.8629        0.3730  0.8360\n",
            "     18        0.4578       \u001b[32m0.8696\u001b[0m        \u001b[35m0.3646\u001b[0m  0.8318\n",
            "     19        \u001b[36m0.4447\u001b[0m       \u001b[32m0.8716\u001b[0m        \u001b[35m0.3596\u001b[0m  0.8402\n",
            "     20        \u001b[36m0.4385\u001b[0m       0.8681        0.3642  0.8417\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.0001; total time=  17.5s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1677\u001b[0m       \u001b[32m0.7226\u001b[0m        \u001b[35m0.6678\u001b[0m  0.8336\n",
            "      2        \u001b[36m0.7330\u001b[0m       \u001b[32m0.7946\u001b[0m        \u001b[35m0.5531\u001b[0m  0.8464\n",
            "      3        \u001b[36m0.6503\u001b[0m       \u001b[32m0.8004\u001b[0m        \u001b[35m0.5076\u001b[0m  0.8389\n",
            "      4        \u001b[36m0.6194\u001b[0m       \u001b[32m0.8229\u001b[0m        \u001b[35m0.4737\u001b[0m  0.8381\n",
            "      5        \u001b[36m0.5893\u001b[0m       \u001b[32m0.8294\u001b[0m        0.4741  0.8305\n",
            "      6        \u001b[36m0.5678\u001b[0m       \u001b[32m0.8371\u001b[0m        \u001b[35m0.4376\u001b[0m  0.8618\n",
            "      7        \u001b[36m0.5513\u001b[0m       0.8345        0.4484  0.8440\n",
            "      8        \u001b[36m0.5351\u001b[0m       \u001b[32m0.8427\u001b[0m        \u001b[35m0.4261\u001b[0m  0.8565\n",
            "      9        \u001b[36m0.5259\u001b[0m       \u001b[32m0.8464\u001b[0m        \u001b[35m0.4209\u001b[0m  0.8450\n",
            "     10        \u001b[36m0.5202\u001b[0m       0.8436        0.4253  0.8363\n",
            "     11        \u001b[36m0.5120\u001b[0m       \u001b[32m0.8519\u001b[0m        \u001b[35m0.4120\u001b[0m  0.8394\n",
            "     12        0.5165       0.8504        \u001b[35m0.4040\u001b[0m  0.8527\n",
            "     13        \u001b[36m0.5011\u001b[0m       \u001b[32m0.8520\u001b[0m        \u001b[35m0.4003\u001b[0m  0.8796\n",
            "     14        \u001b[36m0.4998\u001b[0m       0.8444        0.4057  0.9149\n",
            "     15        \u001b[36m0.4972\u001b[0m       \u001b[32m0.8572\u001b[0m        \u001b[35m0.3879\u001b[0m  0.9009\n",
            "     16        \u001b[36m0.4884\u001b[0m       0.8548        0.3970  0.8883\n",
            "     17        0.4902       0.8526        0.3928  0.8678\n",
            "     18        \u001b[36m0.4859\u001b[0m       \u001b[32m0.8574\u001b[0m        \u001b[35m0.3839\u001b[0m  0.8943\n",
            "     19        0.4874       0.8344        0.4446  0.8764\n",
            "     20        \u001b[36m0.4845\u001b[0m       0.8554        0.3926  0.8692\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=  17.8s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1937\u001b[0m       \u001b[32m0.7619\u001b[0m        \u001b[35m0.6461\u001b[0m  0.8689\n",
            "      2        \u001b[36m0.7452\u001b[0m       \u001b[32m0.7990\u001b[0m        \u001b[35m0.5290\u001b[0m  0.8483\n",
            "      3        \u001b[36m0.6647\u001b[0m       \u001b[32m0.8276\u001b[0m        \u001b[35m0.4803\u001b[0m  0.8590\n",
            "      4        \u001b[36m0.6166\u001b[0m       \u001b[32m0.8346\u001b[0m        \u001b[35m0.4650\u001b[0m  0.8509\n",
            "      5        \u001b[36m0.5883\u001b[0m       \u001b[32m0.8424\u001b[0m        \u001b[35m0.4484\u001b[0m  0.8706\n",
            "      6        \u001b[36m0.5727\u001b[0m       \u001b[32m0.8425\u001b[0m        \u001b[35m0.4401\u001b[0m  0.8737\n",
            "      7        \u001b[36m0.5561\u001b[0m       \u001b[32m0.8449\u001b[0m        \u001b[35m0.4385\u001b[0m  0.8828\n",
            "      8        \u001b[36m0.5373\u001b[0m       \u001b[32m0.8481\u001b[0m        \u001b[35m0.4114\u001b[0m  0.8610\n",
            "      9        \u001b[36m0.5284\u001b[0m       0.8410        0.4432  0.8473\n",
            "     10        \u001b[36m0.5223\u001b[0m       \u001b[32m0.8499\u001b[0m        \u001b[35m0.4086\u001b[0m  0.8524\n",
            "     11        \u001b[36m0.5132\u001b[0m       \u001b[32m0.8565\u001b[0m        \u001b[35m0.3975\u001b[0m  0.8585\n",
            "     12        \u001b[36m0.5112\u001b[0m       \u001b[32m0.8592\u001b[0m        \u001b[35m0.3937\u001b[0m  0.8537\n",
            "     13        \u001b[36m0.5034\u001b[0m       0.8592        \u001b[35m0.3931\u001b[0m  0.8674\n",
            "     14        \u001b[36m0.5002\u001b[0m       0.8556        \u001b[35m0.3914\u001b[0m  0.8593\n",
            "     15        \u001b[36m0.4998\u001b[0m       0.8576        0.3979  0.8524\n",
            "     16        \u001b[36m0.4985\u001b[0m       0.8554        0.3949  0.8543\n",
            "     17        \u001b[36m0.4874\u001b[0m       0.8578        \u001b[35m0.3862\u001b[0m  0.8487\n",
            "     18        0.4877       \u001b[32m0.8614\u001b[0m        \u001b[35m0.3838\u001b[0m  0.8504\n",
            "     19        \u001b[36m0.4827\u001b[0m       \u001b[32m0.8629\u001b[0m        \u001b[35m0.3830\u001b[0m  0.8750\n",
            "     20        0.4868       0.8618        0.3836  0.8596\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=  17.8s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1904\u001b[0m       \u001b[32m0.7630\u001b[0m        \u001b[35m0.6425\u001b[0m  0.8536\n",
            "      2        \u001b[36m0.7465\u001b[0m       \u001b[32m0.8044\u001b[0m        \u001b[35m0.5526\u001b[0m  0.8424\n",
            "      3        \u001b[36m0.6669\u001b[0m       \u001b[32m0.8247\u001b[0m        \u001b[35m0.4867\u001b[0m  0.8398\n",
            "      4        \u001b[36m0.6208\u001b[0m       0.8237        \u001b[35m0.4842\u001b[0m  0.8455\n",
            "      5        \u001b[36m0.5898\u001b[0m       \u001b[32m0.8390\u001b[0m        \u001b[35m0.4419\u001b[0m  0.8530\n",
            "      6        \u001b[36m0.5689\u001b[0m       \u001b[32m0.8403\u001b[0m        0.4485  0.8572\n",
            "      7        \u001b[36m0.5502\u001b[0m       \u001b[32m0.8462\u001b[0m        \u001b[35m0.4162\u001b[0m  0.8499\n",
            "      8        \u001b[36m0.5355\u001b[0m       0.8458        0.4401  0.8513\n",
            "      9        \u001b[36m0.5256\u001b[0m       \u001b[32m0.8474\u001b[0m        \u001b[35m0.4103\u001b[0m  0.8485\n",
            "     10        \u001b[36m0.5159\u001b[0m       \u001b[32m0.8510\u001b[0m        0.4184  0.8434\n",
            "     11        0.5198       0.8466        \u001b[35m0.4069\u001b[0m  0.8612\n",
            "     12        \u001b[36m0.5047\u001b[0m       \u001b[32m0.8579\u001b[0m        \u001b[35m0.3969\u001b[0m  0.8775\n",
            "     13        \u001b[36m0.4998\u001b[0m       0.8529        0.4073  0.8792\n",
            "     14        \u001b[36m0.4947\u001b[0m       \u001b[32m0.8595\u001b[0m        \u001b[35m0.3858\u001b[0m  0.8857\n",
            "     15        \u001b[36m0.4901\u001b[0m       \u001b[32m0.8606\u001b[0m        \u001b[35m0.3838\u001b[0m  0.8544\n",
            "     16        \u001b[36m0.4894\u001b[0m       0.8600        0.3967  0.8578\n",
            "     17        \u001b[36m0.4855\u001b[0m       0.8602        0.3853  0.8576\n",
            "     18        \u001b[36m0.4821\u001b[0m       0.8606        \u001b[35m0.3775\u001b[0m  0.8660\n",
            "     19        \u001b[36m0.4804\u001b[0m       0.8569        0.3866  0.8641\n",
            "     20        \u001b[36m0.4725\u001b[0m       0.8595        0.3892  0.8597\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.7, optimizer__weight_decay=0.001; total time=  17.7s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.2040\u001b[0m       \u001b[32m0.6923\u001b[0m        \u001b[35m0.8208\u001b[0m  0.8580\n",
            "      2        \u001b[36m0.9911\u001b[0m       0.6741        \u001b[35m0.7190\u001b[0m  0.8372\n",
            "      3        \u001b[36m0.9892\u001b[0m       \u001b[32m0.7066\u001b[0m        \u001b[35m0.6810\u001b[0m  0.8321\n",
            "      4        \u001b[36m0.9817\u001b[0m       \u001b[32m0.7291\u001b[0m        0.6835  0.8322\n",
            "      5        \u001b[36m0.9298\u001b[0m       0.7219        \u001b[35m0.6672\u001b[0m  0.8345\n",
            "      6        0.9330       0.7266        0.7160  0.8545\n",
            "      7        0.9444       \u001b[32m0.7522\u001b[0m        \u001b[35m0.6561\u001b[0m  0.8412\n",
            "      8        0.9431       0.7316        0.6568  0.8524\n",
            "      9        0.9361       0.7360        0.6590  0.8396\n",
            "     10        0.9702       0.7231        0.7113  0.8487\n",
            "     11        0.9935       0.7345        0.7011  0.8377\n",
            "     12        0.9894       0.7294        0.6853  0.8437\n",
            "     13        1.0160       0.7279        0.6823  0.8336\n",
            "     14        1.0193       0.7234        0.6871  0.8212\n",
            "     15        1.0989       0.7248        0.7234  0.8155\n",
            "     16        1.1323       0.7151        0.7060  0.8202\n",
            "     17        1.2424       0.6911        0.7876  0.8250\n",
            "     18        1.2556       0.7121        0.7545  0.8528\n",
            "     19        1.3307       0.7100        0.7952  0.8603\n",
            "     20        1.3968       0.7140        0.7317  0.8682\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=  17.4s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.2172\u001b[0m       \u001b[32m0.7160\u001b[0m        \u001b[35m0.7292\u001b[0m  0.8932\n",
            "      2        \u001b[36m1.0172\u001b[0m       \u001b[32m0.7242\u001b[0m        \u001b[35m0.6774\u001b[0m  0.8374\n",
            "      3        \u001b[36m1.0065\u001b[0m       \u001b[32m0.7640\u001b[0m        \u001b[35m0.6622\u001b[0m  0.8638\n",
            "      4        \u001b[36m0.9807\u001b[0m       0.6995        0.6973  0.8631\n",
            "      5        0.9892       0.7047        0.7093  0.8500\n",
            "      6        1.0094       0.7173        0.6666  0.8458\n",
            "      7        0.9839       0.7378        \u001b[35m0.6333\u001b[0m  0.8608\n",
            "      8        1.0377       0.7200        0.7245  0.8793\n",
            "      9        1.0460       0.7316        0.7151  0.8377\n",
            "     10        1.0818       0.6542        0.7446  0.8301\n",
            "     11        1.0747       0.7119        0.7781  0.8331\n",
            "     12        1.0595       0.7154        0.7320  0.8570\n",
            "     13        1.1000       0.7292        0.7189  0.8284\n",
            "     14        1.1535       0.7139        0.8015  0.8573\n",
            "     15        1.1750       0.7073        0.7925  0.8453\n",
            "     16        1.2138       0.7016        0.7844  0.8547\n",
            "     17        1.2673       0.6552        0.8031  0.8461\n",
            "     18        1.3740       0.6761        0.9326  0.8553\n",
            "     19        1.4349       0.5799        1.1415  0.8630\n",
            "     20        1.5226       0.5503        1.1427  0.8206\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=  17.6s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.2087\u001b[0m       \u001b[32m0.7147\u001b[0m        \u001b[35m0.7640\u001b[0m  0.8268\n",
            "      2        \u001b[36m1.0271\u001b[0m       \u001b[32m0.7159\u001b[0m        \u001b[35m0.6852\u001b[0m  0.8359\n",
            "      3        \u001b[36m0.9851\u001b[0m       \u001b[32m0.7305\u001b[0m        \u001b[35m0.6789\u001b[0m  0.8380\n",
            "      4        \u001b[36m0.9520\u001b[0m       0.7189        0.7248  0.8436\n",
            "      5        0.9641       \u001b[32m0.7478\u001b[0m        0.6989  0.8280\n",
            "      6        \u001b[36m0.9471\u001b[0m       0.7382        \u001b[35m0.6724\u001b[0m  0.8272\n",
            "      7        0.9706       0.7279        \u001b[35m0.6630\u001b[0m  0.8837\n",
            "      8        0.9542       \u001b[32m0.7545\u001b[0m        \u001b[35m0.6343\u001b[0m  0.8592\n",
            "      9        0.9753       0.7255        0.6747  0.8460\n",
            "     10        1.0180       0.7191        0.7092  0.8332\n",
            "     11        1.0162       0.7348        0.6730  0.8268\n",
            "     12        1.0158       0.7304        0.7054  0.8448\n",
            "     13        1.0477       0.7258        0.7175  0.8273\n",
            "     14        1.1326       0.7205        0.7561  0.8376\n",
            "     15        1.1797       0.7110        0.8109  0.8393\n",
            "     16        1.2069       0.7190        0.7367  0.8549\n",
            "     17        1.2788       0.7046        0.7673  0.8447\n",
            "     18        1.2887       0.6300        0.8455  0.8370\n",
            "     19        1.3135       0.6827        0.8922  0.8359\n",
            "     20        1.4262       0.6028        0.9398  0.8398\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.0001; total time=  17.4s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.2011\u001b[0m       \u001b[32m0.7130\u001b[0m        \u001b[35m0.7412\u001b[0m  0.8357\n",
            "      2        \u001b[36m0.9678\u001b[0m       0.7064        \u001b[35m0.7065\u001b[0m  0.8628\n",
            "      3        \u001b[36m0.9452\u001b[0m       \u001b[32m0.7149\u001b[0m        0.7286  0.8354\n",
            "      4        0.9452       \u001b[32m0.7354\u001b[0m        \u001b[35m0.6729\u001b[0m  0.8404\n",
            "      5        0.9587       0.7258        0.6828  0.8234\n",
            "      6        \u001b[36m0.9280\u001b[0m       0.7288        \u001b[35m0.6558\u001b[0m  0.8513\n",
            "      7        \u001b[36m0.9100\u001b[0m       0.7296        0.6599  0.8236\n",
            "      8        \u001b[36m0.8861\u001b[0m       0.7308        \u001b[35m0.6328\u001b[0m  0.8340\n",
            "      9        0.9073       0.7232        0.6949  0.8337\n",
            "     10        0.9036       0.7179        0.6995  0.8320\n",
            "     11        0.9046       0.7251        0.6854  0.8213\n",
            "     12        0.9160       0.7262        0.7006  0.8325\n",
            "     13        0.9174       0.7288        0.6941  0.8191\n",
            "     14        0.9215       0.7296        0.6408  0.8412\n",
            "     15        0.9438       0.7256        0.6742  0.8299\n",
            "     16        0.9652       0.7264        0.7041  0.8397\n",
            "     17        0.9316       0.7352        0.6849  0.8263\n",
            "     18        0.9466       0.7299        0.6716  0.8346\n",
            "     19        0.9559       0.7300        0.6543  0.8396\n",
            "     20        0.9673       0.7224        0.6974  0.8358\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=  17.3s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1746\u001b[0m       \u001b[32m0.7221\u001b[0m        \u001b[35m0.7163\u001b[0m  0.8298\n",
            "      2        \u001b[36m0.9519\u001b[0m       \u001b[32m0.7280\u001b[0m        \u001b[35m0.6868\u001b[0m  0.8193\n",
            "      3        \u001b[36m0.9350\u001b[0m       0.7249        0.6943  0.8196\n",
            "      4        \u001b[36m0.9161\u001b[0m       0.7101        \u001b[35m0.6740\u001b[0m  0.8368\n",
            "      5        0.9186       \u001b[32m0.7286\u001b[0m        \u001b[35m0.6499\u001b[0m  0.8267\n",
            "      6        \u001b[36m0.8939\u001b[0m       \u001b[32m0.7421\u001b[0m        \u001b[35m0.6392\u001b[0m  0.8570\n",
            "      7        0.8958       0.7286        \u001b[35m0.6308\u001b[0m  0.8513\n",
            "      8        \u001b[36m0.8821\u001b[0m       0.7389        0.6607  0.8575\n",
            "      9        0.8983       0.7396        0.6712  0.8503\n",
            "     10        0.8978       0.7300        0.6510  0.8667\n",
            "     11        0.9076       0.7269        0.6357  0.8490\n",
            "     12        0.9064       0.7281        0.6698  0.8599\n",
            "     13        0.9059       0.7345        0.6382  0.8433\n",
            "     14        0.9196       0.7340        0.6782  0.8301\n",
            "     15        0.9435       \u001b[32m0.7500\u001b[0m        0.6690  0.8215\n",
            "     16        0.9665       0.7242        0.7342  0.8160\n",
            "     17        0.9596       \u001b[32m0.7524\u001b[0m        0.6504  0.8192\n",
            "     18        0.9402       0.7434        0.6668  0.8495\n",
            "     19        0.9478       0.7361        0.7092  0.8380\n",
            "     20        0.9464       0.7246        0.6965  0.8261\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=  17.3s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.1665\u001b[0m       \u001b[32m0.7236\u001b[0m        \u001b[35m0.6857\u001b[0m  0.8381\n",
            "      2        \u001b[36m0.9795\u001b[0m       \u001b[32m0.7308\u001b[0m        \u001b[35m0.6487\u001b[0m  0.8469\n",
            "      3        \u001b[36m0.9468\u001b[0m       0.7301        0.6542  0.8240\n",
            "      4        \u001b[36m0.9083\u001b[0m       0.7205        0.6753  0.8229\n",
            "      5        \u001b[36m0.9008\u001b[0m       0.7245        0.6811  0.8204\n",
            "      6        0.9016       \u001b[32m0.7834\u001b[0m        \u001b[35m0.6471\u001b[0m  0.8277\n",
            "      7        \u001b[36m0.8884\u001b[0m       0.7282        0.6597  0.8318\n",
            "      8        0.8927       0.7420        \u001b[35m0.6416\u001b[0m  0.8371\n",
            "      9        \u001b[36m0.8858\u001b[0m       0.7194        0.6707  0.8223\n",
            "     10        0.8981       0.7335        \u001b[35m0.6344\u001b[0m  0.8290\n",
            "     11        0.9013       0.7316        0.6460  0.8386\n",
            "     12        0.9081       0.7194        0.6408  0.8391\n",
            "     13        0.9334       0.7279        0.6875  0.8512\n",
            "     14        0.9426       0.7144        0.7101  0.8235\n",
            "     15        0.9173       0.7298        0.6638  0.8367\n",
            "     16        0.9331       0.7360        0.6912  0.8579\n",
            "     17        0.9461       0.7338        0.6589  0.8362\n",
            "     18        0.9520       0.7254        0.6750  0.8405\n",
            "     19        0.9476       0.7342        0.6679  0.8285\n",
            "     20        0.9451       0.7338        0.6703  0.8413\n",
            "[CV] END lr=0.1, max_epochs=20, module__dropout_rate=0.6, optimizer__momentum=0.9, optimizer__weight_decay=0.001; total time=  17.3s\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.9345\u001b[0m       \u001b[32m0.8053\u001b[0m        \u001b[35m0.5206\u001b[0m  1.6143\n",
            "      2        \u001b[36m0.5962\u001b[0m       \u001b[32m0.8297\u001b[0m        \u001b[35m0.4536\u001b[0m  1.6452\n",
            "      3        \u001b[36m0.5316\u001b[0m       \u001b[32m0.8517\u001b[0m        \u001b[35m0.4040\u001b[0m  1.6526\n",
            "      4        \u001b[36m0.4971\u001b[0m       \u001b[32m0.8528\u001b[0m        \u001b[35m0.3922\u001b[0m  1.6362\n",
            "      5        \u001b[36m0.4746\u001b[0m       \u001b[32m0.8608\u001b[0m        \u001b[35m0.3739\u001b[0m  1.6469\n",
            "      6        \u001b[36m0.4550\u001b[0m       0.8537        0.3843  1.6341\n",
            "      7        \u001b[36m0.4428\u001b[0m       \u001b[32m0.8642\u001b[0m        \u001b[35m0.3730\u001b[0m  1.6706\n",
            "      8        \u001b[36m0.4349\u001b[0m       0.8626        \u001b[35m0.3594\u001b[0m  1.6355\n",
            "      9        \u001b[36m0.4207\u001b[0m       \u001b[32m0.8678\u001b[0m        \u001b[35m0.3553\u001b[0m  1.6080\n",
            "     10        \u001b[36m0.4103\u001b[0m       \u001b[32m0.8748\u001b[0m        \u001b[35m0.3433\u001b[0m  1.6259\n",
            "     11        \u001b[36m0.4030\u001b[0m       0.8725        0.3470  1.6463\n",
            "     12        \u001b[36m0.3963\u001b[0m       0.8734        0.3442  1.6363\n",
            "     13        \u001b[36m0.3901\u001b[0m       0.8702        0.3507  1.6552\n",
            "     14        \u001b[36m0.3845\u001b[0m       0.8728        \u001b[35m0.3425\u001b[0m  1.6227\n",
            "     15        \u001b[36m0.3796\u001b[0m       \u001b[32m0.8795\u001b[0m        \u001b[35m0.3376\u001b[0m  1.6103\n",
            "     16        \u001b[36m0.3772\u001b[0m       0.8689        0.3511  1.5954\n",
            "     17        \u001b[36m0.3699\u001b[0m       \u001b[32m0.8805\u001b[0m        \u001b[35m0.3295\u001b[0m  1.6016\n",
            "     18        \u001b[36m0.3669\u001b[0m       \u001b[32m0.8819\u001b[0m        \u001b[35m0.3222\u001b[0m  1.6158\n",
            "     19        \u001b[36m0.3600\u001b[0m       0.8815        0.3236  1.6190\n",
            "     20        0.3622       \u001b[32m0.8840\u001b[0m        0.3250  1.6431\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3,\n",
              "             estimator=<class 'skorch.classifier.NeuralNetClassifier'>[uninitialized](\n",
              "  module=<class '__main__.MLP'>,\n",
              "),\n",
              "             param_grid={'lr': [0.01, 0.05, 0.1], 'max_epochs': [10, 20],\n",
              "                         'module__dropout_rate': [0.5, 0.6],\n",
              "                         'optimizer__momentum': [0.7, 0.9],\n",
              "                         'optimizer__weight_decay': [0.0001, 0.001]},\n",
              "             scoring='accuracy', verbose=2)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
              "             estimator=&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
              "  module=&lt;class &#x27;__main__.MLP&#x27;&gt;,\n",
              "),\n",
              "             param_grid={&#x27;lr&#x27;: [0.01, 0.05, 0.1], &#x27;max_epochs&#x27;: [10, 20],\n",
              "                         &#x27;module__dropout_rate&#x27;: [0.5, 0.6],\n",
              "                         &#x27;optimizer__momentum&#x27;: [0.7, 0.9],\n",
              "                         &#x27;optimizer__weight_decay&#x27;: [0.0001, 0.001]},\n",
              "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
              "             estimator=&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
              "  module=&lt;class &#x27;__main__.MLP&#x27;&gt;,\n",
              "),\n",
              "             param_grid={&#x27;lr&#x27;: [0.01, 0.05, 0.1], &#x27;max_epochs&#x27;: [10, 20],\n",
              "                         &#x27;module__dropout_rate&#x27;: [0.5, 0.6],\n",
              "                         &#x27;optimizer__momentum&#x27;: [0.7, 0.9],\n",
              "                         &#x27;optimizer__weight_decay&#x27;: [0.0001, 0.001]},\n",
              "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: NeuralNetClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
              "  module=&lt;class &#x27;__main__.MLP&#x27;&gt;,\n",
              ")</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NeuralNetClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
              "  module=&lt;class &#x27;__main__.MLP&#x27;&gt;,\n",
              ")</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "#the model is fitted and trained\n",
        "MLP_hyper_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained mlp hyperparameter model\n",
        "joblib.dump(MLP_hyper_model, 'trained_mlp_hyper_model.pkl')"
      ],
      "metadata": {
        "id": "-qx2TFxVKZlT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0baf6210-07a4-40a2-aa0f-4a570e6e1bbb"
      },
      "id": "-qx2TFxVKZlT",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['trained_mlp_hyper_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "f09f0934-7490-4ace-8ed5-39bdf93962b0",
      "metadata": {
        "id": "f09f0934-7490-4ace-8ed5-39bdf93962b0",
        "outputId": "ac55ff65-1788-4cf6-84db-6c426e9b239a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid scores obtained during model development: \n",
            "\n",
            "0.820 (+/-0.003) for {'lr': 0.01, 'max_epochs': 10, 'module__dropout_rate': 0.5, 'optimizer__momentum': 0.7, 'optimizer__weight_decay': 0.0001}\n",
            "0.817 (+/-0.004) for {'lr': 0.01, 'max_epochs': 10, 'module__dropout_rate': 0.5, 'optimizer__momentum': 0.7, 'optimizer__weight_decay': 0.001}\n",
            "0.856 (+/-0.006) for {'lr': 0.01, 'max_epochs': 10, 'module__dropout_rate': 0.5, 'optimizer__momentum': 0.9, 'optimizer__weight_decay': 0.0001}\n",
            "0.855 (+/-0.007) for {'lr': 0.01, 'max_epochs': 10, 'module__dropout_rate': 0.5, 'optimizer__momentum': 0.9, 'optimizer__weight_decay': 0.001}\n",
            "0.803 (+/-0.010) for {'lr': 0.01, 'max_epochs': 10, 'module__dropout_rate': 0.6, 'optimizer__momentum': 0.7, 'optimizer__weight_decay': 0.0001}\n",
            "0.789 (+/-0.011) for {'lr': 0.01, 'max_epochs': 10, 'module__dropout_rate': 0.6, 'optimizer__momentum': 0.7, 'optimizer__weight_decay': 0.001}\n",
            "0.846 (+/-0.008) for {'lr': 0.01, 'max_epochs': 10, 'module__dropout_rate': 0.6, 'optimizer__momentum': 0.9, 'optimizer__weight_decay': 0.0001}\n",
            "0.848 (+/-0.003) for {'lr': 0.01, 'max_epochs': 10, 'module__dropout_rate': 0.6, 'optimizer__momentum': 0.9, 'optimizer__weight_decay': 0.001}\n",
            "0.857 (+/-0.004) for {'lr': 0.01, 'max_epochs': 20, 'module__dropout_rate': 0.5, 'optimizer__momentum': 0.7, 'optimizer__weight_decay': 0.0001}\n",
            "0.856 (+/-0.003) for {'lr': 0.01, 'max_epochs': 20, 'module__dropout_rate': 0.5, 'optimizer__momentum': 0.7, 'optimizer__weight_decay': 0.001}\n",
            "0.873 (+/-0.004) for {'lr': 0.01, 'max_epochs': 20, 'module__dropout_rate': 0.5, 'optimizer__momentum': 0.9, 'optimizer__weight_decay': 0.0001}\n",
            "0.872 (+/-0.003) for {'lr': 0.01, 'max_epochs': 20, 'module__dropout_rate': 0.5, 'optimizer__momentum': 0.9, 'optimizer__weight_decay': 0.001}\n",
            "0.847 (+/-0.002) for {'lr': 0.01, 'max_epochs': 20, 'module__dropout_rate': 0.6, 'optimizer__momentum': 0.7, 'optimizer__weight_decay': 0.0001}\n",
            "0.845 (+/-0.006) for {'lr': 0.01, 'max_epochs': 20, 'module__dropout_rate': 0.6, 'optimizer__momentum': 0.7, 'optimizer__weight_decay': 0.001}\n",
            "0.867 (+/-0.001) for {'lr': 0.01, 'max_epochs': 20, 'module__dropout_rate': 0.6, 'optimizer__momentum': 0.9, 'optimizer__weight_decay': 0.0001}\n",
            "0.866 (+/-0.001) for {'lr': 0.01, 'max_epochs': 20, 'module__dropout_rate': 0.6, 'optimizer__momentum': 0.9, 'optimizer__weight_decay': 0.001}\n",
            "0.858 (+/-0.008) for {'lr': 0.05, 'max_epochs': 10, 'module__dropout_rate': 0.5, 'optimizer__momentum': 0.7, 'optimizer__weight_decay': 0.0001}\n",
            "0.859 (+/-0.008) for {'lr': 0.05, 'max_epochs': 10, 'module__dropout_rate': 0.5, 'optimizer__momentum': 0.7, 'optimizer__weight_decay': 0.001}\n",
            "0.848 (+/-0.011) for {'lr': 0.05, 'max_epochs': 10, 'module__dropout_rate': 0.5, 'optimizer__momentum': 0.9, 'optimizer__weight_decay': 0.0001}\n",
            "0.831 (+/-0.023) for {'lr': 0.05, 'max_epochs': 10, 'module__dropout_rate': 0.5, 'optimizer__momentum': 0.9, 'optimizer__weight_decay': 0.001}\n",
            "0.852 (+/-0.007) for {'lr': 0.05, 'max_epochs': 10, 'module__dropout_rate': 0.6, 'optimizer__momentum': 0.7, 'optimizer__weight_decay': 0.0001}\n",
            "0.848 (+/-0.012) for {'lr': 0.05, 'max_epochs': 10, 'module__dropout_rate': 0.6, 'optimizer__momentum': 0.7, 'optimizer__weight_decay': 0.001}\n",
            "0.835 (+/-0.004) for {'lr': 0.05, 'max_epochs': 10, 'module__dropout_rate': 0.6, 'optimizer__momentum': 0.9, 'optimizer__weight_decay': 0.0001}\n",
            "0.816 (+/-0.007) for {'lr': 0.05, 'max_epochs': 10, 'module__dropout_rate': 0.6, 'optimizer__momentum': 0.9, 'optimizer__weight_decay': 0.001}\n",
            "0.874 (+/-0.012) for {'lr': 0.05, 'max_epochs': 20, 'module__dropout_rate': 0.5, 'optimizer__momentum': 0.7, 'optimizer__weight_decay': 0.0001}\n",
            "0.872 (+/-0.004) for {'lr': 0.05, 'max_epochs': 20, 'module__dropout_rate': 0.5, 'optimizer__momentum': 0.7, 'optimizer__weight_decay': 0.001}\n",
            "0.860 (+/-0.005) for {'lr': 0.05, 'max_epochs': 20, 'module__dropout_rate': 0.5, 'optimizer__momentum': 0.9, 'optimizer__weight_decay': 0.0001}\n",
            "0.843 (+/-0.013) for {'lr': 0.05, 'max_epochs': 20, 'module__dropout_rate': 0.5, 'optimizer__momentum': 0.9, 'optimizer__weight_decay': 0.001}\n",
            "0.868 (+/-0.004) for {'lr': 0.05, 'max_epochs': 20, 'module__dropout_rate': 0.6, 'optimizer__momentum': 0.7, 'optimizer__weight_decay': 0.0001}\n",
            "0.863 (+/-0.008) for {'lr': 0.05, 'max_epochs': 20, 'module__dropout_rate': 0.6, 'optimizer__momentum': 0.7, 'optimizer__weight_decay': 0.001}\n",
            "0.834 (+/-0.016) for {'lr': 0.05, 'max_epochs': 20, 'module__dropout_rate': 0.6, 'optimizer__momentum': 0.9, 'optimizer__weight_decay': 0.0001}\n",
            "0.827 (+/-0.006) for {'lr': 0.05, 'max_epochs': 20, 'module__dropout_rate': 0.6, 'optimizer__momentum': 0.9, 'optimizer__weight_decay': 0.001}\n",
            "0.863 (+/-0.013) for {'lr': 0.1, 'max_epochs': 10, 'module__dropout_rate': 0.5, 'optimizer__momentum': 0.7, 'optimizer__weight_decay': 0.0001}\n",
            "0.855 (+/-0.009) for {'lr': 0.1, 'max_epochs': 10, 'module__dropout_rate': 0.5, 'optimizer__momentum': 0.7, 'optimizer__weight_decay': 0.001}\n",
            "0.803 (+/-0.003) for {'lr': 0.1, 'max_epochs': 10, 'module__dropout_rate': 0.5, 'optimizer__momentum': 0.9, 'optimizer__weight_decay': 0.0001}\n",
            "0.785 (+/-0.019) for {'lr': 0.1, 'max_epochs': 10, 'module__dropout_rate': 0.5, 'optimizer__momentum': 0.9, 'optimizer__weight_decay': 0.001}\n",
            "0.851 (+/-0.004) for {'lr': 0.1, 'max_epochs': 10, 'module__dropout_rate': 0.6, 'optimizer__momentum': 0.7, 'optimizer__weight_decay': 0.0001}\n",
            "0.848 (+/-0.002) for {'lr': 0.1, 'max_epochs': 10, 'module__dropout_rate': 0.6, 'optimizer__momentum': 0.7, 'optimizer__weight_decay': 0.001}\n",
            "0.726 (+/-0.007) for {'lr': 0.1, 'max_epochs': 10, 'module__dropout_rate': 0.6, 'optimizer__momentum': 0.9, 'optimizer__weight_decay': 0.0001}\n",
            "0.748 (+/-0.030) for {'lr': 0.1, 'max_epochs': 10, 'module__dropout_rate': 0.6, 'optimizer__momentum': 0.9, 'optimizer__weight_decay': 0.001}\n",
            "0.876 (+/-0.004) for {'lr': 0.1, 'max_epochs': 20, 'module__dropout_rate': 0.5, 'optimizer__momentum': 0.7, 'optimizer__weight_decay': 0.0001}\n",
            "0.862 (+/-0.014) for {'lr': 0.1, 'max_epochs': 20, 'module__dropout_rate': 0.5, 'optimizer__momentum': 0.7, 'optimizer__weight_decay': 0.001}\n",
            "0.794 (+/-0.043) for {'lr': 0.1, 'max_epochs': 20, 'module__dropout_rate': 0.5, 'optimizer__momentum': 0.9, 'optimizer__weight_decay': 0.0001}\n",
            "0.770 (+/-0.039) for {'lr': 0.1, 'max_epochs': 20, 'module__dropout_rate': 0.5, 'optimizer__momentum': 0.9, 'optimizer__weight_decay': 0.001}\n",
            "0.864 (+/-0.002) for {'lr': 0.1, 'max_epochs': 20, 'module__dropout_rate': 0.6, 'optimizer__momentum': 0.7, 'optimizer__weight_decay': 0.0001}\n",
            "0.857 (+/-0.003) for {'lr': 0.1, 'max_epochs': 20, 'module__dropout_rate': 0.6, 'optimizer__momentum': 0.7, 'optimizer__weight_decay': 0.001}\n",
            "0.620 (+/-0.145) for {'lr': 0.1, 'max_epochs': 20, 'module__dropout_rate': 0.6, 'optimizer__momentum': 0.9, 'optimizer__weight_decay': 0.0001}\n",
            "0.726 (+/-0.006) for {'lr': 0.1, 'max_epochs': 20, 'module__dropout_rate': 0.6, 'optimizer__momentum': 0.9, 'optimizer__weight_decay': 0.001}\n",
            "\n",
            "Best parameters obtained during training: {'lr': 0.1, 'max_epochs': 20, 'module__dropout_rate': 0.5, 'optimizer__momentum': 0.7, 'optimizer__weight_decay': 0.0001}\n",
            "\n",
            "Best score during training: 87.59%\n"
          ]
        }
      ],
      "source": [
        "# This will print all the Grid Scores obtained during model training\n",
        "print(\"Grid scores obtained during model development: \\n\")\n",
        "means = MLP_hyper_model.cv_results_['mean_test_score']\n",
        "stds = MLP_hyper_model.cv_results_['std_test_score']\n",
        "params = MLP_hyper_model.cv_results_['params']\n",
        "for mean, std, param in zip(means, stds, params):\n",
        "    print(f\"{mean:.3f} (+/-{std * 2:.3f}) for {param}\")\n",
        "\n",
        "# Printing the best parameters and best score obtained during training\n",
        "print(\"\\nBest parameters obtained during training:\", MLP_hyper_model.best_params_)\n",
        "print(\"\\nBest score during training: {:.2f}%\".format(MLP_hyper_model.best_score_ * 100))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}